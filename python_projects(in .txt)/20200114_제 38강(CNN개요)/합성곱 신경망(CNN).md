### 합성곱 신경망(CNN)

> CNN은 이미지 인식과 음성 인식 등 다양한 곳에서 사용되며, 
>
> 특히 이미지 인식 분야에서 딥러닝을 활용한 기법은 거의 CNN을 기초로 한다.
>
> → CNN의 매커니즘을 자세히 설명하고 이를 파이썬으로 구현해보자 



#### 1. 전체 구조 

> * Affine계층
>
> 지금까지 배운 신경망은 인접하는 계층의 모든 뉴런과 결합되어 있다. 
>
> → 이를 '완전연결(Fully-Connected, 전결합)' 이라 지칭한다. 
>
> → 완전히 연결된 계층을 'Affine 계층' 이라는 이름으로 구현한다. 
>
> 완전연결 신경망은 Affine 계층 뒤에 활성화 함수를 갖는 ReLU(또는 Sigmoid)계층이 이어진다.
>
> → 마지막 계층은 Affine계층에 이어 Softmax계층이 이어지며 최종결과(확률)를 출력한다. 
>
> * 합성곱 계층 & 풀링 계층
>
> CNN에서는 새로운 계층이 '합성곱(convolution)' 계층과 '풀링(Pooling)' 계층이 추가된다. 
>
> → CNN 계층은 'Conv-ReLU-(Pooling)' 의 흐름으로 연결된다.(Pooling은 불필요시 생략)
>
> → 'Affine-Relu' 에서 'Conv-ReLU-(Pooling)' 로 변화 
>
> 또한, 출력이 가까운 층에서는 지금까지의 Affine-Relu 구성을 사용할 수 있다.
>
> 마지막 출력 계층에서는 Affine-Softmax 조합을 그대로 사용한다. 
>
> ![완전연결 계층과 합성곱 계층](.\완전연결 계층과 합성곱 계층.png)

#### 2. 합성곱 계층 

> - 완전 연결 계층의 문제점 
>
> > * 완전 연결 계층은  '데이터의 형상이 무너진다' 는 단점이 있음. 
> >
> > : 대표적으로 이미지 데이터 → 세로, 가로, 채널(색상) 로 구성된 '3차원 데이터'
> >
> > * 그러나 기존 사례에서는 1차원으로 펴낸 데이터로 입력  
> >
> > (ex/ mnist → (1,28,28) 1채널, 세로 28픽셀, 가로 28픽셀을 1줄로 세운 784개 데이터化) 
> >
> > * 기존 이미지데이터는 3차원 형상으로서 갖는 고유한 정보들이 담겨있음
> >
> > (ex/ 공간적으로 같은 픽셀은 값이 비슷하다, 거리가 먼 픽셀끼리는 별 연관이 없다, 
> >
> > ​        RGB의 각 채널은 서로 밀접한 연관성이 있을 수 있다 etc....)
> >
> > * 완전연결 계층은 이러한 3차원 속에서 의미를 갖는 본질적인 패턴을 놓치고 모든 입력 데이터를 동등한 뉴런으로 취급하여 형상이 담긴 정보를 살릴 수 없음! 
> >
> > > ↔ 반면, 합성곱 계층은 형상을 유지하며, 이미지의 3차원을 유지하고 다음 계층에도 3차원의 데이터로 전달한다. 
> > >
> > > 합성곱 계층의 입출력 데이터는 **특징 맵(feature map)** 이라고 하며, 입력 데이터를 **입력 특징 맵(input feature map), ** 출력 데이터를 **출력 특징 맵(output feature map)**이라고 지칭한다. 
>
> * 합성곱 연산 
>
> > * 합성곱 연산 = (이미지 처리에서의) **필터연산**
> >
> > ![필터연산](.\필터연산.png)
> >
> > * 합성곱 연산은 입력 데이터에 필터를 적용하는 형태로 연산된다. 이때, 입력 데이터와 필터는       (**높이width, 너비height**) 의 형상을 가진다(2차원).
> >
> > * (Ex/ 입력데이터 (4, 4) , 필터(3, 3), 출력(2, 2) )
> >
> > * 필터는 다른 말로 **커널(kernal)** 이라고도 지칭한다. 
> >
> > * 합성곱 연산은 필터의 **윈도우**를 일정간격으로 이동해가며 입력 데이터에 적용한다.  입력과 필터에서 대응하는 원소끼리 곱한 후 그 총합을 구하는 **단일 곱셈 누산(FMA)**이 이루어진다. 
> >
> > * 단일 곱셈 누산의 결과를 출력의 해당 장소에 저장함으로서 연산이 완성된다. 
> >
> >   ![합성곱 연산의 계산순서](.\합성곱 연산의 계산순서.png)
> >
> > * CNN에서는 필터의 매개변수가 '가중치(w)'에 해당하며  '편항(bias)' 역시 존재한다. 
> >
> >   (편향은 항상 하나만 존재(1x1))
> >
> > ![합성곱 연산의 편향](D:\Home\Rhee\python_projects(in .txt)\20200114_제 38강(CNN개요)\합성곱 연산의 편향.png)
>
> * 패딩(Padding)
>
> > * 합성곱 연산에서 (주로)출력 크기를 조정할 목적으로 데이터 주변을 특정값(0) 으로 채우는 기법.
> > * 합성곱 연산을 거듭하면 출력이 크기가 점점 줄어들어(최종적으로 1) 더이상 연산을 수행할 수 없는것을 막기 위함 
> >
> >  <img src=".\패딩.png" alt="패딩" style="zoom:150%;" />
>
> * 스트라이드(stride)
>
> > * 필터를 적용하는 위치의 간격을 지칭. 윈도우의 이동 범위 
> > * 스프라이드의 크기를 키우면 출력의 크기는 작아진다. ↔ 패딩 
> >
> > * 예제 : 입력을 (H, W), 필터가 (FH, FW), 출력이 (OH, OW), 패딩이 P,  스트라이드가 S라고 할때 
> >
> > > OH = (H + 2P - FH) / S +1
> > >
> > > OW =(W + 2P - FW)/S +1						(*패딩과 스트라이드의 역 상관관계)\
> >
> > > 예1: 입력 (4, 4),  패딩 1,  스트라이드 1, 필터 (3,3)
> > >
> > > OH = (4 + 2*1 -3) / 1 + 1 = 4
> > >
> > > OW = (4 + 2*1 - 3) / 1 + 1 = 4					출력(4, 4)
> > >
> > > 예2:  입력 (7, 7),  패딩 0,  스트라이드 2, 필터 (3,3)
> > >
> > > OH = (7 + 2*0 -3) / 2 + 1 = 3
> > >
> > > OW = (7 + 2*0 -3) / 2 + 1 = 3					출력(3, 3)
> > >
> > > 예3:  입력 (28, 31),  패딩 2,  스트라이드 3, 필터 (5,5)
> > >
> > > OH = (28 + 2*2 - 5) / 3 + 1 = 10
> > >
> > > OW = (31 + 2*2 -5) /3 + 1 = 11				 출력(10, 11)
> >
> > * 출력 크기가 정수가 아니면 오류를 내주는 등의 대응이 필요하다.(원소의 개수니깐 당연히 정수)
> > * 3차원 데이터의 합성곱 연산 
> >
> > ![3차원 데이터의 합성곱 연산](.\3차원 데이터의 합성곱 연산.png)
> >
> > 

