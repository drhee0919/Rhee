## (11.21~11.22) 09_Pandas(data frame)(24강,25강) 
## - DataFrame (Pandas 패키지에서 지원하는)
## DataFrame을 만드는 가장 간단한 방법 
import numpy as np 
import pandas as pd

## DataFrame을 위한 dict를 만들어 보아요! 
data = {"서울" : 1000, "인천" : 3000} # => 데이터 표현이 JSON방식을 연상시킨다!
# Python은 JSON 데이터 handling 하는데 간편하다

data = {"names" : "홍길동", "year" : 2015, "points" : 3.9} #학생이름, 입학연도, 평균평점 
# 위 데이터로 만들 수 있는 pandas 형태는? : 일단 Series가 있다. + data frame
s = pd.Series(data)
print(s)
#names      홍길동
#year      2015
#points     3.9
#dtype: object
print(s.values) #['홍길동' 2015 3.9]
                #object타입으로서 value값만 1차원으로 출력된다. 
# 위 데이터를 살짝 변형해서 df도 만들어보자 
data = {"names" : ["홍길동", "김길동"],
        "year" : [2015, 2016],
       "points" : [3.9,4.5] }
df = pd.DataFrame(data)
print(df) #2차원 구조로 출력된다. 
#names  year  points
#0   홍길동  2015     3.9
#1   김길동  2016     4.5

## *DataFrame은 앞으로 print대신 display로 출력하겠다. (jupyter에서만 지원, 좀더 보기 편함)
display(df)

## 만약 행의 갯수가 일치하지 않는다면? -> 에러발생 
# 이렇게 처리 해야 한다. 
data = {"names" : ["홍길동", "김길동","신사임당"],
        "year" : [2015, 2016, np.nan],  #결측명시
       "points" : [3.9,4.5, np.nan] }   #출력시 NaN으로 나옴 
df = pd.DataFrame(data)
display(df)

## df에서 각 열은 Series이다. (df = Series의 집합체)
print(df["names"]) #Series형태로 출력된다.
#0     홍길동
#1     김길동
#2    신사임당
#Name: names, dtype: object

print(df.values) #2차원의 ndarray가 나온다 
#[['홍길동' 2015.0 3.9]
# ['김길동' 2016.0 4.5]
# ['신사임당' nan nan]]

print(df.shape) #(3,3) #3행3열의 2차원 구조 
print(df.size)  #9 # df안의 모든 요소 개수 
print(df.ndim)  #2 #당연히도

## df의 인덱스를 찍어보자 
print("DataFrame의 index: {}".format(df.index))
#DataFrame의 index: RangeIndex(start=0, stop=3, step=1) #RangeIndex라는 또 다른객체로 잡혀서 출력됨 
#RangeIndex는 내부적으로 list와 비슷한 자료구조, 이말인즉
print("DataFrame의 index[0] :{}".format(df.index[0])) #DataFrame의 index[0] :0

# df의 column을 찍어보자(key만 출력)
print("DataFrame의 column : {}".format(df.columns))
# DataFrame의 column : Index(['names', 'year', 'points'], dtype='object') #Index로 찍힘
# 위와 똑같이 이렇게도 접근가능하다 
print("DataFrame의 column[1] : {}".format(df.columns[1])) #DataFrame의 column[1] : year




## df의 index와 column에 이름을 부여해보자 
import numpy as np 
import pandas as pd 

data = {"names" : ["홍길동", "김길동"],
        "year" : [2015, 2016], 
       "points" : [3.9,4.5] }
df = pd.DataFrame(data)
df.index.name = "sNum"
df.columns.name = "학생정보"
display(df)
#학생정보	names	year	points
#sNum			
# 0	      홍길동	2015	  3.9
# 1	      김길동	2016	  4.5





## 외부데이터로 df를 생성해보자
## File(CSV)로 부터 데이터를 읽어와서 DataFrame을생성
import numpy as np 
import pandas as pd

# 일단 student.csv라는 이름의 csv파일과 해당 파일이 저장된 data 폴더를 pythone_DA폴더에 저장 
df = pd.read_csv("./data/student.csv") #csv파일을 읽어오는 함수가 pandas 패키지 내 존재 
display(df)






## 예제 : MovieLens Data File을 이용해서 DataFrame을 생성해 보자 
## ex/ ratings.csv, movies.csv
import numpy as np 
import pandas as pd 

df = pd.read_csv("./data/movies.csv") #아까 data폴더에 movies.csv를 옮겨오자 
display(df)
display(df.head()) #상위 5개가 호출된다.(R에서는 default가 6개)
display(df.shape) #(9742, 3) #movies.csv 파일은 9742행, 3열 






## Exception Handling(예외처리) - 외부데이터를 받아올 때 자주 사용한다. 
## ※exception error: '복구'가 가능한에러 (하드웨어적 결함, 단전 등이 아닌)
## 모든 언어는 의도치않은 오류가 나타났을때 프로그램이 죽는 것을 방지하기 위하여 Exception Handling기능을 지원하다. 
try:
    10/0    #Exceptio이 발생 => 극복해서 프로그램이 중지되지 않도록 처리하자 
except Exception as inst:
    print(inst) #예외상황에대한 내용을 출력 
finally:
    print("호호") #finally부분은 무조건 출력됨
    
#출력결과 
#division by zero
#호호





## Database에서 sql로 데이터를 추출해서 pandas의 DataFrame으로 생성 
## 사용하는 DBMS는 MySQL, 사용하는 데이터는 book table 
## 데이터베이스는 강사용 컴퓨터를 이용 (IP : 70.12.116.160)
## 먼저 package를 설치하자(conda install pymysql)
import pymysql.cursors #MySQL DBMS를 사용하기 위한 module로딩 
import numpy as np 
import pandas as pd 

##데이터베이스 connection 
conn = pymysql.connect(host="70.12.116.160",
                       user="data",
                       password="data",
                       db="library",
                       charset="utf8"
                      ) ##강사용 컴퓨터에 접근 필요 
#데이터가 실행중이라면?
#conn = pymysql.connect(host="localhost")

#검색할 키워드 지정 
keyword = "여행" 

# database에서 data를 가져오기 위한 SQL을 작성
# 책 제목에 keyword가 들어있는행을 찾아서 제목, 가격, 저자정보를 가져와라 
sql = "select btitle,bprice,bauthor " + \
      "from book " + \
      "where btitle like '%여행%'".format(keyword)
##접합부에 한칸 띄어라!!(필요한 부분 외 공백도 철저히 지킬것. 코드에 영향미침)
try:
    df = pd.read_sql(sql, conn)
    display(df)
    # 정상적으로 DataFrame을 얻어왔으면 
    # JSON File로 저장 
    df.to_json("./data/book_columns.json", orient="columns") #열의 형태로 해당경로에 저런 이름으로 편집결과 저장 
except Exception as inst:
    print("먼가 이상해요!!")
finally:
    conn.close()  #처리가 성공하든 그렇지 않든 상관없이 database를 닫는다 

## 브라우저(chrome)에서 편집결과 json파일 실행해보기 
#url주소란에 file:///C:/python_DA/data/book_columns.json 이런식으로 입력 
#또는 폴더창에서 파일 구글페이지로 drag 

# python에서 데이터 프레임은 R에서 사용하던 것 보다 불러오기,조작 후 저장등에서 보다 유연하다   





## 예제2: 영화진흥위원회의 일일 박스오피스 정보를 이용해서 df 작성하기
## 접속해서 JSON을 얻어내면 그걸 분석해서 내가 원하는 형태의 DataFrame을 생성 
import numpy as np 
import pandas as pd 
import urllib    #network접속을 하기 위해서 필요  
import json      #open API의 결과가 JSON
                 #JSON을 읽어들이기위한 module 
    
movie_url = "http://www.kobis.or.kr/kobisopenapi/" +\
            "webservice/rest/boxoffice/" +\
            "searchDailyBoxOfficeList.json?" +\
            "key={}&targetDt={}".format("180bd775952d53adb92d8dcf2c6fd2d4","20191120")
            #저번에 받아온 key값 이어서 쓴다.(로그인 후 확인)
page =urllib.request.urlopen(movie_url) #결과 JSON문자열을 얻어온다.
                                        #들어있는 page객체 확인 
json_page = json.loads(page.read()) #JSON문자열을 읽어옴과 동시에 해당 문자열을 load해서 dict뽑음
print(json_page) #실제 JSON문자열을 얻어옴 
print(type(json_page)) #<class 'dict'> #dict인거 확인 

## 예제3: 이렇게 JSON을 얻었으면 필요한 부분만 추려서 DataFrame으로 생성해보자 
## 순위, 영화제목, 당일 매출액을 DataFrame으로 구성 
## 작성해 보아요 

try:
    data = json_page["boxOfficeResult"]["dailyBoxOfficeList"] #json_page가 dict형태니깐 키로받아야징 
    df = pd.DataFrame(data)
    df2 = pd.DataFrame({"순위" : df["rank"], "영화제목" : df["movieNm"], "당일매출액" : df["salesAmt"]})
    #언어특성상 key로 받으면 value만 나오므로 
    display(df2) 
    #df.to_json("./data/book_columns.json", orient="columns") #열의 형태로 해당경로에 저런 이름으로 편집결과 저장 
except Exception as inst:
    print("먼가 이상해요!!")
finally:
    print("2019-11-20")  #처리가 성공하든 그렇지 않든 뽑아줘 





##예제3 (강사님 답안지)
movie_data = {}
rank_list = list()
title_list =list()
sales_list =list()


for m_dict in json_page["boxOfficeResult"]["dailyBoxOfficeList"]: #임의의 dict변수에 할당 
    rank_list.append(m_dict["rank"])
    title_list.append(m_dict["movieNm"])
    sales_list.append("{:,}".format(int(m_dict["salesAmt"]))) #tip:숫자단위 1000마다 , 표시 
    
movie_data["순위"] = rank_list
movie_data["영화제목"] = title_list
movie_data["당일 매출액"] = sales_list

df = pd.DataFrame(movie_data)
display(df)






## DataFrame 구축 
## -> csv파일로부터 DataFrame생성
## -> Database로부터 DataFrame생성
## -> Open API를 이용해서 JSON으로부터 DataFrame생성 

## DataFrame 생성 시 index와 column을 재 설정 
## R에서 NA(Not Available)는자못된 값,결측치 
## R에서 NULL은 값이 존재하지 않음을 의미
## R에서 NaN(Not available Number)은 숫자이긴 하지만 수학적으로 불가능한숫자 

##Python NaN(Not A Number) missing data를 지칭 
##Python Pandas의 NAN => R의 NA를 지칭 
##Null은 Python에서 None 으로 표현 
import numpy as np 
import pandas as pd
import warnings 

#warnings.filterwarnings(action="default") #warning을 켜요 
warnings.filterwarnings(action="ignore") #warning을 꺼요 

data = {
    "이름" : ["홍길동","신사임당","강감찬","을지문덕"],
    "학과" : ["컴퓨터","영어영문","기계","수학"],
    "학년" : [1,3,np.nan,2],          #결측 표시 방법 
    "학점" : [1.5, 4.5, 2.2, 3.5]
}

df = pd.DataFrame(data,
                 columns=["학년","학과","이름","평균평점","등급"],
                 index=["one","two","three","four"])
display(df.describe()) #R의 summary와 유사한 기능을 구사(기본적인 통계량 )
display(df)

##특정 column을 가져오는 방법  
print(df["이름"]) #column #column명으로 indexing => series로 리턴
## print(df[])

##column을 2개 이상 가져오려면 
df["학과"] #컬럼 1개만 들고와요. Series형태로 들고와요 
#df["학과","이름"] 이렇게 쓸수 없다! 
#대신 fancy indexing으로 
df[["학과","이름"]] #결과가 Data Frame으로 나온다(하나를 들고와도 마찬가지)
                   # 당연히 View로 처리된다. 

  
#주의해야 할 점 
student_names = df["이름"]  #view를 생성 (내가 들고온게view인지 , 복사본인지 잘 살필 것)
student_names["three"] = "최길동" #view를 통해서 수정 
print(student_names)








#df에서 특정 col의 값을 수정하기 
import numpy as np 
import pandas as pd
import warnings 

#warnings.filterwarnings(action="default") #warning을 켜요 
warnings.filterwarnings(action="ignore") #warning을 꺼요 

data = {
    "이름" : ["홍길동","신사임당","강감찬","을지문덕"],
    "학과" : ["컴퓨터","영어영문","기계","수학"],
    "학년" : [1,3,4,2],         
    "학점" : [1.5, 4.5, 2.2, 3.5]
}

df = pd.DataFrame(data,
                 columns=["학년","학과","이름","학점","등급"],
                 index=["one","two","three","four"])

df["등급"] = "A" #broadcasting(전부다 이거)
df["등급"] = ["A","C","F","A"] #각각도 가능
display(df)
df["나이"] =20 #column을 추가할 수 있어요 
df["나이"] = [20,30,10,70]
display(df)

#Series로 추가해보자 
age = pd.Series([20,30,10,70])
df["나이"] = age
display(df) #나이 NAN
            #Series값이 안 들어갔음을 확인 (왜 안들어갈까?)
#Series는 index를 기본적으로 갖고있다. (list의 경우는 따로 지정이 없을 경우 순차적)
#0~부터 시작하는 index인데 여기서 df는 'one'~'four'라는 index로 변경된 상태이기 때문에 안맞아서 안들어간다.
#대신 series는 size를 안맞추고(결측지정 가능하고) 내가 넣을 값만 지정해서 넣어줄 수 있다. 
df["나이"]= pd.Series([20,30,70],
                index = ["one","two","four"]) #1,2,4번째에만 넣는다. 
display(df)

## 조건을 통해 산출하는 col새로 만들어보기
df["장학여부"] = df["학점"] > 3.0
display(df)

##column을 삭제하려할땐?
#del df["등급"]  #알아만 둬 (실제로 쓰지마) -> 통상이런일이 있으면 다른 메서드를 쓴다 
#display(df)

#df.drop("등급",axis=1, inplace=True) #inplace=T면, '원본'을 지우라는 듯, return값이 None

#inplace=False면 원본은 변경하지 않지만, 삭제된 DataFrame이 return 됨 
new_df = df.drop("등급",axis=1, inplace=False)
display(df)
display(new_df)













###################################################################################################
##(11.22) 제 25강 
## Data Framed의 row indexing 
import numpy as np
import pandas as pd

data = {
    "이름" : ["홍길동","최길동","이지안","박동훈"],
    "학과" : ["컴퓨터","철학","영어영문","의학"],
    "학년" : [1,3,4,2],
    "학점" : [3.1,2.4,4.5,3.3]    
}

df = pd.DataFrame(data, 
                  columns = ["학과", "학년", "이름", "학점","등급"],
                  index = ["one","two","three","four"])

display(df)
df["이름"] #df에서 하나의 컬럼을 indexing할 때 사용 
#df["이름":"학점"]   #에러   #col은 slicing이 안된다. 
#대신에 Fancy indexing을 적용하자 
df[["학년","학점"]] #fancy indexing으로 col들을 들고올 수 있다.

##Data Frame에 대한 indexing에서 숫자를 이용하는 경우를 row indexing이라 지칭한다. 

#df[2]   # 에러   #col은 숫자 index로 들고 올 수 없다. 
         # df에서 숫자는 index가 아닌 똑같이 컬럼명을 지칭한다. 
df[1:3]  # row indexing에 대해서 slicing은 가능하다 
df[1:] 
df[1:-1] # 일반적인 slicing기법을 이용할 수 있다. 
# df[[0,3]]  #에러   #숫자를 이용하는 indexing에서 fancy indexing은 지원하지 않는다. 


## Row indexing을 하는 다른 방법 
## :index이름을 이용하여 row indexing을 해 보아요 
#df["one"] ##Error. "one"라는 이름의 column을 찾아낸다. 
df["one" : "three"] #OK, 지정 index값을 이용해서 row slicing 을 할 수 있다. 
df["one":] #일반적인 slicing이용이 가능 
# df["one":-1] #에러     #df[0:-1] 은 되지만, 일반 인덱스와 숫자의 혼합은 불가하다 
# df[["one","three"]]    #Error. fancy indexing은 지원하지 않아요 

## Data Frame의 행과 열을 가져오기 위해서 어떻게 해야 하나 
## 어떤 방식이 지원되고 어떤 방식이 지원되지 않는지를 구분 
## df[]를 이용하여 indexing, slicing 하는 방법 기억 








##loc
##Loc와 index를 이용하면 단일 row추출 및 fancy indexing 가능 

df.loc["two"]  # OK, loc와 index를 이용하면 단일 row 추출 가능 
# df.loc[1] #Error. loc와 숫자 index를 이용하면 단일 row 추출이 안된다. 
df.loc["one":"three"]  #OK. loc와 index를 이용하면 slicing 이 가능 
# df.loc["one":-1] #Error. 지원하지 않는다. 
df.loc[["one","three"]] #fancy indexing 사용가능하다. 
# df.loc[[0,3]] #Error. loc는 숫자 index와 사용할 수 없다. 

# row indexing과 동시에 열도 불러올 수 있다. (loc 는 행과 열에 대한 slicing이 가능하다 )
df.loc["one":"three",:] #row는 one부터 three까지, col은 다 
df.loc["one":"three","이름"]
#one      홍길동
#two      최길동
#three    이지안
#Name: 이름, dtype: object
df.loc["one" : "three",["이름","학점"]]
#   	이름	학점
#one	홍길동	3.1
#two	최길동	2.4
#three	이지안	4.5








## CS에서 특정 대상에 대해 4가지 작업을 할 수 있다. 
## 추가, 삭제, 수정, 검색  => CRUD작업(Create, Read, Update, Delete)
data = {
    "이름" : ["홍길동","최길동","이지안","박동훈"],
    "학과" : ["컴퓨터","철학","영어영문","의학"],
    "학년" : [1,3,4,2],
    "학점" : [3.1,2.4,4.5,3.3]    }


df = pd.DataFrame(data, 
                  columns = ["학과", "학년", "이름", "학점","등급"],
                  index = ["one","two","three","four"] )

display(df)
#	학과	학년	이름	학점	등급
#one	컴퓨터	1	홍길동	3.1	NaN
#two	철학	3	최길동	2.4	NaN
#three	영어영문	4	이지안	4.5	NaN
#four	의학	2	박동훈	3.3	NaN

## 1) row를 추가해보자 
df.loc["five"] = ["체육",2,"김연아",4.5,np.nan] #five라는 row를 추가하여 정보를 추가한다 
display(df)
#학과	학년	이름	학점	등급
#one	컴퓨터	1	홍길동	3.1	NaN
#two	철학	3	최길동	2.4	NaN
#three	영어영문	4	이지안	4.5	NaN
#four	의학	2	박동훈	3.3	NaN
#five	체육	2	김연아	4.5	NaN

df.loc["five","이름":"학점"] = ["김연아", 4.5] #five라는 row를 추가하여 이름과 학점을 정보를 넣는다. 
display(df)
#학과	학년	이름	학점	등급
#one	컴퓨터	1	홍길동	3.1	NaN
#two	철학	3	최길동	2.4	NaN
#three	영어영문	4	이지안	4.5	NaN
#four	의학	2	박동훈	3.3	NaN
#five	체육	2	김연아	4.5	NaN

df.loc["five",["학과","이름"]] = ["체육","김연아"] # 이렇게도 가능하다 
display(df) 
#학과	학년	이름	학점	등급
#one	컴퓨터	1	홍길동	3.1	NaN
#two	철학	3	최길동	2.4	NaN
#three	영어영문	4	이지안	4.5	NaN
#four	의학	2	박동훈	3.3	NaN
#five	체육	2	김연아	4.5	NaN

## 2)삭제를 실시해보자 
new_df = df.drop("학점", axis=1)  #inplace를 생략하면 원본 유지 (24강 부분 참조)
display(new_df)                   # 삭제된 복사본을 return
#	학과	학년	이름	등급
#one	컴퓨터	1	홍길동	NaN
#two	철학	3	최길동	NaN
#three	영어영문	4	이지안	NaN
#four	의학	2	박동훈	NaN
#five	체육	2	김연아	NaN


df.drop("학점", axis=1, inplace =True ) #원본이 변경되고 return  
display(df)
#학과	학년	이름	등급
#one	컴퓨터	1	홍길동	NaN
#two	철학	3	최길동	NaN
#three	영어영문	4	이지안	NaN
#four	의학	2	박동훈	NaN
#five	체육	2	김연아	NaN

new_df = df.drop("one",axis =0)
display(new_df)
#학과	학년	이름	등급
#two	철학	3	최길동	NaN
#three	영어영문	4	이지안	NaN
#four	의학	2	박동훈	NaN
#five	체육	2	김연아	NaN


## 여러행을 삭제해보자 
#만약 slicing을 해보면?
#new_df = df.drop(["one": "three"], axis = 0)
#display(new_df) # error, 지원안함
#대신

new_df = df.drop(["one","three"],axis=0)
display(new_df)
#학과	학년	이름	등급
#two	철학	3	최길동	NaN
#four	의학	2	박동훈	NaN
#five	체육	2	김연아	NaN








## iloc - 숫자 index출력, slicing, fancy indexing이 가능한 loc발전형
data = {
    "이름" : ["홍길동","최길동","이지안","박동훈"],
    "학과" : ["컴퓨터","철학","영어영문","의학"],
    "학년" : [1,3,4,2],
    "학점" : [3.1,2.4,4.5,3.3]    }


df = pd.DataFrame(data, 
                  columns = ["학과", "학년", "이름", "학점","등급"],
                  index = ["one","two","three","four"])

display(df)

#학과	학년	이름	학점	등급
#one	컴퓨터	1	홍길동	3.1	NaN
#two	철학	3	최길동	2.4	NaN
#three	영어영문	4	이지안	4.5	NaN
#four	의학	2	박동훈	3.3	NaN

df.iloc[0]   #ok, 특정 row를 숫자 index로 추출할 수 있다. (그냥loc에서는 안됐다)
#학과    컴퓨터
#학년      1
#이름    홍길동
#학점    3.1
#등급    NaN
#Name: one, dtype: object



df.iloc[0:3]  #ok, slicing되네요
#	학과	학년	이름	학점	등급
#one	컴퓨터	1	홍길동	3.1	NaN
#two	철학	3	최길동	2.4	NaN
#three	영어영문	4	이지안	4.5	NaN

df.iloc[[0,3]] #ok, fancy indexing 도 지원합니다. 
#	학과	학년	이름	학점	등급
#one	컴퓨터	1	홍길동	3.1	NaN
#four	의학	2	박동훈	3.3	NaN

df.iloc[[0,3],0] #ok, column도 숫자 index로 사용할 수 있다. 
#one     컴퓨터
#four     의학
#Name: 학과, dtype: object

df.iloc[[0,3],[0,2]] # 이것두 ok
#	학과	이름
#one	컴퓨터	홍길동
#four	의학	박동훈

df.iloc[0,0]#컴퓨터   
#iloc를 이용하면 마치 2차원 배열 이용하듯 사용할 수 있다.








## boolean indexing 
## boolean indexing은 mask를 사용해요 
df = pd.DataFrame(data, 
                  columns = ["학과", "학년", "이름", "학점","등급"],
                  index = ["one","two","three","four"])

display(df)

df["학점"] >= 3.0 #[True, False, True, True]
## 학점이 3.0이상인 사람의 학과와 이름을 출력하세요 
df.loc[df["학점"] >= 3.0,["학과","이름"]]
#	     학과	       이름
#one	컴퓨터	     홍길동
#three	영어영문	이지안
#four	의학	      박동훈








#연습문제 풀어보기 
import numpy as np
import pandas as pd

data = {
    "이름" : ["이지안","박동훈","홍길동","강감찬","오혜영"],
    "학과" : ["컴퓨터","기계","철학","컴퓨터","철학"],
    "학년" : [1,2,2,4,3],
    "학점" : [1.5,2.0,3.1,1.1,2.7]    
}

df = pd.DataFrame(data, 
                  columns = ["학과", "학년", "이름", "학점","등급"],
                  index = ["one","two","three","four","five"])

display(df)

## 1) 이름이 "박동훈" 인 사람을 찾아 이름과 학점을 DataFrame으로 출력 
df.loc[df["이름"] =="박동훈" ,["이름","학점"]]

## 2) 학점이 (1.5, 2.5)(== 1.5 =< 학점 < 2.5)인 사람을 찾아 학과, 이름, 학점을 DF로 출력 
df.loc[(df["학점"] >= 1.5) & (df["학점"] < 2.5), ["학과","이름","학점"]] 
# numPy 연산에서는 'and' 아닌 '&'를 써야한다.
 
## 3) 학점이 3.0을 초과하는 사람을 찾아 등급을 "A"로 설정하세요 
df.loc[df["학점"] > 3.0 , "등급"] = "A"
display(df)










## Data Frame을 제어하기 
## random seed를 잡아서 재현성을 확보 
#3 [0,10) 정수형 난수를 균등분포로 생성(0이상 10미만 ) →6행 4열로 

import numpy as np
import pandas as pd


np.random.seed(100)
data = np.random.randint(0,10,(6,4))

df = pd.DataFrame(data)
display(df)
#	0	1	2	3
#0	8	8	3	7
#1	7	0	4	2
#2	5	2	2	2
#3	1	0	8	4
#4	0	9	6	2
#5	4	1	5	3



## column과 index를 다시 정의해 보아요 
df.columns = ["A","B","C","D"]
display(df) # col명도 바뀌는 것을 확인할 수 있다. 
#	A	B	C	D
#0	8	8	3	7
#1	7	0	4	2
#2	5	2	2	2
#3	1	0	8	4
#4	0	9	6	2
#5	4	1	5	3




#날짜로서 index를 설정해보자 
df.index = pd.date_range("20190101","20190106")
#또는
df.index = pd.date_range("20190101",periods=6)
display(df)
#           A	B	C   D
#2019-01-01	8	8	3	7
#2019-01-02	7	0	4	2
#2019-01-03	5	2	2	2
#2019-01-04	1	0	8	4
#2019-01-05	0	9	6	2
#2019-01-06	4	1	5	3



##NaN(결치값)을 포함하는 새로운 컬럼 "E"를 추가해보아요! 
df["E"] = [7, np.nan, 4, np.nan, 2, np.nan]
##NaN은 결치값이지만 float(실수)로 간주(연산이 가능(잘못된 값에 무슨 연산을 하든 결과는 NaN이지만))
display(df)
#       	A	B	C	D	E
#2019-01-01	8	8	3	7	7.0
#2019-01-02	7	0	4	2	NaN
#2019-01-03	5	2	2	2	4.0
#2019-01-04	1	0	8	4	NaN
#2019-01-05	0	9	6	2	2.0
#2019-01-06	4	1	5	3	NaN

## sample로 결치값이 포함된 DataFrame을 생성했어요 
## 결치값을 포함한 행을지우고 싶다면? .dropna()
new_df = df.dropna(how="any", inplace=False)
display(new_df)
#           A	B	C	D	E
#2019-01-01	8	8	3	7	7.0
#2019-01-03	5	2	2	2	4.0
#2019-01-05	0	9	6	2	2.0

#how = 'all' 행의 모든 값이 NaN이면 지운다
new_df = df.fillna(value = 0, inplace = False)
display(new_df)
#       	A	B	C	D	E
#2019-01-01	8	8	3	7	7.0
#2019-01-02	7	0	4	2	0.0
#2019-01-03	5	2	2	2	4.0
#2019-01-04	1	0	8	4	0.0
#2019-01-05	0	9	6	2	2.0
#2019-01-06	4	1	5	3	0.0

## E column 에 NaN이 포함된 행을 찾아서 B와 C colyumn의 값을 출력해보아요
## NaN을 판별하는 함수 : isnull()을 이용해서 처리해 보아요 

# 조건이 들어간다? : boolean 사용 
df.loc[df.isnull()["E"],["B","C"]]
#       	B	C
#2019-01-02	0	4
#2019-01-04	0	8
#2019-01-06	1	5
###############################################################
#DataFrame의 제어에 관한 내용
(indexing, slicing, fancy indexing ,boolean indexing )








## 분석용 함수(기본통계함수 )
## : 평균(mean), 편차(deviation), 분산(variance), 표준편차(standard deviation), 공분산(covariance), 상관계수(correlation) 
##
##  ex/ X => 85732
##      mean => 5
##      deviation => 3 0 2 -2 -3 => sum은 0 
## 1) 평균(mean) (*average와 mean의 차이 ) 총 수치값의 합산/ 총 개수 
## 2) 편차(deviation) : 확률변수 X와 mean의 차이 
## 3) 분산(variance)  : 데이터의 흩어짐 정도를알기 위해서 사용하는값으로 편차의 제곱의 평균 
## 4) 표준편차(standard deviation) : 분산의 제곱근, 분산의 단위 문제를 해결하고자 사용(ex/총점이 10일때, 100일때)
## 5) 공분산(covariance) : 두개의 확률변수 X,Y가 있을때 이 두개의 확률변수의 관계를 보여줄 때 사용
##                         데이터가 평균으로부터 얼마나 떨어져있는냐를 표현 (두 확률변수의 편차의 곱의 평균)
## 6) 상관계수(correlation) : 상호 상관관계의 수치 정도를 나타내기 위한 수치 

# 임의의 1차원 리스트 선언 
import numpy as np 

arr = np.array([4,6,1,3,8,8], dtype=np.int32)
print(arr)
print(arr.sum()) #30
#또는 
print(np.sum(arr)) #30

#평균출력하기
print(arr.mean()) #5.0

#분산 출력하기
print(arr.var()) #6.666666666666667

#표준편차 출력하기 
print(arr.std()) #2.581988897471611




##공분산 그래프를 그려보자 
import numpy as np
import matplotlib.pyplot as plt #만약 module이 없다고 error가 나오면 conda install matplotlib 
np.random.seed(1) #항상 같은 난수가 발생하도록 seed처리 
x = np.random.randint(-20,20,(10,))
y = np.random.randint(-10,10,(10,)) #범위가 서로 다름 
print(x) #[ 17  -8 -12 -11  -9 -15  -5 -20  -4 -19]
print(y) #[ 2 -3  3 -4  8 -5  8  1  0  4]

x_mean = x.mean()
y_mean = y.mean()

x_deviation = x-x_mean
y_deviation = y-y_mean

result =0
for i in range(10):
    result += x_deviation[i] + y_deviation[i]

myCov = result/ 9  #모공분산: 원래 공식
print(myCov)       # 표준공분산 : (n-1)로 나눈다. 추정치가 좋아진다. 
#-3.9474596431116675e-16

#또는 
print(np.cov(x,y))
#[[109.6          5.93333333]
# [  5.93333333  20.93333333]]
    
# scatter(산점도) 표현해 보아요 
plt.scatter(x,y,color="red")
plt.scatter(x_mean,y_mean,color="blue")
plt.show()








## 공분산이 양수인경우(KOSPI지수와 삼성전자 주가)
import numpy as np 
import pandas as pd
import pandas_datareader.data as pdr #금융데이터를 이용하기 위해서 
#아나콘다에서 제공을 안해주니 pip install pandas_datareader(파이썬 기본 repository를 찾아서 설치 )
from datetime import datetime 

## 특정 날짜를 이용해서 금융데이터를 가져올거
start = datetime(2018,1,1)  #시작날짜
end = datetime(2018,12,31)  #끝 날짜 

##^KS11 : 한국 KOSPI 지수
#df_KOSPI = pdr.DataReader("^KS11","yahoo",start,end)
#df_KOSPI.to_json("./data/KOSPI.json")
#display(df_KOSPI)
#네트워크 접근이 막혀있으면? : 집에서 해보고 JSON파일을 이용해서 DataFrame을 이용해야 해요 ! 

#JSON을 불러들여서.. DataFrame을 만들어요 2개
#KOSPI.json, SE.json 
# np.cov()를 이용해서 공분산을 구해보아요 
import json 
file_KOSPI = open("./data/KOSPI.json","r")
file_SE = open("./data/SE.json","r")
#파일의 내용을 읽어서 dict로 변환한 후 dict를 이용해서 DataFrame을 생성 
df_KOSPI = pd.DataFrame(json.load(file_KOSPI)) #dict를 pandas로  #코스피
df_SE = pd.DataFrame(json.load(file_SE)) #삼전 
display(df_KOSPI.head())
#                   High	    Low	        Open	   Close	Volume	Adj Close
#1514851200000	2481.020020	2465.939941	2474.860107	2479.649902	262200	2479.649902
#1514937600000	2493.399902	2481.909912	2484.629883	2486.350098	331100	2486.350098
#1515024000000	2502.500000	2466.449951	2502.500000	2466.459961	333800	2466.459961
#1515110400000	2497.520020	2475.510010	2476.850098	2497.520020	308800	2497.520020
#1515369600000	2515.370117	2494.179932	2510.699951	2513.280029	311400	2513.280029
display(df_SE.head())
#                High	  Low	 Open	 Close	 Volume 	Adj Close
#1514851200000	51400.0	50780.0	51380.0	51020.0	8474250.0	31700.921875
#1514937600000	52560.0	51420.0	52540.0	51620.0	10013500.0	32073.728516
#1515024000000	52180.0	50640.0	52120.0	51080.0	11695450.0	31738.205078
#1515110400000	52120.0	51200.0	51300.0	52120.0	9481150.0	32384.400391
#1515369600000	52520.0	51500.0	52400.0	52020.0	8383650.0	32322.263672
#종가를 비교해보자
close_KOSPI = df_KOSPI["Close"]
close_SE = df_SE["Close"]

print(np.cov(close_KOSPI, close_SE))   #공분산이 양수, 즉 정비례한다
#[[   24177.23140621   490222.10530186]
# [  490222.10530186 11919911.50745463]]








## 똑같은 작업을 LIG넥스원과 부산산업을 대상으로 공분산 계산
import numpy as np 
import pandas as pd
import pandas_datareader.data as pdr
from datetime import datetime 

start = datetime(2018,1,1)  #시작날짜
end = datetime(2018,12,31)  #끝 날짜 


import json 

file_KOSPI = open("./data/KOSPI.json","r")
file_LIG = open("./data/LIG넥스원.json","r")
file_Busan = open("./data/부산산업.json","r")

df_KOSPI = pd.DataFrame(json.load(file_KOSPI))
df_LIG = pd.DataFrame(json.load(file_LIG)) #LIG넥스원 dataframe
df_Busan = pd.DataFrame(json.load(file_Busan)) #  부산산업 dataframe

display(df_KOSPI.head())
#                   High	    Low	       Open	       Close	Volume	Adj Close
#1514851200000	2481.020020	2465.939941	2474.860107	2479.649902	262200	2479.649902
#1514937600000	2493.399902	2481.909912	2484.629883	2486.350098	331100	2486.350098
#1515024000000	2502.500000	2466.449951	2502.500000	2466.459961	333800	2466.459961
#1515110400000	2497.520020	2475.510010	2476.850098	2497.520020	308800	2497.520020
#1515369600000	2515.370117	2494.179932	2510.699951	2513.280029	311400	2513.280029
display(df_LIG.head())
#             	 High	 Low	Open	Close	Volume	Adj Close
#1514851200000	60500	59500	59800	60300	105294	60300
#1514937600000	60300	58800	60300	59200	150080	59200
#1515024000000	59500	57700	58600	57800	141177	57800
#1515110400000	57500	55400	56100	55800	281124	55800
#1515369600000	56000	54000	56000	54500	223472	54500
display(df_Busan.head())
#             	 High	 Low	Open	Close	Volume	Adj Close
#1514851200000	30000	29450	29500	29900	835 	29900
#1514937600000	31950	29900	29900	31850	4195	31850
#1515024000000	34300	31500	31850	32500	7425	32500
#1515110400000	32950	30500	32500	32300	4074	32300
#1515369600000	33100	32050	32600	32900	3019	32900

#종가를 비교해보자
close_KOSPI = df_KOSPI["Close"]
close_LIG = df_LIG["Close"]
close_Busan = df_Busan["Close"]
print(np.cov(close_KOSPI, close_LIG)) 
#[[2.41772314e+04 9.80094772e+05]
# [9.80094772e+05 6.35924170e+07]]
print(np.cov(close_KOSPI, close_Busan))
#[[ 2.41772314e+04 -6.11306992e+06]
# [-6.11306992e+06  4.64762211e+09]]

plt.scatter(close_KOSPI, close_LIG,color="red")
plt.scatter(close_KOSPI, close_Busan,color="blue")
plt.show()


