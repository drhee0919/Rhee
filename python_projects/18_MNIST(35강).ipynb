{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "### multinominal classification exercise \n",
    "## -> MNIST 예제를 이용해서 보완해야 하는 부분들을 알아보자 \n",
    "## -> MNIST 는 '이미지를 학습하고 prediction' 하는 예제(28pixel*28pixel크기의 이미지들이 주어진다.)\n",
    "## -> 각 이미지들은 사람이 '수기로 쓴 숫자' 들이 들어있다. \n",
    "## -> 1명당 0~9까지 숫자를 쓴 내용이 5만명 분이 들어있다. (50,000set x 10 = 500,000images)\n",
    "## -> MNIST 의 결과물 multinomial 개수는 10개의 logistic을 가짐(0~9) \n",
    "\n",
    "# 필요한 module import \n",
    "import tensorflow as tf \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from tensorflow.examples.tutorials.mnist import input_data #데이터셋 불러오기용(.gz파일, unix계열 압축파일)\n",
    "\n",
    "# Data Loading \n",
    "mnist = input_data.read_data_sets(\"./data/mnist\", one_hot=True) #one_hot encoding상태로 받아올 수 있다! \n",
    "                                              #단, tf가 제공하는 형태이기 때문에 가능한것(다 되는건 아니다) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading이어서 \n",
    "mnist.train.images # 학습용 데이터 불러오기 (2차원 array)\n",
    "mnist.train.images.shape #(55000, 784)\n",
    "\n",
    "#이미지데이터 -> x train data로 불러오기 \n",
    "\n",
    "train_x_data_df = pd.DataFrame(mnist.train.images) #데이터 프레임으로 만들어\n",
    "train_x_data_df.to_csv(\"./mnist_x_data.csv\", index=False) #csv파일로 만들어버리자 \n",
    "\n",
    "# x데이터의 각 column은(=각 pixel값은) 0과 1사이의 값으로 이미 scale이 되어있는 상태(채도 차이)\n",
    "# 0과 가까울 수 록 흰색을 지칭, 1과 가까울 수 록 색상이 어두워진다. \n",
    "\n",
    "#숫자 데이터 -> y train data로 불러오기\n",
    "train_y_data_df = pd.DataFrame(mnist.train.labels)\n",
    "train_y_data_df.to_csv(\"./mnist_y_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow로 machine learning \n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,784], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None,10], dtype=tf.float32)\n",
    "\n",
    "# Weight & bias \n",
    "W = tf.Variable(tf.random_normal([784, 10]), name=\"weight\") #가중치 7840개\n",
    "b = tf.Variable(tf.random_normal([10]), name=\"bias\")\n",
    "\n",
    "# Hypothesis \n",
    "logit = tf.matmul(X,W) + b\n",
    "H = tf.nn.softmax(logit) #softmax 처음등장 (sigmoid 대신 probability 등장)\n",
    "\n",
    "# cost function \n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = logit, \n",
    "                                                                 labels = Y)) #버전 2로 고르자 \n",
    "#train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate = 0.5).minimize(cost) \n",
    "\n",
    "#session 초기화 \n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost값은 : 0.7083113193511963\n",
      "Cost값은 : 0.1663648933172226\n",
      "Cost값은 : 0.34958332777023315\n",
      "Cost값은 : 0.1819928139448166\n",
      "Cost값은 : 0.1751987338066101\n",
      "Cost값은 : 0.2316340208053589\n",
      "Cost값은 : 0.20302201807498932\n",
      "Cost값은 : 0.11976692080497742\n",
      "Cost값은 : 0.2696097791194916\n",
      "Cost값은 : 0.1277509182691574\n"
     ]
    }
   ],
   "source": [
    "# 이제부터 학습할 땐 조심해야 한다! :데이터 사이즈가 비대하다(잘못돌리면 오래걸림)\n",
    "# 학습 \n",
    "train_epoch = 500 #데이터 사이즈를 보고 에폭수를 조정 \n",
    "batch_size = 100 # (데이터를)몇개로 잘라서 할래? 내 pc가 가진 메모리, cpu에 따라 조정 \n",
    "                 # (아무리 큰 데이터가들어와도 잘라서 처리할 수 있다.)\n",
    "for step in range(train_epoch):\n",
    "    num_of_iter = int(mnist.train.num_examples / batch_size)\n",
    "    cost_val = 0\n",
    "    \n",
    "    for i in range(num_of_iter):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size) #tf 에서 지원(다른 문제에서는 구해야 한다.)\n",
    "                                                              #X쪽 100개, Y쪽 100개를 반복 \n",
    "        _, cost_val = sess.run([train, cost], \n",
    "                               feed_dict={X:batch_x, #ndarray로 넣는 편이 좋다 \n",
    "                                          Y:batch_y})\n",
    "    if step % 50 == 0:\n",
    "        print(\"Cost값은 : {}\".format(cost_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도는 : 0.920799970626831\n"
     ]
    }
   ],
   "source": [
    "# 학습이 종료되었으니 정확도 측정 (학습과 분리)      \n",
    "# Accuracy(정확도)\n",
    "predict = tf.argmax(H,1) #출력되는 셋 중 가장 큰 값의 index번호를 리턴 \n",
    "correct = tf.equal(predict, tf.argmax(Y, 1)) # predict와 correct가 맞으면 좋은 모델(위치를 가지고 비교)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "print(\"정확도는 : {}\".format(sess.run(accuracy, \n",
    "                                   feed_dict={X:mnist.test.images, \n",
    "                                              Y:mnist.test.labels})))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label : [3]\n",
      "Predict : [3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x16c565c1d68>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prediction \n",
    "# 랜덤으로 하나의 데이터를 추출해서 그놈을 이용해서 prediction을 한 후 결과를 비교해 보아요! \n",
    "r = np.random.randint(0,mnist.test.num_examples) #0부터 55000사이의 난수를튕김 \n",
    "# 난수가 의미하는 행의 label값을 먼저 구해보아요! \n",
    "\n",
    "mnist.test.labels[r] # array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n",
    "                     # 요런 형태 \n",
    "print(\"Label : {}\" .format(sess.run(tf.argmax(mnist.test.labels[r:r+1], axis=1)))) \n",
    "#1차원의형태라서 axis=0밖에 못씀\n",
    "#[r:r+1] = r번째 행이지만 차원형태를 위해 지칭\n",
    "#print(\"Label : {}\" .format(sess.run(tf.argmax(mnist.test.labels[r], axis=0)))) ->이거랑 동일 \n",
    "print(\"Predict : {}\" .format(sess.run(tf.argmax(H,1), \n",
    "                      feed_dict={X:mnist.test.images[r:r+1]})))\n",
    "                        #2차원 placeholder와 차원을 맞춰주자 \n",
    "                        #10번 중 한번골로 다른 결과가 다르게 나올 수도 있다.\n",
    "\n",
    "#어떻게 생겼는지 보자     \n",
    "#pyplot에 있는 imshow 메서드를 통해 이미지를 출력 \n",
    "plt.imshow(mnist.test.images[r:r+1].reshape(28,28), cmap=\"Greys\") #그냥 그리면 알아서 컬러풀하게 해주니 따로 원본처럼 설정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "## kaggle데이터를 이용해서 문제를 풀어보자 \n",
    "## tf내장 데이터셋이 아닌 실제 공모 데이터로 측정 \n",
    "\n",
    "# 필요한 module import \n",
    "import tensorflow as tf \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Data Loading \n",
    "train_mnist = pd.read_csv(\"./data/digit-recognizer/train.csv\")\n",
    "test_mnist = pd.read_csv(\"./data/digit-recognizer/test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000,)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#최초확인\n",
    "#print(train_mnist.shape)\n",
    "#print(train_mnist.head(1))\n",
    "\n",
    "# 라벨 col럼 분리하기 \n",
    "train_x_data = train_mnist.drop(\"label\",axis=1)\n",
    "train_y_data = train_mnist[\"label\"]\n",
    "train_x_data.shape #(42000, 784)\n",
    "train_y_data.shape #42000\n",
    "\n",
    "\n",
    "# Y(숫자라벨) 데이터형태 변화 -> 2차원 ndarray\n",
    "#np.unique(train_y_data) #array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n#데이터 타입 변환 \\ntrain_x_data = train_x_data.values.reshape([-1,1])\\ntrain_y_data = train_y_data.values.reshape([-1,1])\\ntrain_x_data.shape\\n'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data process \n",
    "# 정의역 전처리 \n",
    "plot_image = train_x_data.values.reshape(train_x_data.shape[0], 28, 28)\n",
    "\n",
    "#정의역 특정데이터 이미지 확인 \n",
    "plt.figure()\n",
    "plt.imshow(plot_image[2])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n",
    "# 0~1사이로 범위지정(학습하기 좋게 쪼개기)\n",
    "train_x_data = train_x_data / 255.0\n",
    "test_mnist = test_mnist / 255.0\n",
    "#print(train_x_data)\n",
    "#print(test_mnist)\n",
    "\n",
    "#공역 One_Hot Encoding\n",
    "train_y_data = pd.get_dummies(train_y_data) #(42000, 10)\n",
    "\n",
    "\n",
    "\n",
    "print(type(train_x_data))\n",
    "print(type(train_y_data))\n",
    "\n",
    "'''\n",
    "#데이터 타입 변환 \n",
    "train_x_data = train_x_data.values.reshape([-1,1])\n",
    "train_y_data = train_y_data.values.reshape([-1,1])\n",
    "train_x_data.shape\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow로 machine learning \n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,784], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None,10], dtype=tf.float32)\n",
    "\n",
    "# Weight & bias \n",
    "W = tf.Variable(tf.random_normal([784, 10]), name=\"weight\") #가중치 7840개\n",
    "b = tf.Variable(tf.random_normal([10]), name=\"bias\")\n",
    "\n",
    "# Hypothesis \n",
    "logit = tf.matmul(X,W) + b\n",
    "H = tf.nn.softmax(logit) #softmax 처음등장 (sigmoid 대신 probability 등장)\n",
    "\n",
    "# cost function \n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = logit, \n",
    "                                                                 labels = Y)) #버전 2로 고르자 \n",
    "#train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate = 0.5).minimize(cost) \n",
    "\n",
    "#session 초기화 \n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost값은 : 1.8446931838989258\n",
      "Cost값은 : 1.8997782468795776\n",
      "Cost값은 : 1.795259952545166\n",
      "Cost값은 : 1.8737612962722778\n",
      "Cost값은 : 1.8589887619018555\n",
      "Cost값은 : 1.8575539588928223\n",
      "Cost값은 : 1.8748114109039307\n",
      "Cost값은 : 1.8822942972183228\n",
      "Cost값은 : 1.8301352262496948\n",
      "Cost값은 : 1.8440451622009277\n",
      "Cost값은 : 1.891868233680725\n",
      "Cost값은 : 1.8800055980682373\n",
      "Cost값은 : 1.8560906648635864\n",
      "Cost값은 : 1.8524987697601318\n",
      "Cost값은 : 1.7908527851104736\n",
      "Cost값은 : 1.84955632686615\n",
      "Cost값은 : 1.8428955078125\n",
      "Cost값은 : 1.8878588676452637\n",
      "Cost값은 : 1.8694729804992676\n",
      "Cost값은 : 1.8407055139541626\n",
      "Cost값은 : 1.8324928283691406\n",
      "Cost값은 : 1.8578248023986816\n",
      "Cost값은 : 1.8047878742218018\n",
      "Cost값은 : 1.8588370084762573\n",
      "Cost값은 : 1.8754472732543945\n",
      "Cost값은 : 1.829787254333496\n",
      "Cost값은 : 1.8109238147735596\n",
      "Cost값은 : 1.8356175422668457\n",
      "Cost값은 : 1.8442654609680176\n",
      "Cost값은 : 1.9083044528961182\n",
      "Cost값은 : 1.9255743026733398\n",
      "Cost값은 : 1.779686689376831\n",
      "Cost값은 : 1.8799505233764648\n",
      "Cost값은 : 1.858534812927246\n",
      "Cost값은 : 1.871951937675476\n",
      "Cost값은 : 1.8974195718765259\n",
      "Cost값은 : 1.8537259101867676\n",
      "Cost값은 : 1.8412225246429443\n",
      "Cost값은 : 1.8478729724884033\n",
      "Cost값은 : 1.7808599472045898\n",
      "Cost값은 : 1.8781589269638062\n",
      "Cost값은 : 1.8295291662216187\n",
      "Cost값은 : 1.8132864236831665\n",
      "Cost값은 : 1.8344591856002808\n",
      "Cost값은 : 1.8312321901321411\n",
      "Cost값은 : 1.8607968091964722\n",
      "Cost값은 : 1.920516014099121\n",
      "Cost값은 : 1.8304885625839233\n",
      "Cost값은 : 1.8628528118133545\n",
      "Cost값은 : 1.8536651134490967\n",
      "Cost값은 : 1.8269848823547363\n",
      "Cost값은 : 1.87441086769104\n",
      "Cost값은 : 1.8494967222213745\n",
      "Cost값은 : 1.866655707359314\n",
      "Cost값은 : 1.922755479812622\n",
      "Cost값은 : 1.85429048538208\n",
      "Cost값은 : 1.8614088296890259\n",
      "Cost값은 : 1.8501580953598022\n",
      "Cost값은 : 1.8425102233886719\n",
      "Cost값은 : 1.840875267982483\n",
      "Cost값은 : 1.8267489671707153\n",
      "Cost값은 : 1.8580509424209595\n",
      "Cost값은 : 1.868349313735962\n",
      "Cost값은 : 1.8147225379943848\n",
      "Cost값은 : 1.7865662574768066\n",
      "Cost값은 : 1.8814197778701782\n",
      "Cost값은 : 1.8904718160629272\n",
      "Cost값은 : 1.8056442737579346\n",
      "Cost값은 : 1.8751933574676514\n",
      "Cost값은 : 1.850019097328186\n",
      "Cost값은 : 1.8679530620574951\n",
      "Cost값은 : 1.8463062047958374\n",
      "Cost값은 : 1.8301407098770142\n",
      "Cost값은 : 1.8383395671844482\n",
      "Cost값은 : 1.852585792541504\n",
      "Cost값은 : 1.812807559967041\n",
      "Cost값은 : 1.913063645362854\n",
      "Cost값은 : 1.8375580310821533\n",
      "Cost값은 : 1.8379954099655151\n",
      "Cost값은 : 1.8630402088165283\n",
      "Cost값은 : 1.880395531654358\n",
      "Cost값은 : 1.8822015523910522\n",
      "Cost값은 : 1.8251270055770874\n",
      "Cost값은 : 1.9052081108093262\n",
      "Cost값은 : 1.8617587089538574\n",
      "Cost값은 : 1.8175156116485596\n",
      "Cost값은 : 1.8522781133651733\n",
      "Cost값은 : 1.827065110206604\n",
      "Cost값은 : 1.8638516664505005\n",
      "Cost값은 : 1.8409696817398071\n",
      "Cost값은 : 1.8584189414978027\n",
      "Cost값은 : 1.8413283824920654\n",
      "Cost값은 : 1.8114477396011353\n",
      "Cost값은 : 1.8511040210723877\n",
      "Cost값은 : 1.8256090879440308\n",
      "Cost값은 : 1.858970284461975\n",
      "Cost값은 : 1.863211989402771\n",
      "Cost값은 : 1.8820074796676636\n",
      "Cost값은 : 1.8682818412780762\n",
      "Cost값은 : 1.8914860486984253\n",
      "Cost값은 : 1.8443210124969482\n",
      "Cost값은 : 1.8601950407028198\n",
      "Cost값은 : 1.8593767881393433\n",
      "Cost값은 : 1.8626415729522705\n",
      "Cost값은 : 1.8241840600967407\n",
      "Cost값은 : 1.8395483493804932\n",
      "Cost값은 : 1.8600997924804688\n",
      "Cost값은 : 1.926466703414917\n",
      "Cost값은 : 1.8620685338974\n",
      "Cost값은 : 1.849153995513916\n",
      "Cost값은 : 1.8996801376342773\n",
      "Cost값은 : 1.857064962387085\n",
      "Cost값은 : 1.7981390953063965\n",
      "Cost값은 : 1.8788179159164429\n",
      "Cost값은 : 1.8500339984893799\n",
      "Cost값은 : 1.818690538406372\n",
      "Cost값은 : 1.8519675731658936\n",
      "Cost값은 : 1.8530386686325073\n",
      "Cost값은 : 1.8662561178207397\n",
      "Cost값은 : 1.8913748264312744\n",
      "Cost값은 : 1.8228785991668701\n",
      "Cost값은 : 1.8558436632156372\n",
      "Cost값은 : 1.8972935676574707\n",
      "Cost값은 : 1.810843825340271\n",
      "Cost값은 : 1.8634576797485352\n",
      "Cost값은 : 1.8445509672164917\n",
      "Cost값은 : 1.8746110200881958\n",
      "Cost값은 : 1.8640377521514893\n",
      "Cost값은 : 1.9047166109085083\n",
      "Cost값은 : 1.8564034700393677\n",
      "Cost값은 : 1.8910167217254639\n",
      "Cost값은 : 1.8683133125305176\n",
      "Cost값은 : 1.8595126867294312\n",
      "Cost값은 : 1.874606966972351\n",
      "Cost값은 : 1.8613818883895874\n",
      "Cost값은 : 1.836641550064087\n",
      "Cost값은 : 1.8613308668136597\n",
      "Cost값은 : 1.8292824029922485\n",
      "Cost값은 : 1.8712314367294312\n",
      "Cost값은 : 1.8284839391708374\n",
      "Cost값은 : 1.8738868236541748\n",
      "Cost값은 : 1.864346981048584\n",
      "Cost값은 : 1.857669711112976\n",
      "Cost값은 : 1.8585410118103027\n",
      "Cost값은 : 1.8153272867202759\n",
      "Cost값은 : 1.8459640741348267\n",
      "Cost값은 : 1.8369308710098267\n",
      "Cost값은 : 1.8385436534881592\n",
      "Cost값은 : 1.8130288124084473\n",
      "Cost값은 : 1.841188669204712\n",
      "Cost값은 : 1.8107519149780273\n",
      "Cost값은 : 1.8513656854629517\n",
      "Cost값은 : 1.8639678955078125\n",
      "Cost값은 : 1.850450038909912\n",
      "Cost값은 : 1.8769265413284302\n",
      "Cost값은 : 1.816412329673767\n",
      "Cost값은 : 1.886765480041504\n",
      "Cost값은 : 1.8873807191848755\n",
      "Cost값은 : 1.8700023889541626\n",
      "Cost값은 : 1.8763363361358643\n",
      "Cost값은 : 1.8661551475524902\n",
      "Cost값은 : 1.8259304761886597\n",
      "Cost값은 : 1.8706004619598389\n",
      "Cost값은 : 1.8441479206085205\n",
      "Cost값은 : 1.873810887336731\n",
      "Cost값은 : 1.8572680950164795\n",
      "Cost값은 : 1.854455828666687\n",
      "Cost값은 : 1.896830439567566\n",
      "Cost값은 : 1.8482154607772827\n",
      "Cost값은 : 1.8518675565719604\n",
      "Cost값은 : 1.8880501985549927\n",
      "Cost값은 : 1.8946551084518433\n",
      "Cost값은 : 1.8568899631500244\n",
      "Cost값은 : 1.8145593404769897\n",
      "Cost값은 : 1.8327621221542358\n",
      "Cost값은 : 1.8797978162765503\n",
      "Cost값은 : 1.8817628622055054\n",
      "Cost값은 : 1.8493808507919312\n",
      "Cost값은 : 1.8317391872406006\n",
      "Cost값은 : 1.8461123704910278\n",
      "Cost값은 : 1.8107097148895264\n",
      "Cost값은 : 1.8277438879013062\n",
      "Cost값은 : 1.8596974611282349\n",
      "Cost값은 : 1.873576045036316\n",
      "Cost값은 : 1.8627820014953613\n",
      "Cost값은 : 1.8867886066436768\n",
      "Cost값은 : 1.8048495054244995\n",
      "Cost값은 : 1.9116061925888062\n",
      "Cost값은 : 1.9126754999160767\n",
      "Cost값은 : 1.823067307472229\n",
      "Cost값은 : 1.8600306510925293\n",
      "Cost값은 : 1.8502920866012573\n",
      "Cost값은 : 1.7983734607696533\n",
      "Cost값은 : 1.8359801769256592\n",
      "Cost값은 : 1.830177903175354\n",
      "Cost값은 : 1.859250545501709\n",
      "Cost값은 : 1.8279386758804321\n",
      "Cost값은 : 1.7931201457977295\n",
      "Cost값은 : 1.8796420097351074\n",
      "Cost값은 : 1.8786075115203857\n",
      "Cost값은 : 1.7926849126815796\n",
      "Cost값은 : 1.8314430713653564\n",
      "Cost값은 : 1.8721200227737427\n",
      "Cost값은 : 1.8634947538375854\n",
      "Cost값은 : 1.8112683296203613\n",
      "Cost값은 : 1.8805327415466309\n",
      "Cost값은 : 1.8724368810653687\n",
      "Cost값은 : 1.8774789571762085\n",
      "Cost값은 : 1.8895622491836548\n",
      "Cost값은 : 1.894484519958496\n",
      "Cost값은 : 1.84013032913208\n",
      "Cost값은 : 1.8919448852539062\n",
      "Cost값은 : 1.8499683141708374\n",
      "Cost값은 : 1.87458074092865\n",
      "Cost값은 : 1.8766096830368042\n",
      "Cost값은 : 1.9109389781951904\n",
      "Cost값은 : 1.8278902769088745\n",
      "Cost값은 : 1.8999873399734497\n",
      "Cost값은 : 1.8755226135253906\n",
      "Cost값은 : 1.8285951614379883\n",
      "Cost값은 : 1.8226573467254639\n",
      "Cost값은 : 1.8647924661636353\n",
      "Cost값은 : 1.8096356391906738\n",
      "Cost값은 : 1.8115588426589966\n",
      "Cost값은 : 1.8670004606246948\n",
      "Cost값은 : 1.8679972887039185\n",
      "Cost값은 : 1.8510491847991943\n",
      "Cost값은 : 1.8310154676437378\n",
      "Cost값은 : 1.8476883172988892\n",
      "Cost값은 : 1.8654637336730957\n",
      "Cost값은 : 1.851749300956726\n",
      "Cost값은 : 1.8946691751480103\n",
      "Cost값은 : 1.845767855644226\n",
      "Cost값은 : 1.790207862854004\n",
      "Cost값은 : 1.8623400926589966\n",
      "Cost값은 : 1.8838801383972168\n",
      "Cost값은 : 1.9028854370117188\n",
      "Cost값은 : 1.8523586988449097\n",
      "Cost값은 : 1.8416329622268677\n",
      "Cost값은 : 1.8936681747436523\n",
      "Cost값은 : 1.86460542678833\n",
      "Cost값은 : 1.8609130382537842\n",
      "Cost값은 : 1.892888069152832\n",
      "Cost값은 : 1.821944236755371\n",
      "Cost값은 : 1.8474293947219849\n",
      "Cost값은 : 1.9079350233078003\n",
      "Cost값은 : 1.8036091327667236\n",
      "Cost값은 : 1.8665199279785156\n",
      "Cost값은 : 1.8623045682907104\n",
      "Cost값은 : 1.809683084487915\n",
      "Cost값은 : 1.8864647150039673\n",
      "Cost값은 : 1.8114782571792603\n",
      "Cost값은 : 1.8938194513320923\n",
      "Cost값은 : 1.8193762302398682\n",
      "Cost값은 : 1.8771721124649048\n",
      "Cost값은 : 1.8411154747009277\n",
      "Cost값은 : 1.876208782196045\n",
      "Cost값은 : 1.8940162658691406\n",
      "Cost값은 : 1.8873040676116943\n",
      "Cost값은 : 1.8653836250305176\n",
      "Cost값은 : 1.8432183265686035\n",
      "Cost값은 : 1.8444023132324219\n",
      "Cost값은 : 1.8344911336898804\n",
      "Cost값은 : 1.8625370264053345\n",
      "Cost값은 : 1.8894964456558228\n",
      "Cost값은 : 1.8609968423843384\n",
      "Cost값은 : 1.8433129787445068\n",
      "Cost값은 : 1.8457525968551636\n",
      "Cost값은 : 1.8109848499298096\n",
      "Cost값은 : 1.8534899950027466\n",
      "Cost값은 : 1.8454746007919312\n",
      "Cost값은 : 1.8829777240753174\n",
      "Cost값은 : 1.8560912609100342\n",
      "Cost값은 : 1.877152681350708\n",
      "Cost값은 : 1.883499264717102\n",
      "Cost값은 : 1.8838222026824951\n",
      "Cost값은 : 1.843418002128601\n",
      "Cost값은 : 1.8190351724624634\n",
      "Cost값은 : 1.8516343832015991\n",
      "Cost값은 : 1.8701099157333374\n",
      "Cost값은 : 1.8646345138549805\n",
      "Cost값은 : 1.8252768516540527\n",
      "Cost값은 : 1.873623251914978\n",
      "Cost값은 : 1.8310579061508179\n",
      "Cost값은 : 1.8890163898468018\n",
      "Cost값은 : 1.7869518995285034\n",
      "Cost값은 : 1.8574795722961426\n",
      "Cost값은 : 1.8688702583312988\n",
      "Cost값은 : 1.8684762716293335\n",
      "Cost값은 : 1.826167106628418\n",
      "Cost값은 : 1.8316295146942139\n",
      "Cost값은 : 1.835227370262146\n",
      "Cost값은 : 1.87860906124115\n",
      "Cost값은 : 1.8863940238952637\n",
      "Cost값은 : 1.8490397930145264\n",
      "Cost값은 : 1.8084362745285034\n",
      "Cost값은 : 1.8982832431793213\n",
      "Cost값은 : 1.8190633058547974\n",
      "Cost값은 : 1.9096918106079102\n",
      "Cost값은 : 1.8808964490890503\n",
      "Cost값은 : 1.8434393405914307\n",
      "Cost값은 : 1.8559740781784058\n",
      "Cost값은 : 1.8435498476028442\n",
      "Cost값은 : 1.8480535745620728\n",
      "Cost값은 : 1.8616503477096558\n",
      "Cost값은 : 1.8420442342758179\n",
      "Cost값은 : 1.8574446439743042\n",
      "Cost값은 : 1.8795617818832397\n",
      "Cost값은 : 1.859447956085205\n",
      "Cost값은 : 1.8804562091827393\n",
      "Cost값은 : 1.8734664916992188\n",
      "Cost값은 : 1.8310978412628174\n",
      "Cost값은 : 1.9239462614059448\n",
      "Cost값은 : 1.8004958629608154\n",
      "Cost값은 : 1.8166203498840332\n",
      "Cost값은 : 1.8588699102401733\n",
      "Cost값은 : 1.8951058387756348\n",
      "Cost값은 : 1.8243992328643799\n",
      "Cost값은 : 1.8583489656448364\n",
      "Cost값은 : 1.8626266717910767\n",
      "Cost값은 : 1.8983043432235718\n",
      "Cost값은 : 1.8729641437530518\n",
      "Cost값은 : 1.8565020561218262\n",
      "Cost값은 : 1.8212172985076904\n",
      "Cost값은 : 1.8481111526489258\n",
      "Cost값은 : 1.8162283897399902\n",
      "Cost값은 : 1.8398947715759277\n",
      "Cost값은 : 1.866355538368225\n",
      "Cost값은 : 1.8628097772598267\n",
      "Cost값은 : 1.8380926847457886\n",
      "Cost값은 : 1.865012764930725\n",
      "Cost값은 : 1.8195908069610596\n",
      "Cost값은 : 1.8425332307815552\n",
      "Cost값은 : 1.8826881647109985\n",
      "Cost값은 : 1.8149850368499756\n",
      "Cost값은 : 1.8723535537719727\n",
      "Cost값은 : 1.8609601259231567\n",
      "Cost값은 : 1.9125981330871582\n",
      "Cost값은 : 1.8214646577835083\n",
      "Cost값은 : 1.8426073789596558\n",
      "Cost값은 : 1.8016901016235352\n",
      "Cost값은 : 1.857141137123108\n",
      "Cost값은 : 1.8829911947250366\n",
      "Cost값은 : 1.8716120719909668\n",
      "Cost값은 : 1.872963309288025\n",
      "Cost값은 : 1.8373684883117676\n",
      "Cost값은 : 1.8646774291992188\n",
      "Cost값은 : 1.8041043281555176\n",
      "Cost값은 : 1.8556737899780273\n",
      "Cost값은 : 1.8215386867523193\n",
      "Cost값은 : 1.8661291599273682\n",
      "Cost값은 : 1.8019572496414185\n",
      "Cost값은 : 1.8508782386779785\n",
      "Cost값은 : 1.8804268836975098\n",
      "Cost값은 : 1.8497053384780884\n",
      "Cost값은 : 1.7869430780410767\n",
      "Cost값은 : 1.8353580236434937\n",
      "Cost값은 : 1.9126590490341187\n",
      "Cost값은 : 1.8680185079574585\n",
      "Cost값은 : 1.8390021324157715\n",
      "Cost값은 : 1.8266091346740723\n",
      "Cost값은 : 1.918695330619812\n",
      "Cost값은 : 1.857810378074646\n",
      "Cost값은 : 1.8796931505203247\n",
      "Cost값은 : 1.8472814559936523\n",
      "Cost값은 : 1.819665551185608\n",
      "Cost값은 : 1.8223750591278076\n",
      "Cost값은 : 1.8523846864700317\n",
      "Cost값은 : 1.8351107835769653\n",
      "Cost값은 : 1.8753433227539062\n",
      "Cost값은 : 1.8448489904403687\n",
      "Cost값은 : 1.8008745908737183\n",
      "Cost값은 : 1.8657217025756836\n",
      "Cost값은 : 1.8436797857284546\n",
      "Cost값은 : 1.8710503578186035\n",
      "Cost값은 : 1.8804644346237183\n",
      "Cost값은 : 1.8858927488327026\n",
      "Cost값은 : 1.8451505899429321\n",
      "Cost값은 : 1.8662680387496948\n",
      "Cost값은 : 1.8542587757110596\n",
      "Cost값은 : 1.855800747871399\n",
      "Cost값은 : 1.778308391571045\n",
      "Cost값은 : 1.8142131567001343\n",
      "Cost값은 : 1.8493199348449707\n",
      "Cost값은 : 1.8189098834991455\n",
      "Cost값은 : 1.806052803993225\n",
      "Cost값은 : 1.857244610786438\n",
      "Cost값은 : 1.858402132987976\n",
      "Cost값은 : 1.8793997764587402\n",
      "Cost값은 : 1.8947577476501465\n",
      "Cost값은 : 1.8154581785202026\n",
      "Cost값은 : 1.8323493003845215\n",
      "Cost값은 : 1.8152765035629272\n",
      "Cost값은 : 1.8079525232315063\n",
      "Cost값은 : 1.8450654745101929\n",
      "Cost값은 : 1.842587947845459\n",
      "Cost값은 : 1.7985917329788208\n",
      "Cost값은 : 1.823824405670166\n",
      "Cost값은 : 1.8277767896652222\n",
      "Cost값은 : 1.8017489910125732\n",
      "Cost값은 : 1.887036919593811\n",
      "Cost값은 : 1.797061800956726\n",
      "Cost값은 : 1.841915488243103\n",
      "Cost값은 : 1.8918668031692505\n",
      "Cost값은 : 1.8363016843795776\n",
      "Cost값은 : 1.915838360786438\n",
      "Cost값은 : 1.8877297639846802\n",
      "Cost값은 : 1.8646031618118286\n",
      "Cost값은 : 1.833914041519165\n",
      "Cost값은 : 1.7830538749694824\n",
      "Cost값은 : 1.8480762243270874\n",
      "Cost값은 : 1.8379395008087158\n",
      "Cost값은 : 1.9045343399047852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost값은 : 1.87908935546875\n",
      "Cost값은 : 1.8772988319396973\n",
      "Cost값은 : 1.829431176185608\n",
      "Cost값은 : 1.8093311786651611\n",
      "Cost값은 : 1.838004469871521\n",
      "Cost값은 : 1.8204007148742676\n",
      "Cost값은 : 1.8519232273101807\n",
      "[[2 0 1 ... 3 9 2]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 학습 \n",
    "train_epoch = 50 \n",
    "batch_size = 100 \n",
    "for step in range(train_epoch):\n",
    "    num_of_iter = int( train_x_data.shape[0] / batch_size)\n",
    "    cost_val = 0\n",
    "    \n",
    "    for i in range(num_of_iter):\n",
    "        batch_x, batch_y = train_x_data[i*batch_size:i*batch_size+batch_size],train_y_data[i*batch_size:i*batch_size+batch_size] \n",
    "        \n",
    "        \n",
    "        _, cost_val = sess.run([train, cost], \n",
    "                               feed_dict={X:batch_x, #ndarray로 넣는 편이 좋다 \n",
    "                                          Y:batch_y})\n",
    "        if step % 50 == 0:\n",
    "            print(\"Cost값은 : {}\".format(cost_val))\n",
    "\n",
    "result = sess.run(tf.argmax(H,1), \n",
    "                  feed_dict = {X : test_mnist})\n",
    "print(np.array([result]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## retry\n",
    "## 모듈을 이용한 전처리\n",
    "#필요모듈 불러오기 \n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 원본데이터 불러오기 \n",
    "mnist = pd.read_csv(\"./data/digit-recognizer/train.csv\")\n",
    "\n",
    "#데이터 이원화, 분류 \n",
    "train_num = int(mnist.shape[0] * 0.8)\n",
    "test_num = mnist.shape[0] - train_num\n",
    "\n",
    "train_data = mnist[:train_num]\n",
    "test_data = mnist[train_num:]\n",
    "\n",
    "#정의역, 공역 데이터 생성\n",
    "\n",
    "#train x,y 데이터 \n",
    "train_x_data = mnist.drop(\"label\", axis = 1, inplace = False)[:train_num].values\n",
    "test_x_data = mnist.drop(\"label\",axis = 1, inplace = False)[train_num:].values\n",
    "\n",
    "#train x,y 데이터\n",
    "train_y_data = mnist['label'][:train_num].values\n",
    "test_y_data = mnist['label'][train_num:].values \n",
    "\n",
    "#학습을 위한 정규화(x데이터)\n",
    "scaler = MinMaxScaler()\n",
    "train_x_data = scaler.fit_transform(train_x_data)\n",
    "test_x_data=scaler.fit_transform(test_x_data)\n",
    "\n",
    "#더미변수화(One-hot Encoding, y데이터 )\n",
    "train_y_data = pd.get_dummies(train_y_data)\n",
    "test_y_data = pd.get_dummies(test_y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33595</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33596</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33597</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33598</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33599</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33600 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1  2  3  4  5  6  7  8  9\n",
       "0      0  1  0  0  0  0  0  0  0  0\n",
       "1      1  0  0  0  0  0  0  0  0  0\n",
       "2      0  1  0  0  0  0  0  0  0  0\n",
       "3      0  0  0  0  1  0  0  0  0  0\n",
       "4      1  0  0  0  0  0  0  0  0  0\n",
       "...   .. .. .. .. .. .. .. .. .. ..\n",
       "33595  0  0  0  0  0  0  1  0  0  0\n",
       "33596  1  0  0  0  0  0  0  0  0  0\n",
       "33597  1  0  0  0  0  0  0  0  0  0\n",
       "33598  0  0  1  0  0  0  0  0  0  0\n",
       "33599  0  0  1  0  0  0  0  0  0  0\n",
       "\n",
       "[33600 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_x_data)\n",
    "display(type(train_x_data)) #numpy.ndarray\n",
    "display(train_y_data)\n",
    "display(type(train_y_data)) #pandas.core.frame.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow로 machine learning\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,784], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None,10], dtype=tf.float32)\n",
    "\n",
    "# Weight & bias\n",
    "W = tf.Variable(tf.random_normal([784,10]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([10]), name=\"bias\")\n",
    "\n",
    "# Hypothesis\n",
    "logit = tf.matmul(X,W) + b\n",
    "H = tf.nn.softmax(logit)\n",
    "\n",
    "# Cost\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit,\n",
    "                                                                labels=Y))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# session, 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost값은: 1.9066394567489624\n",
      "Cost값은: 0.5986630916595459\n",
      "Cost값은: 0.4995289742946625\n",
      "Cost값은: 0.46032989025115967\n",
      "Cost값은: 0.4372672140598297\n",
      "Cost값은: 0.4207300841808319\n",
      "Cost값은: 0.407909631729126\n",
      "Cost값은: 0.39765632152557373\n",
      "Cost값은: 0.3892902433872223\n",
      "Cost값은: 0.3823453485965729\n"
     ]
    }
   ],
   "source": [
    "# 학습 (batch 이용)\n",
    "train_epoch = 300\n",
    "batch_size = 100\n",
    "\n",
    "for step in range(train_epoch):\n",
    "    num_of_iter = int(train_num/batch_size) #전체행 / batch_size\n",
    "    cost_val = 0\n",
    "    for i in range(num_of_iter):\n",
    "        batch_x = train_x_data[i*batch_size : (i+1)*batch_size]\n",
    "        batch_y = train_y_data[i*batch_size : (i+1)*batch_size]\n",
    "        _,cost_val = sess.run([train,cost],\n",
    "                             feed_dict = {X:batch_x,\n",
    "                                          Y:batch_y})\n",
    "    if step % 30 == 0:\n",
    "        print(\"Cost값은: {}\".format(cost_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도는 : 0.9177380800247192\n"
     ]
    }
   ],
   "source": [
    "# 정확도 측정 (test데이터 기반으로)\n",
    "predict = tf.argmax(H, 1)\n",
    "correct = tf.equal(predict, tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype = tf.float32))\n",
    "print(\"정확도는 : {}\".format(sess.run(accuracy,\n",
    "                                     feed_dict = {X: test_x_data,\n",
    "                                                  Y: test_y_data})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label : [1]\n",
      "Predict :[1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e9388cc780>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prediction\n",
    "# 랜덤으로 하나의 데이터를 추출해서 그놈을 이용해서 prediction을 한 후 결과를 비교해 보자\n",
    "\n",
    "r = np.random.randint(0,test_num) # mnist.test.num_examples = 10000\n",
    "\n",
    "print(\"Label : {}\".format(sess.run(tf.argmax(test_y_data[r:r+1], axis=1))))\n",
    "\n",
    "print(\"Predict :{}\".format(sess.run(tf.argmax(H,1), \n",
    "         feed_dict={X:test_x_data[r:r+1]})))    # 2차원\n",
    "\n",
    "plt.imshow(test_x_data[r:r+1].reshape(28,28), cmap=\"Greys\")\n",
    "# 1,784 => 28,28로 바꿀거야"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 9, ..., 3, 9, 2], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 진짜 test 파일로 돌려보자!!\n",
    "\n",
    "test_data = pd.read_csv(\"./data/digit-recognizer/test.csv\")\n",
    "\n",
    "# MinMax scaler가 min, max값 가지고 있다.\n",
    "prediction_data = scaler.transform(test_data)\n",
    "\n",
    "#sess.run(H,feed_dict={X:prediction_data})\n",
    "result = sess.run(tf.argmax(H,1), feed_dict={X:prediction_data})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#결과 출력 내용 -> df -> .csv로 만들자\n",
    "my_df = pd.DataFrame()\n",
    "my_df[\"ImageId\"] = range(1,test_data.shape[0]+1)\n",
    "my_df[\"Label\"] = result\n",
    "my_df #(28000, 2)\n",
    "\n",
    "my_df.to_csv(\"mnist_submission.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[CPU_ENV]",
   "language": "python",
   "name": "cpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
