{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CNN(Convolution Neural Network) 이란? : 합성곱 신경망 \n",
    "## FC Layer(Fully Connected Layer) : \n",
    "## 이전 layer의 모든 node가 다음 layer의 모든 perceptron 과 실제로 연결되어서 \n",
    "## 학습되는 구조 -> 지금까지(사실 37강때 처음으로) 해왔던 신경망들이 해당\n",
    "## FC Layer를 다른말로 Dense Layer라고도 한다. \n",
    "\n",
    "## FC Layer의 특징은 MNIST의 예제처럼 입력데이터가 1차원으로 한정된다. \n",
    "## 즉, 각각의 이미지가 1차원으로 표현이 되어야 한다. \n",
    "## 그래서 2차원 이미지를 우리가 1차원으로 변환시켜서 사용했던 것\n",
    "## 우리가 사용한 MNIST예제는 상당히 간단한 이미지 학습(grey형태의 채도 일변도, 예측예제)\n",
    "\n",
    "## 이미지 학습의 가장 큰 문제는 \n",
    "## 이미지가 살짝 휘어있거나, 크기가 제각각이거나, 변형이 조금만 되어도 \n",
    "## 학습이 힘들어진다. \n",
    "## 이런 경우에는 training data가 굉장히 많이 필요하고 \n",
    "## 추가적으로 학습할 때 많은 시간을 요구함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 고민하면서 방법을 연구하기 시작함 -> Canada의 Supervision이란 팀이 실마리를 제공함 \n",
    "## CNN을 최초 제시하면서 오차율을 큰 폭으로 줄임 -> 지금은 사람보다 정확한 경지 \n",
    "## CNN은 사람이 학습하는 방식을 모델링 \n",
    "## 사람은 대상이 변형이 있어도 사진을 보고 누군가의 사진임을 알 수 있다.(특징을 인지)\n",
    "## (물론 너무 속이면 못알아볼 수 도 있다.-> 마찬가지로 왜곡되지 않는 특징 추출)\n",
    "\n",
    "## mnist가 특정 사진을 픽셀단위로 핀다음 한번만 학습했다면, \n",
    "## CNN은 여러가지 필터를 적용해서 사진을 다른 형태로 변형한 후 \n",
    "## 도드라진 특징을 가지고 한 이미지를 여러번 학습(Photoshop 의 shapen) \n",
    "## → 이미지를 대표하는 특징을 도출해서 신경망에 여러개 넣어서 학습하는 방식(convolution)\n",
    "\n",
    "## 1장의 컬러사진은 width, length, color(depth) 3차원으로 표현 \n",
    "## 여기서 여러장의 사진이 사용되기 때문에 입력데이터를 총 '4차원' 으로 표현 \n",
    "\n",
    "## 실제 이미지 1장은 3차원이고 이놈을 flatten 시켜서 1차원으로 표현해야 한다. \n",
    "## 크기를 조절해야 하기 때문에 공간에 대한 데이터를 유실할 우려가 있음 \n",
    "## 이런 데이터 유실 때문에 학습과 예측에 문제가 발생하게된다.\n",
    "\n",
    "## '공간데이터의 유실을 없애고 이미지의 특성을 추출해서 학습이 용이하게 만드는 방식'\n",
    "## => CNN\n",
    "\n",
    "## 랜덤크기의 필터(kernel)를 하나 만들고 3차원 이미지 데이터에 적용 -> 당연히 필터도 3차원 \n",
    "## mnist의 depth는 원본의 depth 와 똑같아야 했던 것처럼. (grey 1개)\n",
    "## 이 필터 표현 방식을 channel 이라고 지칭(일반적으로 3 channel, 흑백사진은 1 channel)\n",
    "## 행렬곱을 통해서 결과를 도출 (convolution map)\n",
    "## 원본데이터의 사이즈는줄더라도 작은 이미지의 많은 수로 형성되게 됨 \n",
    "## 여러가지 feature map이 모이면 activation map 이라고 함. \n",
    "## kernal, channel, feature map,activation map, strider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code로 알아봅시당 \n",
    "## 사용되어 지는 함수부터 알아보자\n",
    "## Sample CNN\n",
    "\n",
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "\n",
    "#입력데이터의 형식 : 3*3*1 (width * height * color(색이 1이면 gray scale))\n",
    "#입력 데이터 => (이미지개수,width,height,color) = (1,3,3,1) #총 4차원 \n",
    "# 총 9개의 데이터가 사용(1~9)\n",
    "\n",
    "image = np.array([[[[1],[2],[3]],\n",
    "                   [[4],[5],[6]],\n",
    "                   [[7],[8],[9]]]], dtype=np.float32)\n",
    "\n",
    "print(\"image의 shape : {}\".format(image.shape)) #(1,3,3,1)\n",
    "\n",
    "# Activation map을 위한 filter를 정의(width.height.color.filter개수)\n",
    "# filter(2,2,1,3) : 2행 2열 1컬러 3개\n",
    "weight = np.array([[[[1,10,-1]],[[1,10,-1]]],[[[1,10,-1]],[[1,10,-1]]]])\n",
    "print(\"weight의 shape : {}\".format(weight.shape)) #(2, 2, 1, 3)\n",
    "\n",
    "## convolution latyer\n",
    "# stride = 1 :가로, 세로를 1씩 움직인다 \n",
    "conv2d = tf.nn.conv2d(image,weight,strides=[1,1,1,1], padding = \"VALID\" ) \n",
    "#4차원이므로 stride 형태를 맞추어주어야 한다.\n",
    "#처음과 맨끝은 더미(형태 맞춰주기 위한 쩌리), 핵심은 가운데 2개 \n",
    "# 패딩 설정도 가능하다 (여기선 처리 안하고 알아서 줄일거)\n",
    "print(\"conv2d의 shape : {}\".format(conv2d.shape)) #(1, 2, 2, 3) 맨앞은 이미지 1장 \n",
    "sess = tf.Session()\n",
    "conv2d = sess.run(conv2d) #실행결과 numpy array로 \n",
    "\n",
    "## pooling layer\n",
    "pool = tf.nn.max_pool(conv2d, ksize = [1,2,2,1], \n",
    "                      strides = [1,1,1,1], \n",
    "                      padding = \"SAME\")\n",
    "#kernel사이즈 결정 (2x2),나머지 더미\n",
    "#stride는 한칸씩 \n",
    "#원본크기와 padding size 동일하게 \n",
    "print(\"pool의 shape : {}\".format(pool.shape)) #(1,2,2,3), conv2d와 동일 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tf 내장 MNIST 사용\n",
    "## Convolution 결과 이미지가 원본이미지에 비해 어떻게 다른지 눈으로 확인해보자 \n",
    "import tensorflow as tf \n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "#Data Loading \n",
    "mnist = input_data.read_data_sets(\"./data/mnist\", one_hot=True)\n",
    "img = mnist.train.images[0].reshape(28,28)\n",
    "plt.imshow(img, cmap=\"Greys\")\n",
    "\n",
    "# 해당 이미지를 Convolution 처리를 해 보아요 \n",
    "# 입력데이터 -> (이미지개수, width, height, color) -> (1,3,3,1)\n",
    "img = img.reshape(-1,28,28,1)\n",
    "print(img.shape) #(1, 28, 28, 1)\n",
    "W = tf.Variable(tf.random_normal([3,3,1,5]),\n",
    "                                 name = \"filter1\") #너비, 높이, 컬러 depth, 개수\n",
    "conv2d = tf.nn.conv2d(img,W,strides=[1,2,2,1],\n",
    "                      padding = \"SAME\") #stride 2칸씩 뒴\n",
    "print(\"conv2d의 shape : {}\".format(conv2d.shape)) #(1,14,14,5)\n",
    "\n",
    "# 세션 초기화 \n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "conv2d = sess.run(conv2d)\n",
    "\n",
    "# 이미지를 표현하기 위해서 축을 전환 \n",
    "# numpy 자체 기능 활용\n",
    "# (1, 14, 14, 5) => (5, 14, 14, 1)\n",
    "conv2d_img = np.swapaxes(conv2d,0,3) #첫번째랑 네번째 거 바꿈\n",
    "print(\"conv2d의 shape : {}\".format(conv2d_img.shape)) #(5,14,14,1)\n",
    "plt.imshow(conv2d_img[0].reshape(14,14), cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 내장 MNIST 데이터에 CNN 학습을 적용해보자! \n",
    "## tensorflow-MNIST with CNN\n",
    "\n",
    "# module loading\n",
    "import tensorflow as tf \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# Data Loading\n",
    "mnist = input_data.read_data_sets(\"./data/mnist\", one_hot=True)\n",
    "\n",
    "#Graph 초기화 \n",
    "tf.reset_default_graph()\n",
    "\n",
    "#Placeholder \n",
    "X = tf.placeholder(shape=[None,784], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None,10], dtype=tf.float32)\n",
    "# drop_rate = tf.placeholder(dtype = tf.float32)\n",
    "\n",
    "# Convolution Layer \n",
    "x_img = tf.reshape(X,[-1,28,28,1])\n",
    "W1 = tf.Variable(tf.random_normal([3,3,1,32]))\n",
    "L1 = tf.nn.conv2d(x_img,W1,strides=[1,1,1,1],padding=\"SAME\")\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.max_pool(L1,ksize=[1,2,2,1], \n",
    "                    strides=[1,2,2,1],\n",
    "                    padding = \"SAME\") #maxpooling을 통한 사이즈 반토막 (14*14)\n",
    "\n",
    "# 두번째 C.layer부턴 확 늘려보자 \n",
    "W2 = tf.Variable(tf.random_normal([3,3,32,64]))\n",
    "L2 = tf.nn.conv2d(L1,W2,strides=[1,1,1,1],padding=\"SAME\")\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2,ksize=[1,2,2,1], \n",
    "                    strides=[1,2,2,1],\n",
    "                    padding = \"SAME\") \n",
    "\n",
    "################################\n",
    "\n",
    "## FC Layer\n",
    "# 만든 데이터를 FC Layer에 넣어서 학습하자(이전에 했던 학습 형태 -> L2가 2차원)\n",
    "L2 = tf.reshape(L2,[-1,7*7*64])\n",
    "\n",
    "W3 = tf.get_variable(\"weight3\",shape=[7*7*64, 256],\n",
    "                     initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "#~~\n",
    "b3 = tf.Variable(tf.random_normal([256]), name = \"bias3\")      \n",
    "L3 = tf.sigmoid(tf.matmul(L2,W3) + b3)\n",
    "\n",
    "W4 = tf.Variable(tf.random_normal([256,10]), name = \"weight4\") \n",
    "b4 = tf.Variable(tf.random_normal([10]), name = \"bias4\")      \n",
    "\n",
    "# Hypothesis \n",
    "logit = tf.matmul(L3,W4) + b4 \n",
    "H = tf.nn.softmax(logit) #or tf.sigmoid()\n",
    "\n",
    "# cost\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = logit,\n",
    "                                                                 labels = Y))\n",
    "\n",
    "# train(Adam으로)\n",
    "train = tf.train.AdamOptimizer(learning_rate = 0.01).minimize(cost)\n",
    "#train = tf.train.GradientDescentOptimizer(learning_rate = 0.01).minimize(cost)\n",
    "\n",
    "# session, 초기화 \n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습 \n",
    "num_of_epoch = 30 \n",
    "batch_size = 100 \n",
    "\n",
    "for step in range(num_of_epoch):\n",
    "    num_of_iter = int(mnist.train.num_examples / batch_size)\n",
    "    cost_val = 0 # 코스트 초기화(국룰)\n",
    "    \n",
    "    for i in range(num_of_iter):\n",
    "        batch_x,batch_y = mnist.train.next_batch(batch_size)\n",
    "        _, cost_val = sess.run([train,cost], feed_dict={X:batch_x, \n",
    "                                                        Y:batch_y})\n",
    "    if step % 3 == 0 :\n",
    "        print(\"Cost는 : {}\".format(cost_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = tf.argmax(H,1)\n",
    "correct = tf.equal(predict, tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "print(\"정확도는 : {}\".format(sess.run(accuracy, \n",
    "                                   feed_dict={X:mnist.test.images, \n",
    "                                              Y:mnist.test.labels})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33600, 784)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(33600, 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(8400, 784)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(8400, 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 실제 Kaggle 데이터에 CNN 학습을 적용해보자!\n",
    "# 필요한 module import\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings \n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "warnings.filterwarnings(action = \"ignore\") # warning 출력 방지 \n",
    "\n",
    "# Data Loading\n",
    "mnist = pd.read_csv(\"./data/digit-recognizer/train.csv\")\n",
    "\n",
    "\n",
    "train_num = int(mnist.shape[0] * 0.8)   \n",
    "test_num = mnist.shape[0] - train_num\n",
    "\n",
    "train_data=mnist[:train_num]\n",
    "test_data=mnist[train_num:]\n",
    "\n",
    "# train, test data set\n",
    "train_x_data = mnist.drop(\"label\",axis=1, inplace=False)[:train_num].values\n",
    "test_x_data = mnist.drop(\"label\",axis=1, inplace=False)[train_num:].values\n",
    "\n",
    "train_y_data = mnist['label'][:train_num].values\n",
    "test_y_data = mnist['label'][train_num:].values\n",
    "\n",
    "# 값이 너무 크니 minmax scale \n",
    "scaler= MinMaxScaler()\n",
    "train_x_data = scaler.fit_transform(train_x_data)\n",
    "test_x_data = scaler.fit_transform(test_x_data)\n",
    "\n",
    "# 더미변수로 바꿔주기\n",
    "train_y_data = pd.get_dummies(train_y_data) \n",
    "test_y_data = pd.get_dummies(test_y_data) \n",
    "\n",
    "display(train_x_data.shape, train_y_data.shape, \n",
    "        test_x_data.shape, test_y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# 3rd Convolution Layer \\nc_W3 = tf.Variable(tf.random_normal([3,3,64,64]))\\nc_L3 = tf.nn.conv2d(c_L2,c_W3,strides=[1,1,1,1],padding=\"SAME\")\\nc_L3 = tf.nn.relu(c_L2)\\nc_L3 = tf.nn.max_pool(c_L3,ksize=[1,2,2,1], \\n                      strides=[1,2,2,1],\\n                      padding = \"SAME\") \\n################################\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Graph 초기화 \n",
    "tf.reset_default_graph()\n",
    "\n",
    "#Placeholder \n",
    "X = tf.placeholder(shape=[None,784], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None,10], dtype=tf.float32)\n",
    "# drop_rate = tf.placeholder(dtype = tf.float32)\n",
    "\n",
    "## Convolution Layer\n",
    "# 1st Convolution Layer \n",
    "x_img = tf.reshape(X,[-1,28,28,1])\n",
    "c_W1 = tf.Variable(tf.random_normal([3,3,1,32]))\n",
    "c_L1 = tf.nn.conv2d(x_img,c_W1,strides=[1,1,1,1],padding=\"SAME\")\n",
    "c_L1 = tf.nn.relu(c_L1)\n",
    "c_L1 = tf.nn.max_pool(c_L1,ksize=[1,2,2,1], \n",
    "                    strides=[1,2,2,1],\n",
    "                    padding = \"SAME\") #maxpooling을 통한 사이즈 반토막 (14*14)\n",
    "\n",
    "# 2nd Convolution Layer \n",
    "c_W2 = tf.Variable(tf.random_normal([3,3,32,64]))\n",
    "c_L2 = tf.nn.conv2d(c_L1,c_W2,strides=[1,1,1,1],padding=\"SAME\")\n",
    "c_L2 = tf.nn.relu(c_L2)\n",
    "c_L2 = tf.nn.max_pool(c_L2,ksize=[1,2,2,1], \n",
    "                      strides=[1,2,2,1], \n",
    "                      padding = \"SAME\") \n",
    "'''\n",
    "# 3rd Convolution Layer \n",
    "c_W3 = tf.Variable(tf.random_normal([3,3,64,64]))\n",
    "c_L3 = tf.nn.conv2d(c_L2,c_W3,strides=[1,1,1,1],padding=\"SAME\")\n",
    "c_L3 = tf.nn.relu(c_L2)\n",
    "c_L3 = tf.nn.max_pool(c_L3,ksize=[1,2,2,1], \n",
    "                      strides=[1,2,2,1],\n",
    "                      padding = \"SAME\") \n",
    "################################\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost값은: 0.5784896612167358\n",
      "Cost값은: 0.0388200581073761\n",
      "Cost값은: 0.024859758093953133\n",
      "Cost값은: 0.014755375683307648\n",
      "Cost값은: 0.012241256423294544\n",
      "Cost값은: 0.004170374479144812\n",
      "Cost값은: 0.007692200597375631\n",
      "Cost값은: 0.1492687463760376\n",
      "Cost값은: 0.0006811046041548252\n",
      "Cost값은: 0.028345884755253792\n"
     ]
    }
   ],
   "source": [
    "## FC Layer\n",
    "\n",
    "#Layer 형태 변화(4차원 -> 2차원)\n",
    "reshaped_Layer = tf.reshape(c_L2,[-1,7*7*64])\n",
    "\n",
    "#1st Layer(relu사용)\n",
    "fc_W1 = tf.get_variable(\"Fully_Connected_Weight1\",shape=[7*7*64, 256],\n",
    "                       initializer = tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([256]), name = \"bias1\")\n",
    "fc_L1 = tf.nn.relu(tf.matmul(reshaped_Layer,fc_W1) + b1)\n",
    "\n",
    "#2nd Layer\n",
    "fc_W2 = tf.get_variable(\"Fully_Connected_Weight2\", shape=[256, 256], \n",
    "                        initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([256]), name = \"bias2\")      \n",
    "fc_L2 = tf.nn.relu(tf.matmul(fc_L1,fc_W2) + b2)\n",
    "\n",
    "#3rd Layer\n",
    "fc_W3 = tf.get_variable(\"Fully_Connected_Weight3\", shape=[256, 36], \n",
    "                        initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([36]), name = \"bias3\")      \n",
    "fc_L3 = tf.nn.relu(tf.matmul(fc_L2,fc_W3) + b3)\n",
    "\n",
    "#4th Layer\n",
    "fc_W4 = tf.get_variable(\"Fully_Connected_Weight4\", shape=[36,10],\n",
    "                        initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([10]), name = \"bias4\")\n",
    "\n",
    "# Hypothesis \n",
    "logit = tf.matmul(fc_L3,fc_W4) + b4 \n",
    "H = tf.nn.softmax(logit) #or tf.sigmoid()\n",
    "\n",
    "# cost\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = logit,\n",
    "                                                                 labels = Y))\n",
    "\n",
    "# train(Adam으로)\n",
    "train = tf.train.AdamOptimizer(learning_rate = 0.001).minimize(cost)\n",
    "#train = tf.train.GradientDescentOptimizer(learning_rate = 0.01).minimize(cost)\n",
    "\n",
    "# session, 초기화 \n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "train_epoch = 30\n",
    "batch_size = 100\n",
    "\n",
    "for step in range(train_epoch):\n",
    "    num_of_iter = int(train_num / batch_size)    \n",
    "    cost_val = 0\n",
    "    \n",
    "    for i in range(num_of_iter):\n",
    "        batch_x=train_x_data[i*batch_size:(i+1)*batch_size]\n",
    "        batch_y=train_y_data[i*batch_size:(i+1)*batch_size]\n",
    "        _,cost_val = sess.run([train,cost],\n",
    "                             feed_dict={X:batch_x,\n",
    "                                        Y:batch_y})\n",
    "    if step % 3 ==0:\n",
    "        print(\"Cost값은: {}\".format(cost_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도는 : 0.9873809814453125\n"
     ]
    }
   ],
   "source": [
    "#정확도 측정 \n",
    "\n",
    "predict = tf.argmax(H,1)\n",
    "correct = tf.equal(predict, tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype = tf.float32))\n",
    "print(\"정확도는 : {}\".format(sess.run(accuracy, \n",
    "                                  feed_dict={X:test_x_data,\n",
    "                                             Y:test_y_data})))\n",
    "# 얼마나 학습이 잘 되었는가\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label : [6]\n",
      "Predict :[6]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2229075d160>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 직접확인 \n",
    "r = np.random.randint(0,test_num) # mnist.test.num_examples = 10000\n",
    "print(\"Label : {}\".format(sess.run(tf.argmax(test_y_data[r:r+1], axis=1))))\n",
    "\n",
    "print(\"Predict :{}\".format(sess.run(tf.argmax(H,1), \n",
    "         feed_dict={X:test_x_data[r:r+1]})))    # 2차원\n",
    "\n",
    "plt.imshow(test_x_data[r:r+1].reshape(28,28), cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 9, ..., 3, 9, 2], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 진짜 test 파일로 돌려보자\n",
    "test_data = pd.read_csv(\"./data/digit-recognizer/test.csv\")\n",
    "\n",
    "# MinMax scaler가 min, max값 가지고 있다.\n",
    "prediction_data = scaler.transform(test_data)\n",
    "\n",
    "#sess.run(H,feed_dict={X:prediction_data})\n",
    "result = sess.run(tf.argmax(H,1), feed_dict={X:prediction_data})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27995</th>\n",
       "      <td>27996</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27996</th>\n",
       "      <td>27997</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27997</th>\n",
       "      <td>27998</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27998</th>\n",
       "      <td>27999</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27999</th>\n",
       "      <td>28000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ImageId  Label\n",
       "0            1      2\n",
       "1            2      0\n",
       "2            3      9\n",
       "3            4      0\n",
       "4            5      3\n",
       "...        ...    ...\n",
       "27995    27996      9\n",
       "27996    27997      7\n",
       "27997    27998      3\n",
       "27998    27999      9\n",
       "27999    28000      2\n",
       "\n",
       "[28000 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#파일생성\n",
    "my_df = pd.DataFrame()\n",
    "my_df[\"ImageId\"] = range(1,test_data.shape[0]+1)\n",
    "my_df[\"Label\"] = result\n",
    "my_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df.to_csv(\"./data/digit-recognizer/mnist_submission.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[CPU_ENV]",
   "language": "python",
   "name": "cpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
