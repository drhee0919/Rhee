{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "## MNIST with Neural Network(DEEP Learning) \n",
    "## MNIST 문제를 딥러닝을 사용해서 정확도를 높혀보자\n",
    "## tensorflow가 기본으로 제공하는 예제를 이용해서 구현하기 \n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import warnings \n",
    "\n",
    "warnings.filterwarnings(action = \"ignore\") # warning 출력 방지 \n",
    "\n",
    "# Data Loading \n",
    "mnist = input_data.read_data_sets(\"./data/mnist\",one_hot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost는 : 3.5787243843078613\n",
      "Cost는 : 0.5145321488380432\n",
      "Cost는 : 0.36675402522087097\n",
      "Cost는 : 0.25307580828666687\n",
      "Cost는 : 0.23830538988113403\n",
      "Cost는 : 0.3348872661590576\n"
     ]
    }
   ],
   "source": [
    "# Placeholder \n",
    "X = tf.placeholder(shape=[None, 784], dtype = tf.float32)\n",
    "Y = tf.placeholder(shape=[None, 10], dtype = tf.float32)\n",
    "\n",
    "# Weight & bias( Deep & Wide ) \n",
    "W1 = tf.Variable(tf.random_normal([784,256]), name = \"weight\") # 뒷'열'(perceptron)은 내가 잡고 싶은 대로 조정\n",
    "b1 = tf.Variable(tf.random_normal([256]), name = \"bias\")       # 단 depth 가 깊으면 깊을수록 처리하기 곤란해진다\n",
    "layer1 = tf.sigmoid(tf.matmul(X,W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([256,256]), name = \"weight2\") \n",
    "b2 = tf.Variable(tf.random_normal([256]), name = \"bias2\")      \n",
    "layer2 = tf.sigmoid(tf.matmul(layer1,W2) + b2)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([256,10]), name = \"weight3\") \n",
    "b3 = tf.Variable(tf.random_normal([10]), name = \"bias3\")      \n",
    "layer3 = tf.sigmoid(tf.matmul(layer2,W3) + b3)\n",
    "\n",
    "\n",
    "# Hypothesis \n",
    "logit = tf.matmul(layer2,W3) + b3 \n",
    "H = tf.nn.softmax(logit) #or tf.sigmoid()\n",
    "\n",
    "# cost\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = logit,\n",
    "                                                                 labels = Y))\n",
    "\n",
    "# train \n",
    "train = tf.train.GradientDescentOptimizer(learning_rate = 0.01).minimize(cost)\n",
    "\n",
    "# session, 초기화 \n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습 \n",
    "num_of_epoch = 300 \n",
    "batch_size = 100 \n",
    "\n",
    "for step in range(num_of_epoch):\n",
    "    num_of_iter = int(mnist.train.num_examples / batch_size)\n",
    "    cost_val = 0 # 코스트 초기화(국룰)\n",
    "    \n",
    "    for i in range(num_of_iter):\n",
    "        batch_x,batch_y = mnist.train.next_batch(batch_size)\n",
    "        _, cost_val = sess.run([train,cost], feed_dict={X:batch_x, \n",
    "                                                        Y:batch_y})\n",
    "    if step % 30 == 0 :\n",
    "        print(\"Cost는 : {}\".format(cost_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = tf.argmax(H,1)\n",
    "correct = tf.equal(predict, tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "print(\"정확도는 : {}\".format(sess.run(accuracy, \n",
    "                                   feed_dict={X:mnist.test.images, \n",
    "                                              Y:mnist.test.labels})))\n",
    "# 정확도가 뛰어나지 않다?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 생각보다 정확도가 많이 향상되지 않았다! \n",
    "## Hinton교수가 원인을 파악하고자 노력했다. \n",
    "## deep learning이 좀더 학습이 잘 되기 위해선 layer를 추가하고 각 layer에 많은 perceptron을 추가해서 구현 \n",
    "import tensorflow as tf \n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import warnings \n",
    "\n",
    "warnings.filterwarnings(action = \"ignore\") # warning 출력 방지 \n",
    "\n",
    "# Data Loading \n",
    "mnist = input_data.read_data_sets(\"./data/mnist\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost는 : 15.567130088806152\n",
      "Cost는 : 13.164533615112305\n",
      "Cost는 : 1.4235243797302246\n",
      "Cost는 : 5.230926513671875\n",
      "Cost는 : 2.595508337020874\n",
      "Cost는 : 0.20217889547348022\n",
      "Cost는 : 0.014959617517888546\n",
      "Cost는 : 1.2006701581412926e-05\n",
      "Cost는 : 0.06828956305980682\n",
      "Cost는 : 0.025428257882595062\n"
     ]
    }
   ],
   "source": [
    "#그래프 초기화 \n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Placeholder \n",
    "X = tf.placeholder(shape=[None, 784], dtype = tf.float32)\n",
    "Y = tf.placeholder(shape=[None, 10], dtype = tf.float32)\n",
    "\n",
    "# Weight & bias( Deep & Wide ) \n",
    "W1 = tf.Variable(tf.random_normal([784,256]), name = \"weight\") # 뒷'열'(perceptron)은 내가 잡고 싶은 대로 조정\n",
    "b1 = tf.Variable(tf.random_normal([256]), name = \"bias\")       # 단 depth 가 깊으면 깊을수록 처리하기 곤란해진다\n",
    "layer1 = tf.nn.relu(tf.matmul(X,W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([256,256]), name = \"weight2\") \n",
    "b2 = tf.Variable(tf.random_normal([256]), name = \"bias2\")      \n",
    "layer2 = tf.nn.relu(tf.matmul(layer1,W2) + b2)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([256,10]), name = \"weight3\") \n",
    "b3 = tf.Variable(tf.random_normal([10]), name = \"bias3\")      \n",
    "layer3 = tf.nn.relu(tf.matmul(layer2,W3) + b3)\n",
    "\n",
    "\n",
    "# Hypothesis \n",
    "logit = tf.matmul(layer2,W3) + b3 \n",
    "H = tf.nn.relu(logit) #or tf.sigmoid()\n",
    "\n",
    "# cost\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = logit,\n",
    "                                                                 labels = Y))\n",
    "\n",
    "# train \n",
    "train = tf.train.GradientDescentOptimizer(learning_rate = 0.01).minimize(cost)\n",
    "\n",
    "# session, 초기화 \n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습 \n",
    "num_of_epoch = 30\n",
    "batch_size = 100 \n",
    "\n",
    "for step in range(num_of_epoch):\n",
    "    num_of_iter = int(mnist.train.num_examples / batch_size)\n",
    "    cost_val = 0 # 코스트 초기화(국룰)\n",
    "    \n",
    "    for i in range(num_of_iter):\n",
    "        batch_x,batch_y = mnist.train.next_batch(batch_size)\n",
    "        _, cost_val = sess.run([train,cost], feed_dict={X:batch_x, \n",
    "                                                        Y:batch_y})\n",
    "    if step % 3 == 0 :\n",
    "        print(\"Cost는 : {}\".format(cost_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도는 : 0.9348999857902527\n"
     ]
    }
   ],
   "source": [
    "predict = tf.argmax(H,1)\n",
    "correct = tf.equal(predict, tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "print(\"정확도는 : {}\".format(sess.run(accuracy, \n",
    "                                   feed_dict={X:mnist.test.images, \n",
    "                                              Y:mnist.test.labels})))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "## Hinton 교수님이 중요하게 여기는 또 하나의 요건은 W의 초기값\n",
    "## 초기에는 RBM이라는 방법을 이용하여 초기화를 진행 \n",
    "## 2010 년도에 Xavier 초기화라는 방식으로 논문으로 발표 \n",
    "## 2015 년에는 He's 초기화라는 방식의 논문으로 발표 \n",
    "import tensorflow as tf \n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import warnings \n",
    "\n",
    "warnings.filterwarnings(action = \"ignore\") # warning 출력 방지 \n",
    "\n",
    "# Data Loading \n",
    "mnist = input_data.read_data_sets(\"./data/mnist\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Overfitting(과적합)\n",
    "## 학습한 모델이 training data set에 최적화되어 있는 상태 \n",
    "## 테스트 데이터에는 잘 들어맞지 않는 상태를 지칭\n",
    "\n",
    "## 학습한 모델이 training data set에는 약 98% 이상 정확도를 가지지만\n",
    "## test data set에 대해서는 85% 정도 밖에 나오지 않는 다면 그건 overfitting \n",
    "\n",
    "## 1. 일단 학습하는 데이터 수 가 많아야 한다. \n",
    "## 2. 필요없는 feature들은 학습에서 제외 \n",
    "##    중복되는 feature들은 단일화 시켜야한다. \n",
    "## 3. 학습하는 과정에서 overfitting을 피할 수 있다. \n",
    "## (2014년 논문, logistic을 선택적으로 줄이면 overfitting을 피할 수 있다고 주장 -> dropout)\n",
    "##  -> 이 역시 tensorflow에서 제공된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost는 : 0.488850861787796\n",
      "Cost는 : 0.21620486676692963\n",
      "Cost는 : 0.2792198657989502\n",
      "Cost는 : 0.5132141709327698\n",
      "Cost는 : 0.1840788871049881\n",
      "Cost는 : 0.08009351044893265\n",
      "Cost는 : 0.23177069425582886\n",
      "Cost는 : 0.2800581455230713\n",
      "Cost는 : 0.08646810799837112\n",
      "Cost는 : 0.15106232464313507\n"
     ]
    }
   ],
   "source": [
    "# 그래프 초기화 \n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Placeholder \n",
    "X = tf.placeholder(shape=[None, 784], dtype = tf.float32)\n",
    "Y = tf.placeholder(shape=[None, 10], dtype = tf.float32)\n",
    "dout_rate =tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "# Weight & bias( Deep & Wide ) \n",
    "W1 = tf.get_variable(\"Weight1\", shape=[784, 256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([256]), name = \"bias1\")        \n",
    "_layer1 = tf.nn.relu(tf.matmul(X,W1) + b1)\n",
    "layer1 = tf.nn.dropout(_layer1, rate =dout_rate ) #'죽이는 비율'설정 -> 과적합 방지 (학습시 수치 설정)\n",
    "                                                  # test data로 검사결과(정확도)뽑을 때는 당연 빼야한다 \n",
    "W2 = tf.get_variable(\"Weight2\", shape=[256, 256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([256]), name = \"bias2\")      \n",
    "_layer2 = tf.nn.relu(tf.matmul(layer1,W2) + b2)\n",
    "layer2 = tf.nn.dropout(_layer2, rate = dout_rate )\n",
    "\n",
    "W3 = tf.get_variable(\"Weight3\", shape=[256, 10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([10]), name = \"bias3\")      \n",
    "_layer3 = tf.nn.relu(tf.matmul(layer2,W2) + b2)\n",
    "layer3 = tf.nn.dropout(_layer3, rate = dout_rate )\n",
    "\n",
    "\n",
    "# Hypothesis \n",
    "logit = tf.matmul(layer2,W3) + b3 \n",
    "H = tf.nn.relu(logit) #or tf.sigmoid()\n",
    "\n",
    "# cost\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = logit,\n",
    "                                                                 labels = Y))\n",
    "\n",
    "# train \n",
    "# AdamOptimizer 사용해보기 \n",
    "train = tf.train.AdamOptimizer(learning_rate = 0.01).minimize(cost)\n",
    "#train = tf.train.GradientDescentOptimizer(learning_rate = 0.01).minimize(cost)\n",
    "\n",
    "# session, 초기화 \n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습 \n",
    "num_of_epoch = 30\n",
    "batch_size = 100 \n",
    "\n",
    "for step in range(num_of_epoch):\n",
    "    num_of_iter = int(mnist.train.num_examples / batch_size)\n",
    "    cost_val = 0 # 코스트 초기화(국룰)\n",
    "    \n",
    "    for i in range(num_of_iter):\n",
    "        batch_x,batch_y = mnist.train.next_batch(batch_size)\n",
    "        _, cost_val = sess.run([train,cost], feed_dict={X:batch_x, \n",
    "                                                        Y:batch_y,\n",
    "                                                        dout_rate:0.3})\n",
    "    if step % 3 == 0 :\n",
    "        print(\"Cost는 : {}\".format(cost_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도는 : 0.9649999737739563\n"
     ]
    }
   ],
   "source": [
    "predict = tf.argmax(H,1)\n",
    "correct = tf.equal(predict, tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "print(\"정확도는 : {}\".format(sess.run(accuracy, \n",
    "                                   feed_dict={X:mnist.test.images, \n",
    "                                              Y:mnist.test.labels,\n",
    "                                              dout_rate:0})))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Kaggle Mnist에 들어가기 앞서\n",
    "## Titanic 데이터 셋으로 딥러닝 학습을 시행해보자 \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf \n",
    "import warnings \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "\n",
    "warnings.filterwarnings(action = \"ignore\") # warning 출력 방지\n",
    "\n",
    "train_df = pd.read_csv(\"./data/titanic/train.csv\")\n",
    "\n",
    "train_df.shape #(891, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#누적그래프 함수 만들기\n",
    "def stackedBarChart(feature):\n",
    "    survived = train_df.loc[train_df[\"Survived\"]==1][feature].value_counts() \n",
    "    survived.name = \"Survived\"\n",
    "    survived\n",
    " \n",
    "    dead = train_df.loc[train_df[\"Survived\"]==0][feature].value_counts()\n",
    "    dead.name = \"Dead\"\n",
    "    dead\n",
    "\n",
    "    chart_df = pd.DataFrame([survived,dead])\n",
    "    chart_df.plot(kind=\"bar\", stacked=True) #누적 막대 그래프를 그리겠다고 선언 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr          517\n",
      "Miss        182\n",
      "Mrs         125\n",
      "Master       40\n",
      "Dr            7\n",
      "Rev           6\n",
      "Mlle          2\n",
      "Major         2\n",
      "Col           2\n",
      "Mme           1\n",
      "Ms            1\n",
      "Jonkheer      1\n",
      "Don           1\n",
      "Lady          1\n",
      "Countess      1\n",
      "Capt          1\n",
      "Sir           1\n",
      "Name: Title, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked  Title\n",
       "0           0       3    male  22.0      1      0   7.2500        S      0\n",
       "1           1       1  female  38.0      1      0  71.2833        C      2\n",
       "2           1       3  female  26.0      0      0   7.9250        S      1\n",
       "3           1       1  female  35.0      1      0  53.1000        S      2\n",
       "4           0       3    male  35.0      0      0   8.0500        S      0\n",
       "..        ...     ...     ...   ...    ...    ...      ...      ...    ...\n",
       "886         0       2    male  27.0      0      0  13.0000        S      3\n",
       "887         1       1  female  19.0      0      0  30.0000        S      1\n",
       "888         0       3  female   NaN      1      2  23.4500        S      1\n",
       "889         1       1    male  26.0      0      0  30.0000        C      0\n",
       "890         0       3    male  32.0      0      0   7.7500        Q      0\n",
       "\n",
       "[891 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feature Engineering\n",
    "# 1. Name \n",
    "# + 사용할 feature/ 사용하지 않을 feature 구분 \n",
    "train_df[\"Title\"]= train_df[\"Name\"].str.extract(\"([A-Za-z]+)\\.\") #영문자, 대소문자 한 다음에 . 이 나오는 형태만 뽑아라\n",
    "                                              # (Mr. Mrs. Miss. Rev. ...)\n",
    "print(train_df[\"Title\"].value_counts()) #Title 컬럼에 대해서 몇 개 있는지 출력 \n",
    "#Title안에 Mr. Miss Mrs. Other를 각각 0,1,2,3으로 변환 (Series의 map 이용)\n",
    "title_mapping_dict = {\"Mr\" : 0, \"Miss\":1, \"Mrs\":2,\n",
    "                      \"Master\" :3, \"Dr\" :3, \"Rev\" :3,\n",
    "                      \"Col\" :3, \"Major\" :3, \"Mlle\" :3,\n",
    "                      \"Don\" :3, \"Jonkheer\" :3, \"Countess\" :3,\n",
    "                      \"Lady\" :3, \"Mme\" :3, \"Ms\" :3,\n",
    "                      \"Sir\" :3, \"Capt\" :3} #mapping되는 형태를 dict 형식으로 선언\n",
    "train_df[\"Title\"]=train_df[\"Title\"].map(title_mapping_dict)\n",
    "train_df #출력 확인(컬럼생성여부)\n",
    "stackedBarChart(\"Title\") # Mr. 가 압도적으로 많이 죽은것을 확인 \n",
    "\n",
    "#제거할 건 제거하자(너무 결측치가 많거나 상관없어 보인다)\n",
    "train_df.drop(\"Name\", axis=1, inplace=True)\n",
    "train_df.drop(\"Ticket\", axis=1, inplace=True)\n",
    "train_df.drop(\"Cabin\", axis=1, inplace=True)\n",
    "train_df.drop(\"PassengerId\", axis=1, inplace=True)\n",
    "#train_df.drop(\"Embarked\", axis=1, inplace=True)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 성별  \n",
    "sex_mapping_dict = {'male': 0, 'female':1}\n",
    "train_df[\"Sex\"]=train_df[\"Sex\"].map(sex_mapping_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  Title\n",
       "0           0       3    0  22.0      1      0   7.2500         0      0\n",
       "1           1       1    1  38.0      1      0  71.2833         2      2\n",
       "2           1       3    1  26.0      0      0   7.9250         0      1\n",
       "3           1       1    1  35.0      1      0  53.1000         0      2\n",
       "4           0       3    0  35.0      0      0   8.0500         0      0\n",
       "..        ...     ...  ...   ...    ...    ...      ...       ...    ...\n",
       "886         0       2    0  27.0      0      0  13.0000         0      3\n",
       "887         1       1    1  19.0      0      0  30.0000         0      1\n",
       "888         0       3    1   NaN      1      2  23.4500         0      1\n",
       "889         1       1    0  26.0      0      0  30.0000         2      0\n",
       "890         0       3    0  32.0      0      0   7.7500         1      0\n",
       "\n",
       "[891 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3. 탑승지역 \n",
    "#탑승지역의 결측치를 \"S\"로 대체 (그냥 S에서 가장많이 타서..)\n",
    "train_df[\"Embarked\"].fillna(\"S\", inplace=True)\n",
    "# 탑승지역 col에 대해서 S->0, Q->1, C->2로 변환 \n",
    "embarked_mapping_dict = {'S': 0, 'Q': 1, 'C': 2} #linear처럼 가중치를 크게 생각하지 않고 그냥 나눠준다고(구분) 생각 \n",
    "train_df[\"Embarked\"]=train_df[\"Embarked\"].map(embarked_mapping_dict)\n",
    "display(train_df)\n",
    "display(stackedBarChart(\"Embarked\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.773973</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass  Sex        Age  SibSp  Parch     Fare  Embarked  Title\n",
       "0           0       3    0  22.000000      1      0   7.2500         0      0\n",
       "1           1       1    1  38.000000      1      0  71.2833         2      2\n",
       "2           1       3    1  26.000000      0      0   7.9250         0      1\n",
       "3           1       1    1  35.000000      1      0  53.1000         0      2\n",
       "4           0       3    0  35.000000      0      0   8.0500         0      0\n",
       "..        ...     ...  ...        ...    ...    ...      ...       ...    ...\n",
       "886         0       2    0  27.000000      0      0  13.0000         0      3\n",
       "887         1       1    1  19.000000      0      0  30.0000         0      1\n",
       "888         0       3    1  21.773973      1      2  23.4500         0      1\n",
       "889         1       1    0  26.000000      0      0  30.0000         2      0\n",
       "890         0       3    0  32.000000      0      0   7.7500         1      0\n",
       "\n",
       "[891 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass  Sex  Age  SibSp  Parch     Fare  Embarked  Title\n",
       "0           0       3    0  1.0      1      0   7.2500         0      0\n",
       "1           1       1    1  1.0      1      0  71.2833         2      2\n",
       "2           1       3    1  1.0      0      0   7.9250         0      1\n",
       "3           1       1    1  1.0      1      0  53.1000         0      2\n",
       "4           0       3    0  1.0      0      0   8.0500         0      0\n",
       "..        ...     ...  ...  ...    ...    ...      ...       ...    ...\n",
       "886         0       2    0  1.0      0      0  13.0000         0      3\n",
       "887         1       1    1  0.0      0      0  30.0000         0      1\n",
       "888         0       3    1  1.0      1      2  23.4500         0      1\n",
       "889         1       1    0  1.0      0      0  30.0000         2      0\n",
       "890         0       3    0  1.0      0      0   7.7500         1      0\n",
       "\n",
       "[891 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4. Age + 결측치제거 \n",
    "# 가능한한 타당한 이유로 결측치를 다른 값으로 대체해 주어야 한다. \n",
    "# -전체사람의 평균을 구해서 결측치를 채운다. \n",
    "# -Title을 이용해서 각 title에 맞는 평균 나이로 결측치를 채운다. \n",
    "age_mean = train_df.groupby(\"Title\")[\"Age\"].mean()\n",
    "a = train_df[train_df[\"Title\"]==0][\"Age\"].fillna(age_mean[0]) #series를 return 받는다\n",
    "b = train_df[train_df[\"Title\"]==1][\"Age\"].fillna(age_mean[1])\n",
    "c = train_df[train_df[\"Title\"]==2][\"Age\"].fillna(age_mean[2])\n",
    "d = train_df[train_df[\"Title\"]==3][\"Age\"].fillna(age_mean[3])\n",
    "result_series = pd.concat([a,b,c,d])\n",
    "train_df[\"Age\"]=result_series.sort_index()\n",
    "display(train_df)\n",
    "\n",
    "# Age에 대해서 Binning 처리 \n",
    "# Binning 처리를 할 때 고려해야 할 사항 -> 간격은 어떻게 설정? \n",
    "# Age -> 0~20 :0 \n",
    "# Age -> 20살 초과~40이하 : 1\n",
    "# Age -> 40살 초과~60이하 : 2\n",
    "# Age -> 60살초과 : 3\n",
    "train_df.loc[train_df[\"Age\"] <= 20, \"Age\"] = 0\n",
    "train_df.loc[(train_df[\"Age\"] > 20) & (train_df[\"Age\"] <= 40), \"Age\"] = 1\n",
    "train_df.loc[(train_df[\"Age\"] > 40) & (train_df[\"Age\"] <= 60), \"Age\"] = 2\n",
    "train_df.loc[60 < train_df[\"Age\"] , \"Age\"] = 3\n",
    "\n",
    "stackedBarChart(\"Age\") # 20대~40대 인원들이 가장 많이 죽음(원래 구성비율자체가 높음)\n",
    "display(train_df) # 이 셀만 다시 실행하면 다 꼬인다!! 재실행시 유의할 것\n",
    "                  # 운임요금(Fare) 를 마지막 binning 처리 대상으로! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512.3292\n",
      "0.0\n",
      "7.9104\n",
      "14.4542\n",
      "31.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass  Sex  Age  SibSp  Parch  Fare  Embarked  Title\n",
       "0           0       3    0  1.0      1      0   0.0         0      0\n",
       "1           1       1    1  1.0      1      0   3.0         2      2\n",
       "2           1       3    1  1.0      0      0   1.0         0      1\n",
       "3           1       1    1  1.0      1      0   3.0         0      2\n",
       "4           0       3    0  1.0      0      0   1.0         0      0\n",
       "..        ...     ...  ...  ...    ...    ...   ...       ...    ...\n",
       "886         0       2    0  1.0      0      0   1.0         0      3\n",
       "887         1       1    1  0.0      0      0   2.0         0      1\n",
       "888         0       3    1  1.0      1      2   2.0         0      1\n",
       "889         1       1    0  1.0      0      0   2.0         2      0\n",
       "890         0       3    0  1.0      0      0   0.0         1      0\n",
       "\n",
       "[891 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5. Fare \n",
    "# 여기에 이상치 처리까지하면 모든 전처리가 끝(아마도)\n",
    "import numpy as np \n",
    "\n",
    "print(max(train_df[\"Fare\"])) #512.3292\n",
    "print(min(train_df[\"Fare\"])) #0.0\n",
    "print(np.percentile((train_df[\"Fare\"]), 25)) #7.9104\n",
    "print(np.percentile((train_df[\"Fare\"]), 50)) #14.4542\n",
    "print(np.percentile((train_df[\"Fare\"]), 75)) #31.0\n",
    "\n",
    "train_df.loc[train_df[\"Fare\"] <= 7.9104, \"Fare\"] = 0\n",
    "train_df.loc[(train_df[\"Fare\"] > 7.9104) & (train_df[\"Fare\"] <= 14.4542), \"Fare\"] = 1\n",
    "train_df.loc[(train_df[\"Fare\"] > 14.4542) & (train_df[\"Fare\"] <= 31.0), \"Fare\"] = 2\n",
    "train_df.loc[31.0 < train_df[\"Fare\"] , \"Fare\"] = 3\n",
    "\n",
    "display(train_df)\n",
    "stackedBarChart(\"Fare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Machine Learning\n",
    "\n",
    "train_df.shape\n",
    "train_num = int(train_df.shape[0] * 0.8) #712\n",
    "\n",
    "#train, test data set \n",
    "train_x_data = train_df.drop(\"Survived\", axis = 1, inplace = False)[:train_num]                                                               \n",
    "test_x_data = train_df.drop(\"Survived\", axis=1, inplace=False)[train_num:] \n",
    "\n",
    "# y축은 Survived 하나 \n",
    "# 2차원 형태로 바꾸어주어야 한다.\n",
    "train_y_data = train_df[\"Survived\"][:train_num].values.reshape([-1,1]) \n",
    "test_y_data = train_df[\"Survived\"][train_num:].values.reshape([-1,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost값은: 0.0\n",
      "Cost값은: 0.0\n",
      "Cost값은: 0.0\n",
      "Cost값은: 0.0\n",
      "Cost값은: 0.0\n",
      "Cost값은: 0.0\n",
      "Cost값은: 0.0\n",
      "Cost값은: 0.0\n",
      "Cost값은: 0.0\n",
      "Cost값은: 0.0\n"
     ]
    }
   ],
   "source": [
    "# 그래프 초기화 \n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Placeholder \n",
    "X = tf.placeholder(shape=[None, 8], dtype = tf.float32)\n",
    "Y = tf.placeholder(shape=[None, 1], dtype = tf.float32)\n",
    "dout_rate =tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "# Weight & bias( Deep & Wide ) \n",
    "W1 = tf.get_variable(\"Weight1\", shape=[8, 256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([256]), name = \"bias1\")        \n",
    "_layer1 = tf.nn.relu(tf.matmul(X,W1) + b1)\n",
    "layer1 = tf.nn.dropout(_layer1, rate =dout_rate ) #'죽이는 비율'설정 -> 과적합 방지 (학습시 수치 설정)\n",
    "                                                  # test data로 검사결과(정확도)뽑을 때는 당연 빼야한다 \n",
    "W2 = tf.get_variable(\"Weight2\", shape=[256, 256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([256]), name = \"bias2\")      \n",
    "_layer2 = tf.nn.relu(tf.matmul(layer1,W2) + b2)\n",
    "layer2 = tf.nn.dropout(_layer2, rate = dout_rate )\n",
    "\n",
    "W3 = tf.get_variable(\"Weight3\", shape=[256, 1], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([1]), name = \"bias3\")      \n",
    "_layer3 = tf.nn.relu(tf.matmul(layer2,W2) + b2)\n",
    "layer3 = tf.nn.dropout(_layer3, rate = dout_rate )\n",
    "\n",
    "\n",
    "# Hypothesis \n",
    "logit = tf.matmul(layer2,W3) + b3 \n",
    "H = tf.nn.relu(logit) #or tf.sigmoid()\n",
    "\n",
    "# cost\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = logit,\n",
    "                                                                 labels = Y))\n",
    "\n",
    "# train \n",
    "# AdamOptimizer 사용해보기 \n",
    "train = tf.train.AdamOptimizer(learning_rate = 0.01).minimize(cost)\n",
    "#train = tf.train.GradientDescentOptimizer(learning_rate = 0.01).minimize(cost)\n",
    "\n",
    "# session, 초기화 \n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "train_epoch = 30\n",
    "batch_size = 100\n",
    "\n",
    "# 모든 데이터 불러오지 않고, 몇개씩 불러들어서 학습\n",
    "\n",
    "for step in range(train_epoch):\n",
    "    num_of_iter = int(train_num / batch_size)     # train이 도대체 몇개 행이 있는지 / batch_size\n",
    "    cost_val = 0\n",
    "    \n",
    "    for i in range(num_of_iter):\n",
    "        batch_x=train_x_data[i*batch_size:(i+1)*batch_size]\n",
    "        batch_y=train_y_data[i*batch_size:(i+1)*batch_size]\n",
    "        _,cost_val = sess.run([train,cost],\n",
    "                             feed_dict={X:batch_x,\n",
    "                                        Y:batch_y,\n",
    "                                        dout_rate:0.03})\n",
    "    if step % 3 ==0:\n",
    "        print(\"Cost값은: {}\".format(cost_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도는 : 1.0\n"
     ]
    }
   ],
   "source": [
    "#정확도\n",
    "predict = tf.argmax(H,1)\n",
    "correct = tf.equal(predict, tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype = tf.float32))\n",
    "print(\"정확도는 : {}\".format(sess.run(accuracy, \n",
    "                                  feed_dict={X:test_x_data,\n",
    "                                             Y:test_y_data,\n",
    "                                             dout_rate:0})))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex  Age  SibSp  Parch  Fare  Embarked  Title\n",
       "0         3    0  1.0      0      0   0.0         1      0\n",
       "1         3    1  2.0      1      0   0.0         0      2\n",
       "2         2    0  3.0      0      0   1.0         1      0\n",
       "3         3    0  1.0      0      0   1.0         0      0\n",
       "4         3    1  1.0      1      1   1.0         0      2\n",
       "..      ...  ...  ...    ...    ...   ...       ...    ...\n",
       "413       3    0  1.0      0      0   1.0         0      0\n",
       "414       1    1  1.0      0      0   3.0         2      3\n",
       "415       3    0  1.0      0      0   0.0         0      0\n",
       "416       3    0  1.0      0      0   1.0         0      0\n",
       "417       3    0  0.0      1      1   2.0         2      3\n",
       "\n",
       "[418 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost값은: 0.0\n",
      "Cost값은: 0.0\n",
      "Cost값은: 0.0\n",
      "Cost값은: 0.0\n",
      "Cost값은: 0.0\n",
      "Cost값은: 0.0\n",
      "Cost값은: 0.0\n",
      "Cost값은: 0.0\n",
      "Cost값은: 0.0\n",
      "Cost값은: 0.0\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "2 root error(s) found.\n  (0) Invalid argument: You must feed a value for placeholder tensor 'Placeholder_2' with dtype float\n\t [[node Placeholder_2 (defined at C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) ]]\n\t [[Relu_3/_13]]\n  (1) Invalid argument: You must feed a value for placeholder tensor 'Placeholder_2' with dtype float\n\t [[node Placeholder_2 (defined at C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) ]]\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'Placeholder_2':\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n    app.start()\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\asyncio\\base_events.py\", line 442, in run_forever\n    self._run_once()\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\asyncio\\base_events.py\", line 1462, in _run_once\n    handle._run()\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 361, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 541, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3051, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3242, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3319, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-14-33318fda2fee>\", line 80, in <module>\n    dout_rate =tf.placeholder(dtype=tf.float32)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\", line 2619, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_array_ops.py\", line 6669, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m-> 1350\u001b[1;33m                                       target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m                                             run_metadata)\n\u001b[0m\u001b[0;32m   1444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument: You must feed a value for placeholder tensor 'Placeholder_2' with dtype float\n\t [[{{node Placeholder_2}}]]\n\t [[Relu_3/_13]]\n  (1) Invalid argument: You must feed a value for placeholder tensor 'Placeholder_2' with dtype float\n\t [[{{node Placeholder_2}}]]\n0 successful operations.\n0 derived errors ignored.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-33318fda2fee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[1;31m#예측\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 956\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    957\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1180\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1181\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1359\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                     \u001b[1;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[1;32m-> 1384\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument: You must feed a value for placeholder tensor 'Placeholder_2' with dtype float\n\t [[node Placeholder_2 (defined at C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) ]]\n\t [[Relu_3/_13]]\n  (1) Invalid argument: You must feed a value for placeholder tensor 'Placeholder_2' with dtype float\n\t [[node Placeholder_2 (defined at C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) ]]\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'Placeholder_2':\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n    app.start()\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\asyncio\\base_events.py\", line 442, in run_forever\n    self._run_once()\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\asyncio\\base_events.py\", line 1462, in _run_once\n    handle._run()\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 361, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 541, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3051, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3242, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3319, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-14-33318fda2fee>\", line 80, in <module>\n    dout_rate =tf.placeholder(dtype=tf.float32)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\", line 2619, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_array_ops.py\", line 6669, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "## test.csv를 이용해서 prediction 을 해야 한다. \n",
    "## 예측결과가 나온다! -> 파일로 만들어서 제출 \n",
    "\n",
    "# data loading(train data set loading)\n",
    "test_df = pd.read_csv(\"./data/titanic/test.csv\")\n",
    "\n",
    "\n",
    "# Feature Engineering\n",
    "# Feature : Column \n",
    "test_df.head()\n",
    "\n",
    "test_df[\"Title\"]= test_df[\"Name\"].str.extract(\"([A-Za-z]+)\\.\") \n",
    "test_df[\"Title\"].value_counts() \n",
    "title_mapping_dict = {\"Mr\" : 0, \"Miss\":1, \"Mrs\":2,\n",
    "                      \"Master\" :3, \"Dr\" :3, \"Rev\" :3,\n",
    "                      \"Col\" :3, \"Major\" :3, \"Mlle\" :3,\n",
    "                      \"Don\" :3, \"Dona\" :3, \"Jonkheer\" :3, \n",
    "                      \"Countess\" :3, \"Lady\" :3, \"Mme\" :3,\n",
    "                      \"Ms\" :3, \"Sir\" :3, \"Capt\" :3} \n",
    "test_df[\"Title\"]=test_df[\"Title\"].map(title_mapping_dict) #Dona 추가 \n",
    "\n",
    "#제거할 건 제거하자(안쓸 col들 제거)\n",
    "test_df.drop(\"Name\", axis=1, inplace=True)\n",
    "test_df.drop(\"Ticket\", axis=1, inplace=True)\n",
    "test_df.drop(\"Cabin\", axis=1, inplace=True)\n",
    "test_df.drop(\"PassengerId\", axis=1, inplace=True)\n",
    "#test_df.drop(\"Embarked\", axis=1, inplace=True)\n",
    "# 성별 col에 대해 male=0, female=1로 수정해보자 \n",
    "sex_mapping_dict = {'male': 0, 'female':1}\n",
    "test_df[\"Sex\"]=test_df[\"Sex\"].map(sex_mapping_dict)\n",
    "\n",
    "\n",
    "# 탑승지역 col에 대해서 S->0, Q->1, C->2로 변환 \n",
    "test_df[\"Embarked\"].fillna(\"S\", inplace=True)\n",
    "embarked_mapping_dict = {'S': 0, 'Q': 1, 'C': 2} \n",
    "test_df[\"Embarked\"]=test_df[\"Embarked\"].map(embarked_mapping_dict)\n",
    "\n",
    "\n",
    "# Age처리 \n",
    "# -Title을 이용해서 각 title에 맞는 평균 나이로 결측치를 채운다. \n",
    "age_mean = test_df.groupby(\"Title\")[\"Age\"].mean()\n",
    "a = test_df[test_df[\"Title\"]==0][\"Age\"].fillna(age_mean[0]) #series를 return 받는다\n",
    "b = test_df[test_df[\"Title\"]==1][\"Age\"].fillna(age_mean[1])\n",
    "c = test_df[test_df[\"Title\"]==2][\"Age\"].fillna(age_mean[2])\n",
    "d = test_df[test_df[\"Title\"]==3][\"Age\"].fillna(age_mean[3])\n",
    "result_series = pd.concat([a,b,c,d])\n",
    "test_df[\"Age\"]=result_series.sort_index()\n",
    "\n",
    "# Age에 대해서 Binning 처리 \n",
    "test_df.loc[test_df[\"Age\"] <= 20, \"Age\"] = 0\n",
    "test_df.loc[(test_df[\"Age\"] > 20) & (test_df[\"Age\"] <= 40), \"Age\"] = 1\n",
    "test_df.loc[(test_df[\"Age\"] > 40) & (test_df[\"Age\"] <= 60), \"Age\"] = 2\n",
    "test_df.loc[60 < test_df[\"Age\"] , \"Age\"] = 3\n",
    "\n",
    " \n",
    "    \n",
    "# Fare처리\n",
    "'''\n",
    "print(max(train_df[\"Fare\"])) #512.3292\n",
    "print(min(train_df[\"Fare\"])) #0.0\n",
    "print(np.percentile((train_df[\"Fare\"]), 25)) #7.9104\n",
    "print(np.percentile((train_df[\"Fare\"]), 50)) #14.4542\n",
    "print(np.percentile((train_df[\"Fare\"]), 75)) #31.0\n",
    "'''\n",
    "test_df[\"Fare\"]=test_df[\"Fare\"].fillna(0)\n",
    "test_df.loc[test_df[\"Fare\"] <= 7.9104, \"Fare\"] = 0\n",
    "test_df.loc[(test_df[\"Fare\"] > 7.9104) & (test_df[\"Fare\"] <= 14.4542), \"Fare\"] = 1\n",
    "test_df.loc[(test_df[\"Fare\"] > 14.4542) & (test_df[\"Fare\"] <= 31.0), \"Fare\"] = 2\n",
    "test_df.loc[31.0 < test_df[\"Fare\"] , \"Fare\"] = 3\n",
    "\n",
    "\n",
    "display(test_df)\n",
    "#######################################################################\n",
    "# 그래프 초기화 \n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Placeholder \n",
    "X = tf.placeholder(shape=[None, 8], dtype = tf.float32)\n",
    "Y = tf.placeholder(shape=[None, 1], dtype = tf.float32)\n",
    "dout_rate =tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "# Weight & bias( Deep & Wide ) \n",
    "W1 = tf.get_variable(\"Weight1\", shape=[8, 256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([256]), name = \"bias1\")        \n",
    "_layer1 = tf.nn.relu(tf.matmul(X,W1) + b1)\n",
    "layer1 = tf.nn.dropout(_layer1, rate =dout_rate ) #'죽이는 비율'설정 -> 과적합 방지 (학습시 수치 설정)\n",
    "                                                  # test data로 검사결과(정확도)뽑을 때는 당연 빼야한다 \n",
    "W2 = tf.get_variable(\"Weight2\", shape=[256, 256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([256]), name = \"bias2\")      \n",
    "_layer2 = tf.nn.relu(tf.matmul(layer1,W2) + b2)\n",
    "layer2 = tf.nn.dropout(_layer2, rate = dout_rate )\n",
    "\n",
    "W3 = tf.get_variable(\"Weight3\", shape=[256, 1], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([1]), name = \"bias3\")      \n",
    "_layer3 = tf.nn.relu(tf.matmul(layer2,W2) + b2)\n",
    "layer3 = tf.nn.dropout(_layer3, rate = dout_rate )\n",
    "\n",
    "\n",
    "# Hypothesis \n",
    "logit = tf.matmul(layer2,W3) + b3 \n",
    "H = tf.nn.relu(logit) #or tf.sigmoid()\n",
    "\n",
    "# cost\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = logit,\n",
    "                                                                 labels = Y))\n",
    "\n",
    "# train \n",
    "# AdamOptimizer 사용해보기 \n",
    "train = tf.train.AdamOptimizer(learning_rate = 0.01).minimize(cost)\n",
    "#train = tf.train.GradientDescentOptimizer(learning_rate = 0.01).minimize(cost)\n",
    "\n",
    "# session, 초기화 \n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "train_epoch = 30\n",
    "batch_size = 100\n",
    "\n",
    "# 모든 데이터 불러오지 않고, 몇개씩 불러들어서 학습\n",
    "\n",
    "for step in range(train_epoch):\n",
    "    num_of_iter = int(train_num / batch_size)     # train이 도대체 몇개 행이 있는지 / batch_size\n",
    "    cost_val = 0\n",
    "    \n",
    "    for i in range(num_of_iter):\n",
    "        batch_x=train_x_data[i*batch_size:(i+1)*batch_size]\n",
    "        batch_y=train_y_data[i*batch_size:(i+1)*batch_size]\n",
    "        _,cost_val = sess.run([train,cost],\n",
    "                             feed_dict={X:batch_x,\n",
    "                                        Y:batch_y,\n",
    "                                        dout_rate:0.03})\n",
    "    if step % 3 ==0:\n",
    "        print(\"Cost값은: {}\".format(cost_val))\n",
    "\n",
    "\n",
    "#예측\n",
    "result = sess.run(H, feed_dict={X : test_df})\n",
    "predict = tf.cast(result > 0.5, dtype = tf.int64)\n",
    "print(sess.run(predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex  Age  SibSp  Parch  Fare  Embarked  Title\n",
       "0         3    0  1.0      0      0   0.0         1      0\n",
       "1         3    1  2.0      1      0   0.0         0      2\n",
       "2         2    0  3.0      0      0   1.0         1      0\n",
       "3         3    0  1.0      0      0   1.0         0      0\n",
       "4         3    1  1.0      1      1   1.0         0      2\n",
       "..      ...  ...  ...    ...    ...   ...       ...    ...\n",
       "413       3    0  1.0      0      0   1.0         0      0\n",
       "414       1    1  1.0      0      0   3.0         2      3\n",
       "415       3    0  1.0      0      0   0.0         0      0\n",
       "416       3    0  1.0      0      0   1.0         0      0\n",
       "417       3    0  0.0      1      1   2.0         2      3\n",
       "\n",
       "[418 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost값은: 0.0\n",
      "Cost값은: 0.0\n",
      "Cost값은: 0.0\n",
      "Cost값은: 0.0\n",
      "Cost값은: 0.0\n",
      "Cost값은: 0.0\n",
      "Cost값은: 0.0\n",
      "Cost값은: 0.0\n",
      "Cost값은: 0.0\n",
      "Cost값은: 0.0\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "## 2차시기 : by sigmoid \n",
    "## dropout없이 ㄱㄱ\n",
    "## test.csv를 이용해서 prediction 을 해야 한다. \n",
    "## 예측결과가 나온다! -> 파일로 만들어서 제출 \n",
    "\n",
    "# data loading(train data set loading)\n",
    "test_df = pd.read_csv(\"./data/titanic/test.csv\")\n",
    "\n",
    "\n",
    "# Feature Engineering\n",
    "# Feature : Column \n",
    "test_df.head()\n",
    "\n",
    "test_df[\"Title\"]= test_df[\"Name\"].str.extract(\"([A-Za-z]+)\\.\") \n",
    "test_df[\"Title\"].value_counts() \n",
    "title_mapping_dict = {\"Mr\" : 0, \"Miss\":1, \"Mrs\":2,\n",
    "                      \"Master\" :3, \"Dr\" :3, \"Rev\" :3,\n",
    "                      \"Col\" :3, \"Major\" :3, \"Mlle\" :3,\n",
    "                      \"Don\" :3, \"Dona\" :3, \"Jonkheer\" :3, \n",
    "                      \"Countess\" :3, \"Lady\" :3, \"Mme\" :3,\n",
    "                      \"Ms\" :3, \"Sir\" :3, \"Capt\" :3} \n",
    "test_df[\"Title\"]=test_df[\"Title\"].map(title_mapping_dict) #Dona 추가 \n",
    "\n",
    "#제거할 건 제거하자(안쓸 col들 제거)\n",
    "test_df.drop(\"Name\", axis=1, inplace=True)\n",
    "test_df.drop(\"Ticket\", axis=1, inplace=True)\n",
    "test_df.drop(\"Cabin\", axis=1, inplace=True)\n",
    "test_df.drop(\"PassengerId\", axis=1, inplace=True)\n",
    "#test_df.drop(\"Embarked\", axis=1, inplace=True)\n",
    "# 성별 col에 대해 male=0, female=1로 수정해보자 \n",
    "sex_mapping_dict = {'male': 0, 'female':1}\n",
    "test_df[\"Sex\"]=test_df[\"Sex\"].map(sex_mapping_dict)\n",
    "\n",
    "\n",
    "# 탑승지역 col에 대해서 S->0, Q->1, C->2로 변환 \n",
    "test_df[\"Embarked\"].fillna(\"S\", inplace=True)\n",
    "embarked_mapping_dict = {'S': 0, 'Q': 1, 'C': 2} \n",
    "test_df[\"Embarked\"]=test_df[\"Embarked\"].map(embarked_mapping_dict)\n",
    "\n",
    "\n",
    "# Age처리 \n",
    "# -Title을 이용해서 각 title에 맞는 평균 나이로 결측치를 채운다. \n",
    "age_mean = test_df.groupby(\"Title\")[\"Age\"].mean()\n",
    "a = test_df[test_df[\"Title\"]==0][\"Age\"].fillna(age_mean[0]) #series를 return 받는다\n",
    "b = test_df[test_df[\"Title\"]==1][\"Age\"].fillna(age_mean[1])\n",
    "c = test_df[test_df[\"Title\"]==2][\"Age\"].fillna(age_mean[2])\n",
    "d = test_df[test_df[\"Title\"]==3][\"Age\"].fillna(age_mean[3])\n",
    "result_series = pd.concat([a,b,c,d])\n",
    "test_df[\"Age\"]=result_series.sort_index()\n",
    "\n",
    "# Age에 대해서 Binning 처리 \n",
    "test_df.loc[test_df[\"Age\"] <= 20, \"Age\"] = 0\n",
    "test_df.loc[(test_df[\"Age\"] > 20) & (test_df[\"Age\"] <= 40), \"Age\"] = 1\n",
    "test_df.loc[(test_df[\"Age\"] > 40) & (test_df[\"Age\"] <= 60), \"Age\"] = 2\n",
    "test_df.loc[60 < test_df[\"Age\"] , \"Age\"] = 3\n",
    "\n",
    " \n",
    "    \n",
    "# Fare처리\n",
    "'''\n",
    "print(max(train_df[\"Fare\"])) #512.3292\n",
    "print(min(train_df[\"Fare\"])) #0.0\n",
    "print(np.percentile((train_df[\"Fare\"]), 25)) #7.9104\n",
    "print(np.percentile((train_df[\"Fare\"]), 50)) #14.4542\n",
    "print(np.percentile((train_df[\"Fare\"]), 75)) #31.0\n",
    "'''\n",
    "test_df[\"Fare\"]=test_df[\"Fare\"].fillna(0)\n",
    "test_df.loc[test_df[\"Fare\"] <= 7.9104, \"Fare\"] = 0\n",
    "test_df.loc[(test_df[\"Fare\"] > 7.9104) & (test_df[\"Fare\"] <= 14.4542), \"Fare\"] = 1\n",
    "test_df.loc[(test_df[\"Fare\"] > 14.4542) & (test_df[\"Fare\"] <= 31.0), \"Fare\"] = 2\n",
    "test_df.loc[31.0 < test_df[\"Fare\"] , \"Fare\"] = 3\n",
    "\n",
    "\n",
    "display(test_df)\n",
    "#######################################################################\n",
    "# 머신러닝 대입 \n",
    "\n",
    "# 그래프 초기화 \n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Placeholder \n",
    "X = tf.placeholder(shape=[None, 8], dtype = tf.float32)\n",
    "Y = tf.placeholder(shape=[None, 1], dtype = tf.float32)\n",
    "\n",
    "# Weight & bias( Deep & Wide ) \n",
    "W1 = tf.Variable(tf.random_normal([8,256]), name = \"weight\") # 뒷'열'(perceptron)은 내가 잡고 싶은 대로 조정\n",
    "b1 = tf.Variable(tf.random_normal([256]), name = \"bias\")       # 단 depth 가 깊으면 깊을수록 처리하기 곤란해진다\n",
    "layer1 = tf.sigmoid(tf.matmul(X,W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([256,256]), name = \"weight2\") \n",
    "b2 = tf.Variable(tf.random_normal([256]), name = \"bias2\")      \n",
    "layer2 = tf.sigmoid(tf.matmul(layer1,W2) + b2)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([256,1]), name = \"weight3\") \n",
    "b3 = tf.Variable(tf.random_normal([1]), name = \"bias3\")      \n",
    "layer3 = tf.sigmoid(tf.matmul(layer2,W3) + b3)\n",
    "\n",
    "\n",
    "# Hypothesis \n",
    "logit = tf.matmul(layer2,W3) + b3 \n",
    "H = tf.sigmoid(logit) #or tf.sigmoid()\n",
    "\n",
    "# cost\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = logit,\n",
    "                                                                 labels = Y))\n",
    "\n",
    "# train \n",
    "# AdamOptimizer 사용해보기 \n",
    "train = tf.train.AdamOptimizer(learning_rate = 0.01).minimize(cost)\n",
    "#train = tf.train.GradientDescentOptimizer(learning_rate = 0.01).minimize(cost)\n",
    "\n",
    "# session, 초기화 \n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "train_epoch = 30\n",
    "batch_size = 100\n",
    "\n",
    "# 모든 데이터 불러오지 않고, 몇개씩 불러들어서 학습\n",
    "\n",
    "for step in range(train_epoch):\n",
    "    num_of_iter = int(train_num / batch_size)     # train이 도대체 몇개 행이 있는지 / batch_size\n",
    "    cost_val = 0\n",
    "    \n",
    "    for i in range(num_of_iter):\n",
    "        batch_x=train_x_data[i*batch_size:(i+1)*batch_size]\n",
    "        batch_y=train_y_data[i*batch_size:(i+1)*batch_size]\n",
    "        _,cost_val = sess.run([train,cost],\n",
    "                             feed_dict={X:batch_x,\n",
    "                                        Y:batch_y})\n",
    "    if step % 3 ==0:\n",
    "        print(\"Cost값은: {}\".format(cost_val))\n",
    "\n",
    "\n",
    "#예측\n",
    "result = sess.run(H, feed_dict={X : test_df})\n",
    "predict = tf.cast(result > 0.5, dtype = tf.int64)\n",
    "print(sess.run(predict))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#결과 제출용 파일 생성 \n",
    "\n",
    "#test_df.isnull().sum()\n",
    "#결과 제출용 파일 생성 \n",
    "\n",
    "result_df = pd.DataFrame(sess.run(predict))\n",
    "result_df.rename(columns={0:\"Survived\"}, inplace = True)\n",
    "display(result_df)\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"./data/titanic/gender_submission.csv\")\n",
    "submit_df= df[\"PassengerId\"]\n",
    "submit_df = pd.DataFrame(submit_df)\n",
    "display(submit_df)\n",
    "\n",
    "\n",
    "submit_df = pd.concat([submit_df, result_df], axis= 1)\n",
    "display(submit_df)\n",
    "\n",
    "submit_df.to_csv(\"./data/titanic/result.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[GPU_ENV]",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
