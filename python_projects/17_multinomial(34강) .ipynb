{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.96346605  4.59676542]\n",
      " [11.0329545  -0.16816717]\n",
      " [11.54155807  5.21116083]\n",
      " [ 8.69289001  1.54322016]\n",
      " [ 8.1062269   4.28695977]\n",
      " [ 8.30988863  4.80623966]\n",
      " [11.93027136  4.64866327]\n",
      " [ 9.67284681 -0.20283165]\n",
      " [ 8.34810316  5.13415623]\n",
      " [ 8.67494727  4.47573059]\n",
      " [ 9.17748385  5.09283177]\n",
      " [10.24028948  2.45544401]\n",
      " [ 8.68937095  1.48709629]\n",
      " [ 8.92229526 -0.63993225]\n",
      " [ 9.49123469  4.33224792]\n",
      " [ 9.25694192  5.13284858]\n",
      " [ 7.99815287  4.8525051 ]\n",
      " [ 8.18378052  1.29564214]\n",
      " [ 8.7337095   2.49162431]\n",
      " [ 9.32298256  5.09840649]\n",
      " [10.06393839  0.99078055]\n",
      " [ 9.50048972 -0.26430318]\n",
      " [ 8.34468785  1.63824349]\n",
      " [ 9.50169345  1.93824624]\n",
      " [ 9.15072323  5.49832246]\n",
      " [11.563957    1.3389402 ]]\n",
      "[1 0 1 0 0 1 1 0 1 1 1 1 0 0 1 1 1 0 0 1 0 0 0 0 1 0]\n",
      "Cost값은 : 6.739695072174072\n",
      "Cost값은 : 0.3205195665359497\n",
      "Cost값은 : 0.2772982120513916\n",
      "Cost값은 : 0.2666107416152954\n",
      "Cost값은 : 0.2625156342983246\n",
      "Cost값은 : 0.26050126552581787\n",
      "Cost값은 : 0.25928375124931335\n",
      "Cost값은 : 0.25840598344802856\n",
      "Cost값은 : 0.2576836347579956\n",
      "Cost값은 : 0.25703614950180054\n",
      "[[0.85048306]]\n",
      "[1]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAADrCAYAAABXYUzjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAPwUlEQVR4nO3d309U577H8c8UBlnHGJBSq4D8nCMhItFqk5P0btuIyY6J8aJ/wP4Das4FyTZN3KY3NvFix/4BOzk358K9Y8huiWUn9abd5qRhd1I9Oyk9DFZlgGhtwdYOZYB1LmavgTUsKMOw1rN+vF9JQ3iG4gPoZx6e5/l+J2XbtgAAwXvF9AQAIKkIYAAwhAAGAEMIYAAwhAAGAEMIYAAwpL6aD25tbbW7u7t9mgoAxE9ra6vGx8fHbds+X/lYVQHc3d2tiYmJvZsZACRAKpVq9RpnCwIADCGAAcAQAhgADCGAAcAQAhgADCGAAcAQAhgADCGAAcAQAhgADCGAAcAQAjgJ7t+S/jgoXWsuvb1/y/SMAKjKXhCIoPu3pI/elYqF0vuLT0rvS9LQO+bmBYAVcOx9+v56+DqKhdI4AKMI4LhbnKluHEBgCOC4a+qobhxAYAjguDt7VUpb7rG0VRoHYBQBHHdD70gXPpSajkpKld5e+JADOCAEuAWRBEPvELhACLECBgBDCGAAwaAgaBO2IAD4j4IgT6yAHUl9dk7q141gURDkiRWwlJxn5/u3Sn/hF2dK94D//Zz01X9v/rof/4/0f39b/7izV+P1fUDwKAjyxApYSsazs/Mks/hEkl16O/En76974k/uj/voXVbGqA0FQZ4IYCkZz85eTzKyt/jgivG4PRkheBQEeSKApWQ8O9f6ZBKnJyMEj4IgT+wBS6Vn4Y17wFL8np2bOv61rVApJfeKt/L9Df8/UAsKgjZhBSwl49l5q18Bz/zO/XWf+R2/KgIBYQXsiPuzs/O1bbwFsdXths7/2NnHAahJyra3OojZ7MyZM/bExISP0wGA+EmlUv+wbftM5Xi0tiAoGgAQI9HZgvCrWKKyOIFftwEEJDorYD+KJbyKEyg6ABCQ6ASwH8USSaiAAxBa0QlgP4olklABByC0ohPAfpQyJqECDkBoRSeA/SiWoD4diKeI3JiKzi0Iae+LJaopTgAQDRFqLxutAPZD3Cvg4o5rhKi03eF6yP5uEMCIrgitdBCgCB2uR2cPGKjENUJ4idDhOgEchIgcCEROhFY6CFCEDtcJYL9RbeefCK10EKAItZdlD9hvEToQiJwkNNLH7kTkcJ0VsN/4Ndk/EVrpAF5YAfttq5cC4tfkvRGRlQ7ghRWw3yJ0ILArHDACuxabFfBoNq8b45OaXSiordnSyHC/Lp5qNz2teFfbcQ8XqEksXpJoNJvXldsPVCiulsesdJ2uXzoRjhCOqz8ObrG9clT6z/8Nfj5ASMXjJYm2cGN80hW+klQorurG+KShGSUEB4xATWIRwLMLharGsUe4hwvUJBYB3NZsVTWOPRL3A0bAZ7EI4JHhflnpOteYla7TyHC/oRklBPdwgZrE4haEc9AWylsQccc9XGDXYhHAUimECVwAURKLLQgAiCICOMLGpsd07i/nNPRfQzr3l3Mamx4zPSUAVYjNFkTSjE2P6dq9a1paXZIkzb2c07V71yRJv+39rcGZAdgpVsARdfPLm+XwdSytLunmlzcNzQhAtaoK4MXFRX399df65Zdf/JoPdmj+5XxV4wDCp6otiGfPnmlkZESpVEpHjx5VJpNRX1+fMpmMent71djY6Nc8UeHw/sOaeznnOQ4gGqoK4O7ubr333nvK5XKamppSNpvV3bt3JUmpVErt7e3q6+tzhfL+/ft9mXjSXX7jsmsPWJIa6xp1+Y3LBmcFoBo1d0P7/vvvy4HsvH3+/Hn58SNHjpQD2QnnAwcO7NkXkGRj02O6+eVNzb+c1+H9h3X5jcscwAEhtFU3NF/aUS4uLpYD2Qnlp0+flh8/dOiQMpmMK5Sbmpp2PA8AiJJAA9jLjz/+uGmlPD+/fmDU2trqWilnMhkdPHhwV38WAITJVgEc2D3gAwcO6OTJkzp58mR57OXLl65Vci6X0xdffCHnSaGlpcW1p9zX16dXX31VqVQqqGkDgG+MFmLs379fQ0NDGhoaKo8VCoVyKDvBPDExUQ7lpqYm19ZFJpPRa6+9RigDiJzQVcJZlqXBwUENDg6Wx5aWlvTw4UPXSjmbzWptbU1SaXVdedB3+PBhQhlAqIUugL00NjZqYGBAAwMD5bHl5WV9++23mpqaKofy6OioVlZWJJVW15XbF21tbYQygNCIRAB7aWho0LFjx3Ts2LHy2MrKSjmUnS2Mjz/+WMViUVIpyCsP+trb2/XKK1RkAwheZAPYS319ffl6m2NlZUVPnjxxhfKdO3e0vLwsSdq3b596e3tdq+WOjg7V18fqWwMghGLxsvTVWl1d1czMjGtPeXp6WktLpaqyhoYGdXV1lcM8k8mos7OTUAawK8bvAYedbdvK5/OuUM7lcvr5558llVbXTig7K+Wuri41NDQYnjmAsCOAd8G2bc3Pz7uKR3K5nH766SdJUl1dnTo7O137yj09Pdq3b5/hmQMIEwJ4j9i2radPn26q6nvx4oUk0SkOwCYEsI9s29bz5883rZR/+OEHSXSKA5KOADZgJ53iKlfKdIoD4sd4L4gkamlpUUtLi958883yWGWnuMnJSX322Wflx19//fVNVX10igPiiRVwCFR2isvlcpqbW3+1CzrFAdHGCjjE6BQHJBMBHFJ0igPijwCOEDrFAfFCAEfcr3WKc4KZTnFA+BDAMeTVKa5YLOrRo0eulTKd4gCzuAWRYE6nOCeUp6am9PDhw207xR09elR1dXWGZw5EC4UY2JHV1VXl83nX9kVlp7ju7m7Xarmrq4tOccA2CGDsGp3igNoQwNhTdIoDdo4Ahu82dorbGMqLi4uSNneK6+vrU29vryzLMjxzwF8EMIxwOsVVNiWiUxyShABGqFTTKc75j05xiCp6QSBUdtMp7tChQ66DPjrFIepYASPUqu0U19fXp5aWFoMzBjZjBYxIolMc4owARuRs1SluenratadMpziEHQGMWLAsS8ePH9fx48fLY06nuI3bF3SKQ5gQwIgtOsUh7AhgJMqvdYpzQplOcQgCAYzES6fTymQyymQy5bHKTnG5XE537txxdYrr6elxhXJHRwdNiVAVrqEBO7S2tlYO5Z10istkMurs7CSUQSUc4Ac6xWEnCGAgIHSKQyUCOERGs3ndGJ/U7EJBbc2WRob7dfFUu+lpwUdeneKmpqb04sULSeud4iqvxTU2NhqeOfYCARwSo9m8rtx+oEJxtTxmpet0/dIJQti0+7ekT9+XFmekpg7p7FVp6B3f/jinU9zGrQs6xcUTARwSb31wV/mFwqbx9mZLf//9bwzMCJJK4fvRu1Jxw88mbUkXPvQ1hL04neI2bl9899135cePHDmyaaVMp7hwoxdESMx6hO924wjIp++7w1cqvf/p+4EH8E46xX3zzTf6/PPPy4/TKS6aCOCAtTVbnivgtmZeFcKoxZnqxgPW1NSk06dP6/Tp0+Uxr05x9+7dKz9e2Skuk8no4MGDJqaPLRDAARsZ7vfcAx4Z7jc4K6ipQ1p84j0eUnSKiz4COGDOQRu3IELm7FXvPeCzV83NaRfoFBctHMIBjoBvQZjk1Snu8ePHdIrzCbcgAGyrslNcLpfTo0eP6BS3B7gFAWBbtXSK2xjKHR0ddIrbIQIYwJa26xS3cU/5k08+oVPcLrAFAaBmq6urmpmZ+dVOcRv3lLu6uhITyuwBAwjU2tqaZmdn6RQnAhhACCS1UxwBDCCUbNvWs2fPXKG8Xae4TCajnp4eWVZ0qkcJYACRUdkpznnr1SnOWSmHuVMcAQwg8qLaKY57wPANDeYRlLh1imMFjJrQYB5h5NUpbm5urvx40J3i2IKAL2gwj6jw6hQ3OzsbSKc4tiDgCxrMIyq26hTnhLKJTnEEMGpCg3lEmWVZGhwc1ODgYHnM6RS3caWczWZ96RRHAKMmNJhH3DQ2NmpgYEADAwPlseXlZT18+NDVV3l0dNSzU5wTzjvpFEcAoyY0mEcSNDQ0qL+/X/396wuLYrGox48flwtHcrmcZ6e48+fPb/l5CWDU7OKpdgIXiZNOp8sr3uHhYUnrneI2bl84vS+8EMAAsEfq6+vV09Ojnp4evf3227/+8QHMKRIoJgAQNAJYm4sJ8gsFXbn9QJIIYQC+4XVDVDpA2niKL0mF4qpujE8amhGAJGAFrGCKCdjiAFCJFbC2LhrYq2KC0WxeI3/+SvmFgmyVtjhG/vyVRrP5Pfn8AKKJAFapmMBK17nG9rKY4Npf/6nimrvnRnHN1rW//nNPPj+AaGILQv4XEywUilWNA0gGAvhfKCYAEDS2IAJw8N/SVY0DSAYCOAB/uHBc6Tp3U450XUp/uHDc0IwAc0azeb31wV31/H5Mb31wN9GH0bHeggjL1S8a1gAlFD25xTaAw/aDZo8Z2L7oKYn/PmK7BUF1GxA+vIKKW2wDmB80ED5+Fz1FTWwDmB80ED5+Fz1FTWwDmB80ED4XT7Xr+qUTam+2lFLp1bOvXzqRyP1fKcaHcNw8AMKJA+l1sQ1giR80gHCL7RYEAIRdrFfASLawFOIAWyGAEUthK8QBvLAFgViiEAdRQAAjlijEQRQQwIglCnEQBQQwYolCHEQBh3CIJQpxEAUEMGKLQhyEHVsQAGAIAQwAhhDAAGAIAQwAhhDAAGAIAQwAhhDAAGAIAQwAhhDAAGAIAQwAhhDAAGAIAQwAhhDAAGAIAQwAhhDAAGAIAQwAhhDAAGAIAQwAhhDAAGAIAQwAhhDAAGAIAQwAhhDAAGAIAQwAhhDAAGAIAQwAhhDAAGAIAQwAhtSbngAAf41m87oxPqnZhYLami2NDPfr4ql209OCCGAEjDAI1mg2ryu3H6hQXJUk5RcKunL7gSTxfQ8BtiAQGCcM8gsF2VoPg9Fs3vTUYuvG+GQ5fB2F4qpujE8amhE2YgWMmu10VbtdGLAa88fsQqGqcQSLFTBqUs2qljAIXluzVdU4gkUAoybV/IpLGARvZLhfVrrONWal6zQy3G9oRtiIAEZNqlnVEgbBu3iqXdcvnVB7s6WUpPZmS9cvnWDLJyTYA0ZN2pot5T3C1mtV6/yj5xZEsC6eaud7HFIEMGoyMtzvuuYkbb+qJQyAdQQwasKqFtg9Ahg1Y1UL7A6HcABgCAEMAIYQwABgCHvAEUADGyCeCOCQo5sVEF9sQYQc3ayA+CKAQ44GNkB8EcAhRwMbIL4I4JCjgQ0QXxzChRylvkB8EcARQKkvEE9sQQCAIQQwABhCAAOAIQQwABhCAAOAIQQwABhCAAOAIQQwABhCAAOAIQQwABiSsm175x+cSj2T9Mi/6QBA7HwnSbZtn698oKoABgDsHbYgAMAQAhgADCGAAcAQAhgADCGAAcAQAhgADCGAAcAQAhgADCGAAcCQ/wfLYv5D7XtgjAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 시작하기 앞서\n",
    "## Logistic Regression 을 그림으로 알아보자 \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf \n",
    "import warnings \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "import mglearn \n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\") # warning 메시지 출력 배제 \n",
    "\n",
    "x, y = mglearn.datasets.make_forge() #갖고 있는 데이터 중에서 임의의 데이터 구성 \n",
    "\n",
    "print(x) #array (난수)\n",
    "print(y) #array (1과0 두가지 뿐)\n",
    "\n",
    "## 산점도 부터 그려보자(Scatter)\n",
    "## y값이 0(또는 1)인 x를 추출해서 x의 첫번째 컬럼을 x축으로, x의 두번째 컬럼을 y축으로 scatter를 그려보자 \n",
    "\n",
    "y == 0 # broad casting으로 비교: boolean mask가 결과로 떨어짐 \n",
    "\n",
    "blue = x[y == 0]    #공역이 0으로 찍히는 정의역 \"blue\"  \n",
    "orange = x[y == 1]  #공역이 1로 찍히는 정의역 \"orange\"\n",
    "\n",
    "plt.scatter(blue[:,0], blue[:,1]) # ndarray임으로 유념! \n",
    "plt.scatter(orange[:,0], orange[:,1])\n",
    "\n",
    "########################\n",
    "\n",
    "## machine learning (Logistic Regression)\n",
    "## train data set( ※ test data set 은 넘어간다(train만) )\n",
    "train_x_data = x \n",
    "train_y_data = y.reshape([-1,1]) # 이전 y가 1차원 0,1 배열이니 (-1<=y<=1 범위를 갖는)2차원으로 변경 해줌 \n",
    "\n",
    "# placeholder \n",
    "X = tf.placeholder(shape=[None,2], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None,1], dtype=tf.float32)\n",
    "\n",
    "# Weight, bias \n",
    "W = tf.Variable(tf.random_normal([2,1]), name = 'weight') # 내부적으로는 W는 값 두개가 구해짐 \n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias') # 절편은 하나 \n",
    "\n",
    "# Hypothesis \n",
    "logit = tf.matmul(X,W) + b # H = WX + b\n",
    "H = tf.sigmoid(logit) #H바로 쓰지 않고 sigmoid化\n",
    "\n",
    "# Cost(Loss) Function \n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = logit,\n",
    "                                                              labels = Y))\n",
    "# train\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "# train = tf.train.GradientDescentOptimizer(learning_rate = 0.01).minimize(cost) #보통 축약해서 쓴다\n",
    "\n",
    "#session 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#학습진행\n",
    "for step in range(3000):\n",
    "    _, cost_val = sess.run([train,cost], feed_dict = {X: train_x_data,\n",
    "                                                      Y: train_y_data})\n",
    "    if step % 300 == 0:\n",
    "        print(\"Cost값은 : {}\".format(cost_val))\n",
    "\n",
    "        \n",
    "# 정확도 측정(Accuracy) : 95% 이상 나오면 쓸만한 모델 (생략)\n",
    "# Prediction(예측)\n",
    "result = sess.run(H, feed_dict = {X : [[9,4]]}) #약 0.8\n",
    "print(result)\n",
    "plt.scatter(9,4)\n",
    "\n",
    "model = LogisticRegression()\n",
    "myModel = model.fit(x,y) #logistic model 학습 \n",
    "print(myModel.predict([[9,4]])) # 1로 나옴 \n",
    "mglearn.plots.plot_2d_separator(myModel,x,\n",
    "                                fill=False,eps=0.5,alpha=0.7) #myModel을 기준으로 분류선 생성\n",
    "                                                              #산점도는 찍히는 순서대로 파->오->초 순"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x24f6d8c1588>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Logistic multinominal 로 확장해보자\n",
    "## x쪽 데이터는 시험성적과 출석점수, \n",
    "## y쪽 데이터는 학점 \n",
    "## example1.xlsx 참조\n",
    "x = np.array([[10,5],\n",
    "              [9,5],\n",
    "              [5,1],\n",
    "              [4,2],\n",
    "              [1,3]])\n",
    "y = np.array([[\"A\"],\n",
    "              [\"A\"],\n",
    "              [\"B\"],\n",
    "              [\"B\"],\n",
    "              [\"C\"]])\n",
    "plt.scatter(x[0:2,0],x[0:2,1]) # A학점의 점을 찍어보아요 \n",
    "plt.scatter(x[2:4,0],x[2:4,1]) # B학점의 점을 찍어보아요 \n",
    "plt.scatter(x[4,0],x[4,1]) #C학점의 점을 찍어보아요 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost값은 : 12.790746688842773\n",
      "Cost값은 : 1.015552282333374\n",
      "Cost값은 : 0.683975338935852\n",
      "Cost값은 : 0.5510250926017761\n",
      "Cost값은 : 0.502730667591095\n",
      "Cost값은 : 0.45980969071388245\n",
      "Cost값은 : 0.054219264537096024\n",
      "Cost값은 : 0.048886846750974655\n",
      "Cost값은 : 0.04497601464390755\n",
      "Cost값은 : 0.041863150894641876\n",
      "정확도 : 1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "#train  data set (example2.xlsx 참조) \n",
    "train_x_data = [[10,7,8,5],\n",
    "                [8,8,9,4],\n",
    "                [7,8,2,3],\n",
    "                [6,3,9,3],\n",
    "                [7,5,7,4],\n",
    "                [3,5,6,2],\n",
    "                [2,4,3,1]]\n",
    "train_y_data = [[1,0,0],                #one hot encoding 형태 \n",
    "                [1,0,0],\n",
    "                [0,1,0],\n",
    "                [0,1,0],\n",
    "                [0,1,0],\n",
    "                [0,0,1],\n",
    "                [0,0,1]]\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,4], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None,3], dtype=tf.float32)\n",
    "\n",
    "# Weight, bias \n",
    "W = tf.Variable(tf.random_normal([4,3]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([3]), name=\"bias\") #세개의 multinomial이기 때문에 bias 도 3개 필요 \n",
    "\n",
    "# Hypothesis \n",
    "logit = tf.matmul(X,W) + b\n",
    "H = tf.nn.softmax(logit) #softmax 처음등장 (sigmoid 대신 probability 등장)\n",
    "\n",
    "# cost function \n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = logit, \n",
    "                                                                 labels = Y)) #버전 2로 고르자 \n",
    "#train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate = 0.1).minimize(cost) \n",
    "\n",
    "#session, 초기화 \n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#학습 \n",
    "for step in range(3000):\n",
    "    _, cost_val = sess.run([train, cost], feed_dict={X:train_x_data,\n",
    "                                                     Y:train_y_data})\n",
    "    if step % 300 == 0:\n",
    "        print(\"Cost값은 : {}\".format(cost_val))\n",
    "        \n",
    "# Accuracy(정확도)\n",
    "predict = tf.argmax(H, axis = 1) #출력되는 셋 중 가장 큰 값의 index번호를 리턴 \n",
    "correct = tf.equal(predict, tf.argmax(Y, axis= 1)) # predict와 correct가 맞으면 좋은 모델(위치를 가지고 비교)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "print(\"정확도 : {}\".format(sess.run(accuracy, \n",
    "                                   feed_dict={X:train_x_data,\n",
    "                                              Y:train_y_data}))) #테스트 할때도 train데이터\n",
    "                                                                 #결과도 1과 거의 같음 \n",
    "#sess.run(H, feed_dict = { X : [[10,8,9,5]] })\n",
    "                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>188</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>161</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>178</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>136</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>2</td>\n",
       "      <td>139</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>1</td>\n",
       "      <td>142</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  height  weight\n",
       "0          1     188      71\n",
       "1          2     161      68\n",
       "2          0     178      52\n",
       "3          2     136      63\n",
       "4          1     145      52\n",
       "...      ...     ...     ...\n",
       "19995      0     163      48\n",
       "19996      2     139      70\n",
       "19997      1     150      48\n",
       "19998      1     189      69\n",
       "19999      1     142      41\n",
       "\n",
       "[20000 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "표준\n"
     ]
    }
   ],
   "source": [
    "## 예제 : BMI 지수를 학습해보자!\n",
    "## BMI 데이터를 학습한 후 자신의 키와 몸무게를 넣어서 결과 확인 \n",
    "\n",
    "## 1) by Sklearn \n",
    "## sklearn의 LogisticRegression 멀티클래스 중 multinomial 사용, softmax연산시행\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "data_df = pd.read_csv(\"./data/bmi/bmi.csv\", skiprows=3) #세줄 뛰고 받아옴\n",
    "display(data_df)\n",
    "\n",
    "X = data_df[['height','weight']]\n",
    "Y = data_df[\"label\"]\n",
    "softmax_reg = LogisticRegression(multi_class = \"multinomial\", solver = \"lbfgs\", C=10)\n",
    "softmax_reg.fit(X,Y)\n",
    "#학습끝!! \n",
    "result = softmax_reg.predict([[183, 72]])\n",
    "\n",
    "if int(result) == 0:\n",
    "    print(\"저체중\")\n",
    "elif int(result) == 1:\n",
    "    print(\"표준\")\n",
    "else:\n",
    "    print(\"과체중\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " ...\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]]\n",
      "Cost값은 : 1.3443607091903687\n",
      "Cost값은 : 0.6374951601028442\n",
      "Cost값은 : 0.552199125289917\n",
      "Cost값은 : 0.5001764893531799\n",
      "Cost값은 : 0.46352702379226685\n",
      "Cost값은 : 0.435551255941391\n",
      "Cost값은 : 0.413112610578537\n",
      "Cost값은 : 0.3945048153400421\n",
      "Cost값은 : 0.3786999583244324\n",
      "Cost값은 : 0.3650273382663727\n"
     ]
    }
   ],
   "source": [
    "## 2) by TensorFlow (단, sklearn MinMaxScaler참조)\n",
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import warnings \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "\n",
    "#data loading\n",
    "data_df = pd.read_csv(\"./data/bmi/bmi.csv\", skiprows=3)\n",
    "\n",
    "# 결측치 확인 \n",
    "data_df.isnull().sum(axis=0) #결측이 없다(OK)\n",
    "\n",
    "# 이상치 확인 \n",
    "'''\n",
    "plt.boxplot(data_df[\"height\"]) #이상치가 없다(OK)\n",
    "plt.boxplot(data_df[\"weight\"]) #이상치가 없다(OK)\n",
    "'''\n",
    "# train & test data set + 정규화  \n",
    "split_num = int(data_df.shape[0] * 0.8)\n",
    "scaler = MinMaxScaler()\n",
    "x_data = scaler.fit_transform(data_df[[\"height\", \"weight\"]])\n",
    "\n",
    "train_x_data = x_data[:split_num]\n",
    "test_x_data = x_data[split_num:] #shape는 (16000, 2), 정규화 과정에서 numpy를 slicing 했기 때문  \n",
    "\n",
    "'''\n",
    "train_x_data = data_df.loc[:split_num,[\"height\",\"weight\"]] \n",
    "scaler = MinMaxScaler()\n",
    "train_x_data = scaler.fit_transform(train_x_data)\n",
    "scaler.data_max_\n",
    "'''\n",
    "# 학습용, 테스트용 y data를 생성 -> one hot encoding \n",
    "# one hot encoding으로 전환시킬 때, \n",
    "# pandas.get_dummies()\n",
    "# tensorflow.one_hot() 둘 중에 하나 보통 사용 \n",
    "\n",
    "sess = tf.Session() #one_hot()은 tf이므로 세션 시작\n",
    "'''\n",
    "tf.one_hot(data_df.loc[:split_num, \"label\"],3)  #이때 label은 1차원 series(df에서 떨어져나옴)\n",
    "                                                #3개로 쪼개는 것을 지정 -> 2차원 化\n",
    "                                                #단, shape이 (16001,3)\n",
    "'''\n",
    "#그리하여\n",
    "train_y_data = sess.run(tf.one_hot(data_df.loc[:split_num-1, \"label\"],3)) \n",
    "test_y_data = sess.run(tf.one_hot(data_df.loc[split_num:, \"label\"],3)) #이거는 inclusive \n",
    "print(test_y_data)\n",
    "\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,2], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None,3], dtype=tf.float32)\n",
    "\n",
    "# Weight, bias \n",
    "W = tf.Variable(tf.random_normal([2,3]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([3]), name=\"bias\") #세개의 multinomial이기 때문에 bias 도 3개 필요 \n",
    "\n",
    "# Hypothesis \n",
    "logit = tf.matmul(X,W) + b\n",
    "H = tf.nn.softmax(logit) #softmax 처음등장 (sigmoid 대신 probability 등장)\n",
    "\n",
    "# cost function \n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = logit, \n",
    "                                                                 labels = Y)) #버전 2로 고르자 \n",
    "#train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate = 0.1).minimize(cost) \n",
    "\n",
    "#session 초기화 \n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#학습 \n",
    "for step in range(3000):\n",
    "    _, cost_val = sess.run([train, cost], feed_dict={X:train_x_data,\n",
    "                                                     Y:train_y_data})\n",
    "    if step % 300 == 0:\n",
    "        print(\"Cost값은 : {}\".format(cost_val))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.9505000114440918\n",
      "NORMAL\n"
     ]
    }
   ],
   "source": [
    "# 매번 학습 돌리는 거 방지를 위해 분리        \n",
    "# Accuracy(정확도)\n",
    "predict = tf.argmax(H, axis = 1) #출력되는 셋 중 가장 큰 값의 index번호를 리턴 \n",
    "correct = tf.equal(predict, tf.argmax(Y, axis= 1)) # predict와 correct가 맞으면 좋은 모델(위치를 가지고 비교)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "print(\"정확도 : {}\".format(sess.run(accuracy, \n",
    "                                   feed_dict={X:test_x_data,\n",
    "                                              Y:test_y_data}))) #테스트 할때도 train데이터\n",
    "                                                                 #결과도 1과 거의 같음 \n",
    "\n",
    "# prediction \n",
    "prediction_data = scaler.transform([[183,72]]) #계산 필요 없이 역산 시행 \n",
    "''' 이하 생략되는 절차  \n",
    "Ex/ \n",
    "tmp1 = (160 - train_df[\"height\"].min()) / (train_df[\"height\"].max() - train_df[\"height\"].min())\n",
    "tmp2 = (30 - train_df[\"weight\"].min()) / (train_df[\"weight\"].max() - train_df[\"weight\"].min())\n",
    "result = sess.run(predict,feed_dict={X:[[tmp1,tmp2]]})\n",
    "'''\n",
    "result = sess.run(tf.argmax(H,1), \n",
    "                  feed_dict = {X : prediction_data})[0] #배열에 있는 첫번째 '값'만 받자 \n",
    "if result == 0:\n",
    "    print(\"THIN\")\n",
    "elif result == 1:\n",
    "    print(\"NORMAL\")\n",
    "else:\n",
    "    print(\"FAT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1  2\n",
       "0      0  1  0\n",
       "1      0  0  1\n",
       "2      1  0  0\n",
       "3      0  0  1\n",
       "4      0  1  0\n",
       "...   .. .. ..\n",
       "19995  1  0  0\n",
       "19996  0  0  1\n",
       "19997  0  1  0\n",
       "19998  0  1  0\n",
       "19999  0  1  0\n",
       "\n",
       "[20000 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.get_dummies(data_df['label']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[CPU_ENV]",
   "language": "python",
   "name": "cpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
