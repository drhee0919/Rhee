## Practical Statistics for Data Science

### 데이터 과학을 위한 통계

#### Contents

> 1. 탐색적 데이터 분석(EDA)
>
> > * 정형화된 데이터 요소 
> > * 테이블 데이터 
> > * 위치 추정 
> > * 변이 추정 
> > * 데이터 분포 탐색하기 
> > * 이진 데이터와 범주 데이터 탐색하기 
> > * 상관관계
> > * 두 개 이상의 변수 탐색하기 
>
> 2. 데이터와 표본분포 
>
> > - 랜덤표본추출과 표본편향
> > - 선택편향
> > - 통계학에서의 표본분포 
> > - 부트스트랩
> > - 신뢰구간
> > - 정규분포
> > - 긴꼬리 분포 
> > - 스튜던트의 t분포
> > - 이항분포 
> > - 푸아송 분포 와 그외 관련 분포들
>
> 3. 통계적 실험과 유의성 검정 
>
> > - A/B검정
> > - 가설검정
> > - 재표본추출
> > - 통계적 유의성과 P값
> > - t검정
> > - 다중검정
> > - 자유도 
> > - 분산분석
> > - 카이제곱 검정 
> > - 멀티암드 밴딧 알고리즘
> > - 검정력과 표본크기
>
> 4. 회귀와 예측
>
> > - 단순선형회귀
> > - 다중선형회귀
> > - 회귀를 이용한 예측 
> > - 회귀에서의 요인변수 
> > - 회귀방정식 해석
> > - 가정 검정: 회귀진단
> > - 다항회귀와 스플라인 회귀
>
> 5. 분류 
>
> > - 나이브 베이즈
> > - 판별분석
> > - 로지스틱 회귀
> > - 분류 모델 평가하기
> > - 불균형 데이터 다루기
>
> 6. 통계적 머신러닝 
>
> > - KNN
> > - 트리모델
> > - 배깅과 랜덤 포레스트
> > - 부스팅
>
> 7. 비지도 학습 
>
> > - 주성분 분석
> > - K평균 클러스터링
> > - 계층적 클러스터링
> > - 모델 기반 클러스터링
> > - 스케일링과 범주형 변수 

----

----



#### Chapter 1 : 탐색적 데이터 분석

> - 정형화된 데이터의 요소 
>
> > * 연속형(Continuous)
> >
> > > 일정 범위 안에서 어떤 값이든 취할 수 있는 데이터
> > >
> > > (유의어: 구간형, 실수형, 수치형 데이터)
> >
> > * 이산(Discrete)
> >
> > > 횟수와 같은 정수 값만 취할 수 있다. 
> > >
> > > (유의어: 정수형, 횟수 데이터)
> >
> > * 범주형(Categorical)
> >
> > > 가능한 범주 안의 값만을 취할 수 있다.
> > >
> > > (유의어: 목록, 열거, 요인, 명목, 다항형 데이터)
> >
> > * 이진(Binary)
> >
> > > 두 개의 값(0,1; T,F) 만을 갖는 범주형 데이터의 특수한 경우
> > >
> > > (유의어: 이항적, 논리형, 지표(indicator), 불리언 데이터) 
> >
> > * 순서형(Ordinal)
> >
> > > 값들 사이에 분명한 순위가 있는 범주형 데이터다
> > >
> > > (유의어: 정렬된 요인 데이터)
>
> - 테이블 데이터
>
> > * 데이터 프레임 
> >
> > > 통계와 머신러닝 모델에서 가장 기본이 되는 테이블 형태의 데이터 구조 
> > >
> > > (유의어: 스프레드 시트, 테이블)
> >
> > * 피처
> >
> > > 일반적으로 테이블의 각 열이 하나의 피처를 의미 
> > >
> > > (유의어: 특징, 속성, 입력, 예측변수(predictor), 변수)
> >
> > * 결과(Outcome)
> >
> > > 데이터 과학 프로젝트의 목표는 대부분 어떤 결과를 예측하는 데 있다.<br>실험이나 연구에서 결과를 예측하기 위하여 피처를 사용한다. 
> > >
> > > (유의어: 종속변수, 응답, 목표, 출력) 
> >
> > * 레코드 
> >
> > > 일반적으로 테이블의 각 행은 하나의 레코드를 의미한다. 
> > >
> > > (유의어: 기록값, 사건(case), 사례, 예제, 관측값, 패턴, 샘플)
>
> - 위치 추정
>
> > "위치" 로 대변되는 중심경향성은 데이터의 특징을 요약하는 중요한 요소 중 하나.
> >
> > * 중간값(Median)
> >
> > > 데이터에서 가장 가운데 위치한 값
> >
> > * 가중 중간값(Weighted Median)
> >
> > > 데이터를 정렬한 후, 각 가중치 값을 위헤서부터 더할 때, 총합의 중간에 위치하는 데이터 값
> >
> > * 절사평균(Trimmed mean)
> >
> > > 정해진 개수의 극단값(extreme value)을 제외한 나머지 값들의 평균 
> > >
> > > (유의어: 절단 평균(truncated mean))
> >
> > * 로버스트(Robust)
> >
> > > 극단값들에 민감하지 않다는 것을 의미
> > >
> > > (유의어: 저항성 있다.(resistant))
> >
> > * 특잇값(Outlier)
> >
> > > 대부분의 값과 매우 다른 데이터 값
> > >
> > > (유의어: 극단값)
> >
> > Ex/ R을 이용한 인구의 평균, 절사평균, 중간값(Github 참조)
> >
> > ``` R
> > state <- read.csv(file="/Users/andrewbruce1/book/state.csv") #경로는 임의설정
> > mean(state[["Population"]]) #인구의 평균 
> > mean(state[["Population"]], trim=0.1) #인구의 절사평균(각 끝 10%제외)
> > median(state[["Population"]]) #인구의 중간값
> > ```
> >
> > Ex/R을 이용한 미국 전체의 평균적 살인률 가중평균, 가중 중간값 
> >
> > ```R
> > library("matrixStats") #matrixStats 패키지 불러오기
> > weighted.mean(state[["Murder.Rate"]], w=state[["Population"]]) #가중평균
> > weighted.median(state[["Murder.Rate"]], w=state[["Population"]]) #가중 중간값 
> > ```
> > 
> >
> > 
> >
>
> 
>
> - 변의 추정 
>
> > "변의" 는 데이터 값이 얼마나 밀집해 있는지, 퍼져 있는지를 나타내는 산포도로서 위치와 함께 데이터의 특징을 요약하는 요소이다. 
> >
> > * 편차(deviation)
> >
> > > 관측값과 위치 추정값사이의 차이 
> > >
> > > (유의어: 오차, 잔차)
> >
> > * 분산(variance)
> >
> > > 평균과의 편차를 제곱한 값들의 합을 n-1로 나눈 값. n은 데이터 개수를 지칭
> > >
> > > (유의어: 평균제곱오차)
> >
> > * 표준편차(standard deviation)
> >
> > > 분산의 제곱근 
> > >
> > > (유의어: l2노름(norm), 유클리드 노름)
> >
> > * 평균절대편차(mean absolute deviation)
> >
> > > 평균과의 편차의 절댓값의 평균 
> > >
> > > (유의어: l1노름, 맨하탄 노름)
> >
> > * 중간값의 중위절대편차(median absolute deviation from the median)
> >
> > > 중간값과의 편차의 절댓값의 중간값 
> >
> > * 범위(range)
> >
> > > 데이터의 최댓값과 최솟값의 차이 
> >
> > * 순서통계량(order statistics)
> >
> > > 최소에서 최대까지 정렬된 데이터 값에 따른 계량형
> > >
> > > (유의어: 순위)
> >
> > * 백분위수(percentile)
> >
> > > 어떤 값들의 p퍼센트가 이 값 혹은 더 작은 값을 갖고, (100-p)퍼센트가 이 값 혹은 더 큰 값을 갖도록 하는 값 
> > >
> > > (유의어: 분위수)
> >
> > * 사분위 범위(interquartile range)
> >
> > > 72번째 백분위수와 25번쨰 백분위수 사이의 차이 
> > >
> > > (유의어: IQR)
> >
> > * 평균절대편차 
> >
> > > 각 측정치에서 전체 평균 값을 뺀 값의 절댓값으로 표시되는 편차들의 합에서 산술평균
> >
> > * 중위절대편차(MAD)
> >
> > >  [평균 절대 편차](https://ko.wikipedia.org/wiki/평균_절대_편차)(average absolute deviation)와 유사하지만 [평균](https://ko.wikipedia.org/wiki/평균) 대신 [중앙값](https://ko.wikipedia.org/wiki/중앙값)을 쓴다는 점이 다르다. [절대 편차](https://ko.wikipedia.org/wiki/절대_편차)(absolute deviation)의 일종 [평균 절대 편차](https://ko.wikipedia.org/wiki/평균_절대_편차)(average absolute deviation)와 유사하지만 [평균](https://ko.wikipedia.org/wiki/평균) 대신 [중앙값](https://ko.wikipedia.org/wiki/중앙값)을 쓴다는 점이 다르다. [절대 편차](https://ko.wikipedia.org/wiki/절대_편차)(absolute deviation)의 일종
> >
> > 
>
> - 데이터 분포 탐색하기 
>
> > 상기 추정들은 모두 데이터의 위치 혹은 변이를 나타내기 위한 수치로 데이터를 요약한다.<br>더불어 데이터가 전반적을 어떻게 분포하고 있는지를 알아보는 것 역시 유용하다. 
> >
> > * 상자그림(boxplot)
> >
> > > 투키가 데이터의 분포를 시각화하기 위한 간단한 방법으로 소개한 그림. 중위수, 사분위수, 이상치 확인에 용이 
> > >
> > > (유의어: 상자 수염도)
> >
> > * 도수분포표(frequency table)
> >
> > > 어떤 구간(interval)(=빈bin)에 해당하는 수치 데이터 값들의 빈도를 나타내는 기록
> >
> > * 히스토그램(histogram)
> >
> > > x축은 구간, y축은 빈도수를 나타내는 도수 테이블의 그림 
> >
> > * 밀도 그림(density plot)
> >
> > > 히스토그램을 부드러운 곡선으로 나타낸 그림. 커널밀도추정(kernel density estimation)을 주로 사용
> >
> > 
>
> - 이진 데이터와 범주 데이터 탐색하기 
>
> > * 최빈값(mode)
> >
> > > 데이터에서 가장 자주 등장하는 범주 혹은 값
> >
> > * 기댓값(expected value)
> >
> > > 범주에 해당하는 어떤 수치가 있을 때, <u>범주의 출현 확률에 따른 평균</u>
> >
> > * 막대도표(bar chart)
> >
> > > 각 범주의 빈도수 혹은 비율을 막대로 나타낸 그림 
> >
> > * 파이그림(pie chart)
> >
> > > 각 범주의 빈도수 혹은 비율을 원의 부채꼴 모양으로 나타낸 그림 
>
> - 상관관계 
>
> > "X가 큰 값을 가지면 종속변수 Y도 큰값을 가지고, X가 작은 값을 가지면 Y도 작은 값을 갖는 경우, 변수 X와 Y는 <u>양의 상관관계</u>를 갖는다고 말한다.(반대의 경우 <u>음의 상관관계</u>)"
> >
> > * 상관계수(correlation coefficient)
> >
> > > 수치적 변수들 간에 어떤 관계가 있는지를 나타내기 위해 사용되는 측정량 
> > >
> > > (-1에서 +1까지 범위)
> >
> > * 상관행렬(correlation matrix)
> >
> > > 행과 열이 변수들을 의미하는 표를 말하며, 각 셀은 그 행과 열에 해당하는 변수들 간의 상관관계를 의미함.
> >
> > ```R
> > # R의 corrplot 패키지를 이용한 ETF들의 일간 수익 사이 상관관계 도식 코드
> > etfs <- sp500_px[row.names(sp500_px)>"2012-07-11",
> >                  sp500_sym[sp500_sym$sector=="etf", 'symbol']]
> > library(corrplot)
> > corrplot(cor(etfs), method="ellipse")
> > ```
> >
> > 
> >
> > * 산점도(scatter plot)
> >
> > > X축과 Y축이 서로 다른 두 개의 변수를 나타내는 도표 
> > >
> > > (상관관계 파악에 용이하다.)
> >
> > ```R
> > # AT&T와 Verizon의 일간 수익 사이를 그림으로(산점도로) 표시
> > plot(telecom$T, telecom$VZ, xlab="T", ylab="VZ")
> > ```
> >
> > 
>
> - 두 개 이상의 변수 탐색하기(이변량분석)
>
> > * 분할표(contingency table)
> >
> > > 두 가지 이상의 범주형 변수의 빈도수를 기록한 표
> >
> > ```R
> > #워싱턴 주 킹 카운티의 주택 시설에 대한 과세 평가 금액 정보 kc_tax
> > kc_tax0<-subset(kc_tax, TaxAssessedValue<750000 & SqFtToLiving>100 &
> >                 SqFtToLiving<3500) #이상치 기준을 정하여 전처리 
> > nrow(kc_tax0) #[1] 432733
> > ```
> >
> > * 육각형 구간(hexagonal binning)
> >
> > > 두 변수를 육각형 모양의 구간으로 나눈 그림
> >
> > ```R
> > #집의 크기와 과세 평가액을 나타낸 육각형 구간 도표 
> > ggplot(kc_tax0, (aes(x=SqFtToLiving, y=TaxAssessedValue))) + stat_binhex(colour="white")+
> > theme_bw()+
> > scale_fill_gradient(low="white", high="black") + 
> > labs(x="Finished Square Feet", y="Tax Assessed Value")
> > ```
> >
> > * 등고 도표(contour plot)
> >
> > > 지도상에 같은 높이의 지점을 등고선으로 나타내는 것처럼 두 변수의 밀도를 등고선으로 표시한 도표 
> >
> > ```R
> > #집의 크기와 과세 평가액을 나타낸 등고선 도표 
> > ggplot(kc_tax0, aes(x=SqFtToLiving, y=TaxAssessedValue)) + 
> > theme_bw()+
> > geom_point(alpha=0.1) + 
> > geom_density(colour="white") + 
> > labs(x="Finished Square Feet", y="Tax Assessed Value")
> > ```
> >
> > ※ 히트맵, 육각 구간, 등고 도표 모두 이차원상의 밀도를 시각화하는 데 사용된다. <br>(히스토그램과 밀도 그림과 유사성 확인)
> >
> > * 바이올린 도표(violine plot)
> >
> > > 상자그림과 비슷하지만 밀도추정을 함께 보여준다. 
> >
> > ```R
> > #항공기 원인에 따른 운항 지연 비율을 나타내는 상자그림과 바이올린 도표의 조합 
> > ggplot(data=airline_stats, aes(airline, pt_carrier_delay)) + 
> > ylim(0,50) +
> > geom_violin()+
> > labs(x="".y="Daily % of Delayed Flights")
> > ```
> >
> > 

----



#### chapter 2. 데이터와 표본분포 

> - 랜덤표본추출과 표본편향
>
> > * 표본(sample)
> >
> > > 더 큰 데이터 집합으로부터 얻은 부분집합 
> >
> > * 모집단(population)
> >
> > > 어떤 데이터 집합을 구성하는 전체 대상 혹은 전체 집합 
> >
> > * N(n) (←괄호포함)
> >
> > > 모집단(표본)의 크기
> >
> > * 임의표집(랜덤표본추출; random sampling)
> >
> > > 무작위로 표본을 추출하는 것 
> >
> > * 층화표집(층화표본추출; stratified sampling)
> >
> > > 모집단을 층으로 나눈 뒤, 각 층에서 무작위로 표본을 추출 하는 것 
> >
> > * 단순임의표본(단순랜덤표본; simple random sample)
> >
> > > 모집단 층화없이 랜덤표본추출로 얻은 표본 
> >
> > - 대표성 
> >
> > > 표본이 전체 모집단을 대표하는 정도 
> > >
> > > ※ 데이터 품질이란 완결성, 형식의 일관성, 깨끗함, 데이터 정확성등을 지칭<br>통계는 여기서 대표성이라는 개념을 추가함 
> >
> > * 표본편향(sample bias)
> >
> > > 모집단을 잘못 대표하는 표본 
> > >
> > > ex/ 리터러리 다이제스트의 랜던 vs 프랭클링 대선경합 예상설문 
> >
> > - 층화표본추출 
> >
> > > 모집단을 여러 층으로 나누고, 각 층(Strata)에서 무작위로 샘플을 추출하는 것 
> > >
> > > ex/ 가령 지역별 특정 인종에 대한 지지율을 분석할 때, 해당 지역에 특정 인종이 지나치게 적게 분포할 경우 해당 층에 높은 가중치를 주는 표본추출을 통해 계층마다 동일한 표본크기를 얻을 수 있다.  
>
> - 선택편향
>
> > * 편향(bias)
> >
> > > 계통적 오차 
> >
> > * 데이터 스누핑(data snooping)
> >
> > > 뭔가 흥미로운 것을 찾아 광범위하게 데이터를 살피는 것 
> >
> > * 방대한 검색 효과(vast search effect)
> >
> > > 중복 데이터 모델링이나 너무 많은 예측변수를 고려하는 모델링에서 비롯되는 편향 혹은 비재현성. 
> >
> > - 목표값 섞기(target shuffling, 순열검정)
> >
> > > 데이터마이닝 모델에서 제시하는 예측들을 검증하기 위해, 샘플들을 한 쌍 씩 섞어주는 것이 아니라 무작위로 섞은 뒤 그룹을 나누어 검정하는 방법 
>
> - 통계학에서의 표본분포 
>
> > 고전 통계의 대부분은 작은 표본을 가지고 매우 큰 모집단을 추론하는 것과 관련이 있다. 
> >
> > * 표본통계량(sample statistics)
> >
> > > 더 큰 모집단에서 추출된 표본 데이터들로부터 얻은 측정 지표 
> >
> > * 데이터 분포(data distribution)
> >
> > > 어떤 데이터 집합에서 각 개별 값의 도수분표
> >
> > * 표본분포(sample distribution)
> >
> > > 여러 표본들 혹은 재표본들로부터 얻은 표본 통계량의 도수분포
> >
> > * 중심극한정리(central limit theorem)
> >
> > > 표본크기가 커질 수록 표본분포가 정규분포를 따르는 경향 
> >
> > * 표준오차(standard error)
> >
> > > 여러 표본들로부터 얻은 표본통계량의 변량
> > >
> > > (※ 개별 데이터 값들의 변량을 뜻하는 표준편차와 혼동 X)
>
> - 부트스트랩
>
> > 보통 재표본추출이라는 용어는 여러 표본이 결합되어 비복원추출을 수행할 수 있는 순열 과정을 포함하고, 부트스트랩이라는 용어는 항상 관측된 데이터로부터 복원추출한다는 것을 의미함.
> >
> > * 부트스트랩(데이터로부터 복원추출)은 표본통계량의 변동성을 평가하는 강력한 도구 
> > * 부트스트랩은 표본분포으 수학적 근사치에 대한 엄청난 연구 없이도 다양한 환경에서 유사한 방식으로 적용될 수 있다. 
> >
> > * 부트스트랩 표본(boostrap sample)
> >
> > > 관측 데이터 집합으로부터 얻은 복원추출 표본 
> >
> > * 재표집, 재표본추출(resampling)
> >
> > > 관측 데이터로부터 반복해서 표본추출하는 과정. 부트스트랩과 순열(셔플링)과정을 포함한다. 
> > >
> > > ※부트스트랩 재표본추출 알고리즘 순서
> > >
> > > > 1. 샘플 값을 하나 뽑아서 기록하고 제자리에 놓는다. 
> > > > 2. n번 반복한다. 
> > > > 3. 재표본추출된 값의 평균을 기록한다. 
> > > > 4. 1~3단계를 n번 반복한다. 
> > > > 5. R개의 결과를 사용하여 
> > > >
> > > > > 5-1. 그것들의 표준편차를(표본평균의 표준오차) 계산한다. 
> > > > >
> > > > > 5-2. 히스토그램 또는 상자 그림을 그린다.
> > > > >
> > > > > 5-3. 신뢰구간을 찾는다. 
> >
> > ```R
> > #대출받은 사람들의 소득 데이터에 부트스트랩 적용
> > library(boot)
> > stat_fun <- funtion(x, idx) median(x[idx])
> > boot_obj <- boot(loans_income, R=1000, statistic=stat_fun)
> > ```
> >
> > 
>
> - 신뢰구간
>
> > 어떤 단일루치(점추정) 분석이 제공될 때, 추정치에 과도한 믿음이 실리는 것을 방지하기 위해 어떤 범위로 추정치를 제시하는 통계적 샘플링 원칙에 근거한 방식의 신뢰구간. 
>
> ```
> 표본크기 n과 관심있는 표본통계량이 주어졌을 때, 부트스트랩의 신뢰구간을 구하는 법 
> 1. 데이터에서 복원추출 방식으로 크기 n인 표본을 뽑는다.(재표본추출)
> 2. 재표본추출한 표본에 대해 원하는 통계량을 기록한다. 
> 3. 1~2.를 R번 반복한다. 
> 4. x% 신뢰구간을 구하기 위해, R개의 재표본 결과로부터 분포의 양쪽 끝에서
>    [(100-x)/2]% 만큼 잘라낸다. 
> 5. 절단한 점들은 x% 부트스트랩 신뢰구간의 양 끝점이다. 
> ```
>
> > * 90% 신뢰구간이란, 표본통계량의 부트스트랩 표본분포의 90%를 포함하는 구간을 말한다. 
> >
> > * 신뢰수준(confidence level)
> >
> > > 같은 모집단으로부터 같은 방식으로 얻은, 관심 통계량을 포함할 것으로 예상되는 신뢰구간의 백분율
> >
> > * 구간끝점(interval endpoint)
> >
> > > 신뢰구간의 최상위, 최하위 끝점
>
> - 정규분포
>
> > 정규분포는 독일의 수학자 카를 프리드리히 가우스의 이름을 따 가우스 분포(Gaussian Distribution)라고도 부린다. 
> >
> > - 정규분포에서 데이터의 68%는 평균의 표준편차 내에 속하며 95%는 표준편차 두 배수 내에 있다.
> >
> > * 오차(error)
> >
> > > 데이터 포인트와 예측값 혹은 평균 사이의 차이 
> >
> > * 표준화하다(정규화하다; standarize)
> >
> > > 데이터에서 평균을 뺴고 표준편차로 나눈다. 
> >
> > * z-점수(z-score)
> >
> > > 개별 데이터 포인트를 정규화한 결과(표준화한 결과)
> >
> > * 표준정규분포
> >
> > > 평균=0, 표준편차=1인 정규분포(z분포)
> >
> > * QQ그림(QQ-plot)
> >
> > > 표본분포가 정규분포에 얼마나 가까운지를 보여주는 그림 
> >
> > ![qq_plot](.\qq_plot.png)
> >
> > ```R
> > ## 정규분포에서 임의로 생성한 100개의 값에 대한 QQ그림 도식 
> > norm_samp <- rnorm(100)
> > qqnorm(norm_samp)
> > abline(a=0, b=1, col='grey')
> > ```
> >
> > ※주요 개념 
> >
> > > * 정규분포는 불확실성과 변동성에 관한 수학적 근사가 가능하도록 했다. 이는 통계의 역사적 발전에 필수적이었다.
> > > * 원시 데이터 자체는 대게 정규분포가 아니지만, 표본들의 평균과 합계, 그리고 오차가 많은 경우 정규분포를 따른다. 
> > > * 데이터를 z점수로 변환하려면 데이터의 값에서 평균을 뺴는 표준편차로 나눈다. 그러면 데이터를 정규분포와 비교할 수 있다. 
>
> - 긴꼬리 분포 
>
> > * 정규분포를 따를 것이라는 가정은, 자주 일어나지 않는 예외의 경우(흑고니; blackswan)에 관한 과소평가를 가져올 수 있다. 
> >
> > * 꼬리(tail)
> >
> > > 적은 수의 극단값이 주로 존재하는, 도수분포의 길고 좁은 부분
> >
> > * 왜도(skewness)
> >
> > > 분포의 한쪽 꼬리가 반대족 다른 꼬리보다 긴 정도
>
> - 스튜던트의 t분포
>
> > t분포는 정규분포와 생김새가 비슷하지만, 꼬리 부분이 약간 더 두껍고 길다. 이것은 표본통계량의 분포를 설명하는 데 광범위하게 사용된다. 
> >
> > * n : 표본크기 
> > * 자유도(degrees of freedom)
> >
> > > 다른 표본크기, 통계량, 그룹의 수에 따라 t분포를 조절하는 변수 
>
> - 이항분포 
>
> > * 시행(trial)
> >
> > > 독립된 결과를 가져오는 하나의 사건 
> >
> > * 성공(success)
> >
> > > 시행에 대한 관심의 결과
> > >
> > > (유의어: 1, 즉 0에 대한 반대)
> >
> > * 이항식(binomial)
> >
> > > 두 가지 결과를 갖는다
> > >
> > > (유의어: 예/아니오, 0/1, 이진)
> >
> > * 이항시행(binomial trial)
> >
> > > 두 가지 결과를 가져오는 시행 
> > >
> > > (유의어: 베르누이 시행)
> >
> > * 이항분포(binomial distribution)
> >
> > > x번 시행해서 성공한 횟수에 대한 분포
> > >
> > > (유의어: 베르누이 분포)
>
> - 푸아송 분포 와 그외 관련 분포들
>
> > * 푸아송 분포는 시간 단위 또는 공간 단위로 표본들을 수집할 때, 그 사건들의 분포를 알려준다. 
> >
> >   ex/ '5초 동안 서버에 도착한 인터넷 트래픽을 95%확률로 완벽하게 처리하는 데 필요한 용량은?' 
> >
> > * 람다(lambda)
> >
> > > 단위 시간이나 단위 면적당 사건이 발생하는 비율(푸아송 분포의 핵심 파라미터)
> >
> > * 푸아송 분포(Poisson distribution)
> >
> > > 표집된 단위 시간 혹은 단위 공간에서 발생한 사건의 도수분포
> >
> > ```R
> > ##람다가 2인 푸아송 분포에서 100개의 난수를 생성 
> > rpois(100,lambda =2)
> > ```
> >
> > 
> >
> > * 지수분포(Exponential distribution)
> >
> > > 한 사건에서 그다음 사건까지의 시간이나 거리에 대한 도수분포
> >
> > * 베이불 분포(Weibull distribution)
> >
> > > 사건 발생률이 시간에 다라 변화하는, 지수분포의 일반화된 버전 



#### Chapter3. 통계적 실험과 유의성 검정 

> - A/B검정
>
> > A/B 검정은 두 처리 방법, 혹은 절차 중 어느 쪽이 다른 쪽보다 더 우월하다는 것을 입증핳기 위해 실험군을 두 그룹으로 나누어 진행하는 실험을 뜻한다. 
> >
> > * 처리(treatment)
> >
> > > 어떤 대상에게 주어지는 특별한 환경이나 조건(약, 가격, 인터넷 뉴스 제목)
> >
> > * 처리군(treatment group)
> >
> > > 특정 처리에 노출된 대상들의 집단
> >
> > * 대조군(control group)
> >
> > > 어떤 처리도 하지 않은 대상들의 집단
> >
> > * 임의화(랜덤화; randomization)
> >
> > > 처리를 적용할 대상을 임의로 결정하는 과정
> >
> > * 대상(subject)
> >
> > > 처리를 적용할 개체 대상
> > >
> > > (유의어: 피실험자)
> >
> > * 검정통계량(test statistics)
> >
> > > 처리 효과를 측정하기 위한 지표 
>
> - 가설검정
>
> > * 귀무가설(null hypothesis)
> >
> > > 우연 때문이라는 가설(=그룹들이 보이는 결과는 서로 동일하며, 그룹간의 차이는 우연의 일치)
> > >
> > > 통계에서는 "모집단의 특성에 대해 옳다고 제안하는 잠정적인 주장"
> > >
> > > ex/ ~와 차이가 없다, ~의 효과가 없다, ~와 같다. 
> > >
> > > →즉 가설검정이란, 귀무가설이 틀렸다는 것을 입증하여, A,B 두 그룹 간의 차이가 우연이 아니라는 것을 입증 
> > >
> > > (유의어: 영가설)
> >
> > * 대립가설(alternative hypothesis)
> >
> > > 귀무가설과의 대조(=증명하고자 하는 가설)
> > >
> > > 귀무가설이 틀렸다고 판단되었을 때, 대안적으로 선택되는 가설 
> > >
> > > ex/ ~와 차이가 있다, ~의 효과는 있다, ~와 다르다 
> >
> > ※ 귀무가설과 대립가설은 모든 가능성을 설명할 수 있어야 한다. 
> >
> > * 일원검정(one-way test)
> >
> > > 한 방향으로만 우연히 일어날 확률을 계산하는 가설검정
> >
> > * 이원검정(two-way test)
> >
> > > 양방향으로 우연히 일어날 확률을 계산하는 가설검정 
>
> - 재표본추출
>
> > * 순열검정(permutation test)
> >
> > > 두 개 이상의 표본을 함께 결함하여 관측값들을 무작위로(또는 전부를) 재표본으로 추출하는 검정 과정 
> > >
> > > (유의어: 임의화검정, 임의순열검정, 정확검정)
> > >
> > > * 순열의 절차
> > >
> > > > 1. 여러 그룹의 결과를 단일 데이터 집합으로 결합한다
> > > > 2. 결합된 데이터를 잘 섞은 후, 그룹 A와 동일한 크기의 표본을 무작위로(비복원) 추출
> > > > 3. 나머지 데이터에서 그룹 B와 동일한 크기의 샘플을 무작위로(비복원) 추출
> > > > 4. 이하 C,D ... 로 이어지는 그룹에 대해서도 동일 작업 수행
> > > > 5. 원래 샘플에 대한 통계량 또는 추정치가 무엇이었든 간에(ex/ 그룹간 비율차이 등) 지금 추출한 재표본에 대해 모두 다시 계산 후 기록. → 이것으로 한번의 순열반복 진행
> > > > 6. 앞선 단계들을 R번 반복하여 검정통계량의 순열 분포 획득 
> > > >
> > > > 이후 최초 그룹간의 차이와 순열 과정에서 얻은 집합에서 관찰된 차이가 순열 분포 바깥에 있다면, '통계적으로 유의미하다(=우연이 아니다, statistically, significant)' 고 결론지을 수 있다. 
> > > >
> > > > * 전체순열검정
> > > >
> > > > > 데이터를 무작위로 섞고 나누는 대신 실제로 나눌 수 있는 모든 가능한 조합을 찾는 순열검정(유의어: 정확검정)
> > > >
> > > > * 부트스트랩 순열검정
> > > >
> > > > > 무작위 순열검정의 2,3단계에서 비복원으로 하던 것을 복원추출로 수행하는 검정 
> >
> > * 복원/비복원(with / without replacement)
> >
> > > 표본을 추출할 때, 이미 한번 뽑은 데이터를 다음번 추출을 위해 다시 제자리에 돌려 놓거나 다음 추출에서 제외하는 표집방법 
> >
> > * 대리변수(proxy variable)
> >
> > > 어떤 관심변수를 직접 얻을 수 없거나, 측정하는 데 많은 비용이나 시간이 소요될 경우 대체하는 변수 
> > >
> > > ex/ 기후 연구에서 과거 온도의 대체변수로 사용되는 고대 빙하 중심부의 산소 함량 
>
> - 통계적 유의성과 P값
>
> > * 통계적 유의성
> >
> > > 실험(또는 기존 데이터에 대한 연구) 결과가 우연히 일어난 것인지, 아니면 우연히 일어날 수 없는 극단적인 것인지를 판단하는 방법 
> > >
> > > → 결과가 우연히 벌어질 수 있는 변동성의 바깥에 존재한다면 이를 '통계적으로 유의하다' 고 할 수 있다. 	
> >
> > * p값(p-value)
> >
> > > 귀무가설을 구체화한 기회 모델이 주어졌을 때, 관측된 결과와 같이 특이하거나 극단적인 결과를 얻을 확률
> >
> > ```R
> > mean(perm_diffs > obs_pct_diff)
> > #[1]0.308
> > #P값이 0.308 = 우연히 얻은 결과의 약 30%정도가 과날한 것만큼 극단적이거나 그 이상 극단적인 결과를 얻을 수 있다. 
> > ```
> >
> > 
> >
> > * 알파(alpha)
> >
> > > 실제 결과가 통계적으로 의미 있는 것으로 간주되기 위해, 우연에 의한 기회 결과가 능가해야 하는 '비정상적인' 가능성의 임계 확률 
> >
> > * 제 1종 오류(type 1 error)
> >
> > > 우연에 의한 효과가 실제 효과라고 잘못 결론 내리는 것(맞는걸 틀리다고 하는거)
> >
> > * 제 2종 오류(type 2 error) 
> >
> > > 실제 효과를 우연에 의한 효과라고 잘못 결론 내리는 것(틀린걸 맞다고 하는거)
> >
> > Ex/ 임의의 전자 상거래 실험 결과를 담은 2x2표
> >
> > | 결과          | 가격A | 가격B |
> > | ------------- | ----- | ----- |
> > | 전환          | 200   | 182   |
> > | 전환되지 않음 | 23539 | 22406 |
> >
> > > * 가격 A는 가격B에 비해 5% 정도 우수한 결과를 보임(0.8425% 대 0.8057%, 0.0369%p 개선)
> > > * 전환율이 너무 낮기 때문에(1%미만), 재표본추출 절차를 통해 가격A, B간 전환율 차이가 우연에 의한 것인지(귀무가설) 검정할 수 있다. 
> > > * 다음 순열 절차는 '두 가격이 동일한 전환율을 공유하는지, 이 랜덤 변이가 5% 만큼의 차이를 만들어낼 수 있는지' 에 대한 답을 구하는 절차이다. 
> > >
> > > > 1. 모든 표본 정보가 담긴 전체 전환율은 45,945개의 0과 382개의 1이므로 전환율은 0.8245%가 될 것이다. 
> > > > 2. 크기 23,739(가격A)의 표본을 섞어서 뽑고 그중 1이 몇 개인지 기록한다. 
> > > > 3. 나머지 22,588개(가격B)에서 1의 수를 기록한다. 
> > > > 4. 1의 비율 차이를 기록한다. 
> > > > 5. 2~4단계를 반복한다. 
> > > > 6. 이 차이가 얼마나 자주 >=0.0368 인가 확인한다. 
> > >
> > > ```R
> > > # 무작위로 순열 추출한 전환율 차이에 대한 히스토그램 
> > > obs_pct_diff <- 100*(200/23739 - 182/22588)
> > > conversion <- c(rep(0,45945), rep(1,382))_
> > > perm_diffs <- rep(0, 1000)
> > > for(i in 1:1000)
> > >     perm_diffs[i] = 100*perm_fun(conversion, 23739, 22588)
> > > hist(perm_diffs, xlab-'Conversion rate (percent)', main='')
> > > abline(v=obs_pct_diff, lty=2, lwd=1.5)
> > > text("Observed\n differnce", x=obs_pct_diff, y=par()$usr[4]-20, adj=0)
> > > ```
> > >
> > > 
>
> - t검정
>
> > * 검정통계량(test statistic)
> >
> > > 관심의 차이 또는 효과에 대한 측정 지표
> >
> > * t통계량(t-statistic)
> >
> > > 표준화된 형태의 검정통계량
> >
> > * t분포(t-distribution)
> >
> > > 관측된 t통계량을 비교할 수 있는 (귀무가설에서 파생된) 기준 분포
>
> - 다중검정
>
> > * 제 1종 오류(type 1 error)
> >
> > > 어떤 효고가 통게적으로 유의미하다고 잘못된 결론을 내린다
> >
> > * 거짓 발견 비율(FDR; false discovery rate)
> >
> > > 다중검정에서 1종 오류가 발생하는 비율 
> >
> > * p값 조정(adjustment of p-value)
> >
> > > 동일한 데이터에 대해 다중검정을 수행하는 경우에 필요하다
> >
> > * 과대적합(overfitting)
> >
> > > 잡음까지 피팅(fitting)한 경우 
>
> - 자유도 
>
> > * 표본크기 n 
> >
> > > 해당 데이터에서 관측값의 개수(행 혹은 기록값의 개수와 같은 의미)
> >
> > * d.f.(degrees of freedom)
> >
> > > 자유도. 표본 데이터에서 계산된 통계량에 적용되며 변화가 가능한 값들의 개수 
>
> - 분산분석(analysis of variance; anova)
>
> > * 쌍별 비교(pairwise comparison)
> >
> > > 여러 그룹 중 두 그룹 간의(ex/평균) 가설검정
> >
> > * 총괄검정(omnius test)
> >
> > > 여러 그룹 평균들의 전체 분산에 관한 단일 가설검정
> >
> > * 분산분해(decomposition of variance)
> >
> > > 구성 요소 분리, 예를 들면 전체 평균, 처리 평균, 잔차 오차로부터 개별 값들에 대한 기여를 뜻한다. 
> >
> > * F통계량(F-statistics)
> >
> > > 그룹 평균 간의 차이가 랜덤 모델에서 예상되는 것보다 벗어나는 정도를 측정하는 표준화된 통계량 
> >
> > * SS(sum of squares)
> >
> > > 어떤 평균으로부터의 편차들의 제곱합 
>
> - 카이제곱 검정 
>
> > * 카이제곱 통계량(chi-square statistic)
> >
> > > 기댓값으로부터 어떤 관찰값까지의 거리를 나타내는 측정치
> >
> > * 기댓값(expectation, expected)
> >
> > > 어떤 가정(보통 귀무가설)으로부터 데이터가 발생할 때, 그에 대해 기대하는 정도
> >
> > * d.f.(degrees of freedom) : 자유도
>
> - 멀티암드 밴딧 알고리즘
>
> > 멀티암드 밴딧(multi-armed bandit)은 우리말로 번역하면 손잡이가 여러 개인 슬롯머신(밴딧)을 뜻한다. 슬롯머신에 달린 여러 개의 손잡이 중에서 어느 것을 당겨야 더 많은 수익을 올릴 수 있을지 결정하는 방법을 찾는 것이 목표다. 
> >
> > * 멀티암드 밴딧
> >
> > > 고객이 선택할 수 있는 손잡이가 여러개인 가상의 슬롯머신을 말하며, 각 손잡이는 각기 다른 수익을 가져다준다. **다중 처리 실험**에 대한 비유라고 생각할 수 있다. 
> >
> > * 손잡이(arm)
> >
> > > 실험에서 어떤 하나의 처리를 지칭(ex/ 웹 테스트 中 '헤드라인 A')
> >
> > * 상금(수익; win)
> >
> > > 슬롯머신으로 딴 상금에 대한 비유(ex/ '고객들의 링크 클릭 수') 
>
> - 검정력과 표본크기
>
> > * 효과크기(effect size)
> >
> > > 통계 검정을 통해 판단할 수 잇는 효과의 최소 크기(ex/ '클릭률의 20% 향상')
> >
> > * 검정력(power)
> >
> > > 주어진 표본크기로 주어진 효과크기를 <u>알아낼 확률</u>
> >
> > * 유의수준(significance level)
> >
> > > 검증 시 사용할 통계 유의수준 



#### chapter4. 회귀와 예측

> - 단순선형회귀
>
> > 한 변수와 또 다른 변수의 크기 사이에서 어떤 관계(ex/ X가 증가하면 Y도 증가)가 있는지를 보여준다. 
> >
> > * 응답변수(반응변수; response variable) 
> >
> > > 예측하고자 하는 변수
> > >
> > > (유의어: 종속변수, 변수 Y, 목표, 출력)
> >
> > * 독립변수(independent variable)
> >
> > > 응답치를 예측하기 위해 사용되는 변수
> > >
> > > (유의어: 변수X, 피처, 속성)
> >
> > * 레코드(record)
> >
> > > 한 특정 경우에 대한 입력과 출력을 담고 있는 백터
> > >
> > > (유의어: 행, 사건, 예시(instance), 예제(example))
> >
> > * 절편(intercept)
> >
> > > 회귀직선의 절편. 즉 X=0일 때 예측값
> > >
> > > (유의어: b0, β0)
> >
> > * 회귀계수(regression coefficient)
> >
> > > 회귀직선의 기울기
> > >
> > > (유의어: 기울기(slope), b1,β1,모수 추정값, 가중치)
> >
> > * 적합값(fitted value)
> >
> > > 회귀선으로부터 얻은 추정치 Yi
> > >
> > > (유의어: 예측값)
> >
> > * 잔차(residual)
> >
> > > 관측값과 적합값의 차이
> > >
> > > (유의어: 오차)
> >
> > * 최소제곱(least square)
> >
> > > 잔차의 제곱합을 최소화하여 회귀를 피팅하는 방법
> > >
> > > (유의어: 보통최소제곱)
>
> - 다중선형회귀
>
> > * 제곱근 평균제곱오차(root mean squared error)
> >
> > > 회귀 시 평균제곱오차의 제곱근. 회귀모형을 평가하는 데 가장 널리 사용되는 측정 지표
> > >
> > > (유의어: RMSE)
> >
> > * 잔차 표준오차(residual standard error)
> >
> > > 평균제곱오차와 동일하지만 자유도에 따라 보정된 값 
> > >
> > > (유의어: RSE)
> >
> > * R제곱(r-squared)
> >
> > > 0에서 1까지 몯ㄹ에 의해 설명된 분산의 비율
> > >
> > > (유의어: 결정계수(coefficient of determination, R2))
> >
> > * t 통계량(t-statistic)
> >
> > > 계수의 표준오차로 나눈 예측변수의 계수. 모델에서 변수의 중요도를 비교하는 기준이 된다. 
> >
> > * 가중회귀(weighted regression)
> >
> > > 다른 가중치를 가진 레코드들을 회귀하는 방법 
> >
> > * 교차타당성검사 
> >
> > > 홀드 아웃(모델을 만든 후 떼어놓았던 데이터) 샘플 아이디어를 여러 개의 연속된 홀드아웃 샘플로 확장한 것 (ex/ k 다중 교차타당성검사(k-fold cross-validation))
> >
> > * 오컴의 면도날
> >
> > > 모든 것이 동일한 조건에서는, 복잡한 모델보다는 단순한 모델을 우선 사용해야 한다는 원리.
>
> - 회귀를 이용한 예측 
>
> > * 예측구간(prediction interval)
> >
> > > 개별 예측값 주위의 불확실한 구간 
> >
> > * 외삽법(extrepolation)
> >
> > > 모델링이 사용된 데이터 범위를 벗어난 부분까지 모델을 확장하는 것 
>
> - 회귀에서의 요인변수 
>
> > * 가변수(dummy variable)
> >
> > > 회귀나 다른 모델에서 요인 데이터를 사용하기 위해 0과 1의 이진변수로 부호화한 변수 
> >
> > * 기준 부호화(reference coding)
> >
> > > 통계학자들이 많이 사용하는 부화화 형태. 여기서 한 요인을 기준으로 하고다른 요인들이 이 기준에 따라 비교할 수 있도록 한다. 
> > >
> > > (유의어: 처리 부호화(treatment coding))
> >
> > * 원-핫 인코딩(one-hot encoding)
> >
> > > 머신러닝 분야에서 많이 사용되는 부호화. 모든 요인 수준이 계속 유지된다. 
> > >
> > > ※ 어떤 머신 러닝 알고리즘에서는 유용한 반면, 다중선형회귀에는 적합하지 않음 
> >
> > * 편차 부호화(deviation coding)
> >
> > > 기준 수준과는 반대로 전체 평균에 대해 각 수준을 비교하는 부호화 방법
> > >
> > > (유의어: 총합 대비(sum contrast))
>
> - 회귀방정식 해석
>
> > * 변수 간 상관(correlated variables)
> >
> > > 예측 변수들끼리 서로 높은 상관성을 갖을 떄 개별 계수를 해석하는 것은 어렵다 
> >
> > * 다중공선성(multicollinearity)
> >
> > > 예측변수들이 완벽하거나 완벽에 가까운 상관성을 가질 떄, 회귀는 불안정하며 계산이 불가능하다.
> > >
> > > (유의어: 공선성)
> >
> > * 교란변수(confounding variable)
> >
> > > 중요한 예측변수이지만 회귀방적식에 누락되어 결과를 잘못되게 이끄는 변수 
> >
> > * 주효과(main effect)
> >
> > > 다른 변수들과 독립된, 하나의 예측변수와 결과변수 사이의 관계
> >
> > * 상호작용(interaction)
> >
> > > 둘 이상의 예측변수와 응답변수 사이의 상호 의존적인 관계 
>
> - 가정 검정: 회귀진단
>
> > * 표준화잔차(standardized residual) 
> >
> > > 잔차를 표준오차로 나눈 값 
> >
> > * 특잇값(outlier)
> >
> > > 나머지 데이터(혹은 예측값)과 멀리 떨어진 레코드(혹은 출력값)
> >
> > * 영향값(influential value)
> >
> > > 있을 떄와 없을 때 회귀방정식이 큰 차이를 보이는 값 혹은 레코드
> >
> > * 지렛대(leverage)
> >
> > > 회귀식에 한 레코드가 미치는 영향력의 정도
> > >
> > > (유의어: 햇 값(hat-value))
> >
> > * 비정규잔차(non-norma value)
> >
> > > 정규분포를 따르지 않는 잔차는 회귀분석의 요건을 무효로 만들 수 있다. 
> > >
> > > 데이터 과학에서는 별로 중요하게 다뤄지지 않는다.
> >
> > * 이분산성(heteroskedasticity)
> >
> > > 어떤 범위 내 출려값의 잔차가 매우 높은 분산을 보이는 경향
> > >
> > > 어떤 예측변수를 회귀식이 놓치고 있다는 것을 의미할 수 있다.
> >
> > * 편잔차그림(partial residual plot)
> >
> > > 결과변수와 특정 예측변수 사이의 관계를 진단하는 그림
> > >
> > > (유의어: 추가변수그림(added variable plot))
>
> - 다항회귀와 스플라인 회귀
>
> > * 다항회귀(polynomial regression)
> >
> > > 회귀모형에 다항식(제곱, 세제곱 등) 항을 추가한 방식
> >
> > * 스플라인 회귀(spline regression)
> >
> > > 다항 구간들을 부드러운 곡선 형태로 피팅한다.
> >
> > * 매듭(knot)
> >
> > > 스플라인 구간을 구분하는 값들
> >
> > * 일반화가법모형(generalized additive model; GAM)
> >
> > > 자동으로 구간을 결정하는 스플라인 모델
>



#### chapter5 분류 

> 에/아니오의 이진 분류부터, 범주의 개수가 두 개 이상인 분류에서 각 클래스에 속할 확률을 구한다. 
>
> - 나이브베이즈
>
> > 주어진 결과에 대해 예측변수 값을 관찰할 확률을 사용하여, 예측변수가 주어졌을 때, Y=i를 관찰할 확률을 추정한다. 
> >
> > 
> >
> > * 조건부확률(conditional probability)
> >
> > > 어떤 사건(Y=i)이 주어졌을 때, 해당 사건(X=i)을 관찬할 확률P(Xi|Yi)
> >
> > * 사후확률(posterior probability)
> >
> > > 예측 정보를 통합한 후 결과의 학률
> > >
> > > (※이와 달리, 사전확률에서는 예측변수에 대한 정보를 고려하지 않는다.)
>
> -  
>
> 
>
> 
>
> 
>



